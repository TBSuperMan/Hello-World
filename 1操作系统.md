# 操作系统

## 什么是操作系统？

- 是管理计算机硬件与软件资源的程序，是计算机的基石
- 本质上也是一个运行在计算机上的软件，用于管理计算机硬件与资源。
- 屏蔽了硬件层的复杂性
- 分为内核与外壳
  - 外壳是围绕着内核的应用程序，连接用户与内核；
  - 内核直接操作硬件
- 内核（Kernel）是操作系统的核心，负责系统的内存管理、硬件设备的管理、文件系统的管理与应用程序的管理，是连接应用程序与硬件的桥梁，决定着操作系统的性能与稳定性

## 并发和并行有什么区别？

并发就是在一段时间内，多个任务都会被处理；但**在某一时刻，只有一个任务在执行**。
单核处理器可以做到并发。比如有两个进程`A`和`B`，`A`运行一个时间片之后，切换到`B`，`B`运行一个时间片之后又切换到`A`。因为切换速度足够快，所以宏观上表现为在一段时间内能同时运行多个程序。

并行就是在**同一时刻，有多个任务在执行**。
这个需要多核处理器才能完成，在微观上就能同时执行多条指令，不同的程序被放到不同的处理器上运行，这个是物理上的多个进程同时进行。

## 中断是什么

中断即打断计算机正常执行的任务的现象，中断是**外部设备向处理器发起的请求事件**，通过中断信号让计算机停止执行当前的进程，并**转入内核态**，由操作系统内核对中断进行处理，并在处理完成后跳转会原来的进程，继续执行

中断使得计算机系统具备应对对处理突发事件的能力，提高了CPU的工作效率。
如果没有中断系统，CPU就只能**按照原来的程序编写的先后顺序，对各个外设进行查询和处理**，即**轮询**工作方式，轮询方法貌似公平，但实际工作效率却很低，且不能及时响应紧急事件。


轮询：CPU按照编码顺序，对**特定设备**轮流询问。效率低，突发事件的等待时间长，CPU利用率不高


中断：通过**特定事件**提醒CPU。
* 轮询：效率低等待时间长，CPU利用率不高。中断：容易遗漏问题，CPU利用率不高。

**执行流程**
1. 保护现场：将当前执行程序的相关数据保存在寄存器中，然后入栈。
2. 开中断：以便执行中断时能响应较高级别的中断请求。
3. 中断处理
4. 关中断：保证恢复现场时不被新中断打扰
5. 恢复现场：从堆栈中按序取出程序数据，恢复中断前的执行状态。


## 中断与异常的区别

- 中断Interruption，外中断，指来自CPU执行指令意外的事件的发生
- 异常Exception，内中断，指**源自CPU执行指令内部的事件**


## 什么是用户态和内核态？

用户态和系统态是操作系统的两种运行状态，都是基于进程的：

- 用户态：用户态运行的进程只能**受限地访问内存**，**只能直接读取用户程序的数据**，并且不允许访问外围设备，用户态下的 CPU 不允许独占，也就是说 CPU 能够被其他程序获取。
  - 在用户态，凡是与系统级别的资源有关的操作，都必须**通过系统调用的方式向OS发出请求**，并由OS代为完成

- 内核态：内核态运行的进程可以**访问计算机的任何数据和资源**，包括外围设备，不受限制。
  处于内核态的 CPU 可以从一个程序切换到另外一个程序，并且占用 CPU 不会发生抢占情况。

> 系统调用：操作系统提供给用户态的接口，用于进行与系统级别的资源相关的操作（由OS在内核态执行）
> 主要包括设备管理、文件管理、进程控制、内存管理

将操作系统的运行状态分为用户态和内核态，主要是为了**对访问能力进行限制**，防止随意进行一些比较危险的操作导致系统的崩溃，比如设置时钟、内存清理，这些都需要在内核态下完成 。

## 用户态和内核态是如何切换的?

所有的用户进程都是运行在用户态的，但用户程序的访问能力有限，一些比较重要的比如从硬盘读取数据，从键盘获取数据的操作则是**内核态**才能做的事情，而这些数据却又对用户程序来说非常重要。
所以就涉及到两种模式下的转换，即**用户态 -> 内核态 -> 用户态**，而唯一能够做这些操作的只有 ==系统调用==，而能够执行系统调用的就只有 `操作系统`。

> 中断和异常也可以切换入内核态

一般用户态 -> 内核态的转换我们都称之为 `trap` 进内核，也被称之为 `陷阱指令(trap instruction)`。

他们的工作流程如下：

![image-20210807152619210](http://blog-img.coolsen.cn/img/image-20210807152619210.png)

当发生用户态到内核态的切换时，会发生如下过程（本质上是从“用户程序”切换到“内核程序”）：
- 设置处理器为内核态
- 保存当前寄存器（栈指针、程序计数器、通用寄存器）
- 将栈指针设置指向内核栈地址
- 将程序计数器设置为一个事先约定的地址上，该地址上存放的是**系统调用处理程序的起始地址**

而之后从内核态返回用户态时，又会进行类似的工作


## 用户态空间的内存和内核态空间的内存有什么区别

操作系统为每个进程都分配了内存空间，一部分是用户空间，一部分是内核空间。内核空间是操作系统内核访问的区域，是受保护的内存空间，而用户空间是用户应用程序访问的内存区域。

以32位操作系统为例，它会为每一个进程都分配了4G(2的32次方)的内存空间。

- **内核空间**：主要提供进程调度、内存分配、连接硬件资源等功能
- **用户空间**：提供给各个程序进程的空间，它不具有访问内核空间资源的权限，如果应用程序需要使用到内核空间的资源，则需要通过系统调用来完成。进程从用户空间切换到内核空间，完成相关操作后，再从内核空间切换回用户空间。

## 进程与线程分别是什么？有什么区别？

- 进程：是具有独立功能的程序在一个数据集合上运行的过程，执行前需要将程序放到内存中，才能被CPU处理（单处理机系统中，同一时刻只能有一个进程占用处理机）
  - 是系统进行==资源分配的基本单位==
  - 有独立的内存空间
    - **上下文切换的内容包括：**
      - **用户级上下文（用户堆栈、数据、共享存储区）**
      - **寄存器上下文（cpu寄存器、程序计数器）**
      - **系统级上下文（内存管理信息（例如页表等）、内核栈、进程控制块）**
  - 进程间不共享资源
  - 通讯都需要通过内核，主要通过信号的方式实现
  - 调度由OS完成

- 线程：基本的CPU执行单元，也是程序执行流的最小单元，是进程中的一个实体，是被系统==独立调度与分派的基本单位==，拥有一些运行时必不可少的资源
  - 同一进程内的多个线程共享进程的资源，**线程间的同步与通信很容易实现，但存在线程安全问题**
    - 可以通过共享内存的方式实现通信
  - **线程切换只需要保存与设置少量寄存器内容，开销较小**，
    - 但内核级线程的调度需要在内核态与用户态之间频繁切换，资源消耗也不小
    - 不过用户级线程的调度由进程负责完成，不需要进行用户态和内核态的切换
  - 调度由OS完成

- 协程：
  - 比线程更加轻量级，协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行，没有线程切换的开销）
  - 一个线程（进程）可以有多个协程
  - 协程需要保证是**非堵塞的且没有相互依赖**
  - 协程基本上不能同步通讯，多采用**异步的消息通讯**，效率比较高
  - 协程通过多进程+协程的方式利用多核，且发挥了协程的高效率

> 协程和普通的子程序类似，但子程序通过栈的方式实现调用，不能中断，但协程可以中断

> CPU内核栈的内容：用户栈地址 + 硬件现场内容，用于

## 进程与线程的切换流程？

**进程切换分两步**：

1. 虚拟内存地址空间的转换
   - 切换**页表**以使用新的地址空间，一旦去切换上下文，==处理器中的快表所有已经缓存的内存地址一瞬间都作废了==，导致快表中的内容全部要重新填入，就严重影响了速度
     - 上下文是由程序运行所需的状态组成，包括程序的代码和数据，堆栈，寄存器，程序计数器，打开的句柄等
2. 内核栈和硬件上下文的切换
   - 主要是cpu寄存器内容的切换 
    
对于linux来说，线程和进程的最大区别就在于**地址空间**，
**对于线程切换，不需要切换地址空间，但第2步是进程和线程切换都要做的**。

> 因为每个进程都有自己的虚拟地址空间，
> 而**线程是共享所在进程的虚拟地址空间的，因此同一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换**

## 什么是上下文切换

什么是CPU上下文？
> CPU 寄存器，是CPU内置的容量小、但速度极快的内存。
> 而程序计数器，则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。
> 它们都是 **CPU 在运行任何任务前，必须的依赖环境，因此叫做CPU上下文**。

上下文切换的基本原理就是当发生任务切换时, **保存当前任务的CPU上下文（CPU寄存区与程序计数器）的内容到内存中，然后将下一个即将运行的任务的CPU上下文的内容加载到当前CPU中**，最后再跳转到程序计数器所指的新位置，运行新任务，**同一时刻只允许一个任务独享寄存器**。

在任务切换的过程中是涉及任务上下文的保存和恢复操作，而任务上下文切换操作的性能是衡量操作系统性能的一个重要指标。任务上下文切换指标可以反映出操作系统在多任务环境下的处理能力。

- **上下文切换的内容包括：**
    - **用户级上下文（用户堆栈、数据、共享存储区）**
    - **寄存器上下文（cpu寄存器、程序计数器）**
    - **系统级上下文（内存管理信息（例如页表等）、内核栈、进程控制块）**

## 线程切换过程中，操作系统有什么操作

在每个任务执行前，CPU需要知道从哪里加载，从哪里开始运行，即**需要OS提前设置好CPU寄存器与程序计数器**。
**CPU寄存器与程序计数器即CPU上下文，它们都是CPU在任何任务开始运行前，必须的依赖环境**

- CPU寄存器是CPU内置的容量小、但速度极快的内存
- 程序计数器用来存储CPU正在执行的指令位置，或即将执行的下一条指令的位置


## 线程的分类？

从线程的运行空间来说，分为用户级线程和内核级线程

- **用户级线程**：它仅存在于用户态中，这种线程**不需要内核的支持**，在用户程序中实现
  - 用户级线程利用**线程库来完成其创建和管理**，==用户级线程的线程切换不需要内核的直接参与，速度比较快==，**操作系统内核无法感知用户级线程的存在**。
  - 可以在不支持线程的操作系统中实现
  - 同一进程中只能同时有一个用户级线程在运行，且==一个用户级线程的阻塞将会引起整个进程的阻塞==

- **内核级线程**：这类线程**依赖于内核**，创建、撤销和切换都**由内核**实现，当==内核级线程切换时，由用户态转为内核态，切换完之后又要转回用户态==，可以更好的利用多核CPU
  - **当有多个处理机时，一个进程的多个内核级线程可以同时执行**
  - 内核级线程只有很小的数据结构和堆栈，切换速度快，当然它本身也可以用多线程技术实现，提高系统的运行速率。
    - 当然，还是用户级线程切换更快，它甚至不需要切换到内核态
  - 用户态与内核态的切换比较消耗资源


## java中的线程是内核态的线程吗？

java中的线程并不属于内核态线程，虽然具备内核态和用户态之间切换的特征，但用户也可以通过程序控制，而不是交给OS来控制

线程的底层实现是依赖于宿主操作系统及硬件的。只是一般情况下，现代的CPU及硬件下，java线程在底层的实现是内核级别的（只要它支持）。否则它就是用户级的，甚至可能在单个CPU核心下，它是通过CPU调度CS的（即是虚拟的）。如果是用户级线程，那的确会在I/O中断时，使同一进程内的其他线程都会造成阻塞（因为CPU的调度基本单位是进程）

在HotSpot虚拟机中，规定使用一对一的线程模型，也就是一个用户态线程对应一个内核态线程

## 操作系统fork创建进程的具体流程

`fork()`系统调用用于**创建新进程**，新创建的进程为**子进程**，调用`fork()`并创建新进程的进程是**父进程**。
`fork()`创建的进程与与原来的进程几乎完全相同，这俩个进程拥有同样的代码，但如果初始参数和传入的变量不同，俩个进程也可以完成不同的功能。
`fork()`之后，父子进程并发执行，即执行顺序不固定。

> 父子进程运行的时间： 子进程和父进程是同时执行的。但是输出没有固定的顺序，有可能父进程先输出，也有可能子进程先输出。

`fork()`的流程：
子进程创建后，系统会给子进程分配资源，然后**把原来的进程的所有值都复制到新的子进程中**，只有少数值与原来的进程的值不同；子进程其实就是父进程的一份副本。

但是子进程和父进程**驻留在不同的内存空间上**，**但这些内存空间具有相同的内容**，因此，一个进程执行的任何操作都不会影响其他进程。

> 但是，fork()方法并不会直接将父进程的数据空间复制给子进程，而是**在子进程修改数据空间上的数据时，才会给子进程分配空间**

## 从磁盘进行IO的大致流程

https://zhuanlan.zhihu.com/p/371574406

![](./../images/OS/IO.jpg)

1. 选择合适的IO引擎
   - 即选择sync、psync、vsync等引擎提供的`read`、`write`函数，进行读写，这些引擎会使用系统调用，让OS完成后面的工作
2.  经过系统调用后，切换为内核态，也来到了OS的内核层
   - 系统调用将内核中其它组件的功能进行封装，然后通过接口的形式暴露给用户进程来访问，而读写文件依赖的就是内核中的**VFS内核组件**
3. VFS虚拟文件系统
   - VFS 的思想就是在 Linux 上抽象一个**通用的文件系统模型**，对我们开发人员或者是用户**提供一组通用的接口**，让我们不用 care 具体文件系统的实现。 
   - 抽象的VFS在由操作系统具体实现之后，与Page Cache进行交互
4. Page Cache（页高速缓存）
   - Page Cache位于VFS与文件系统之间，是 Linux 内核使用的主要磁盘高速缓存，可以将一些磁盘上的文件数据保留在内存中，加速磁盘资源访问
   - 当用户要访问的文件的时候，如果**要访问的文件 block 正好存在于 Page Cache 内**，那么 Page Cache 组件直接把数据从内核态拷贝到用户进程的内存中就可以了
     - 如果不存在于Page Cache，则申请一个新页，发出页中断，然后到磁盘读取它
5. 文件系统
   - 文件系统提供对VFS的具体实现，不同的文件系统提供不同的`read`、`write`等函数的操作逻辑
   - 而文件系统又依赖于更底层的通用块层 
6. 通用块层 
   - 对上层的文件系统，通用块层提供一个统一的接口让供文件系统实现者使用，而不用关心不同设备驱动程序的差异，使得文件系统能够应用于任何块设备
7. IO调度层
   - 当通用块层把 IO 请求实际发出以后，并不一定会立即被执行。因为调度层会从全局出发，尽量让整体磁盘 IO 性能最大化。
   - IO调度层负责调度IO请求，并与驱动程序直接交互，由驱动程序进行数据的读取
     > 例如控制HDD的磁头工作、SSD的调度  


## 操作系统执行代码的原理

一行代码能够执行,必须要有可以执行的上下文环境,包括,指令寄存器,数据寄存器,栈空间等内存资源
然后这行代码必须作为一个执行流能够被操作系统的任务调度器识别,并给他分配 CPU 资源,
当然，这行代码所代表的指令必须是 CPU 可以解码识别的
所以一行 Java 代码必须被解释成对应的 CPU 指令才能执行.

Java作为高级语言，是不能直接运行在硬件上的，需要首先经过Java编译，转换为字节码文件，然后由JVM通过类加载器加载字节码文件，通过解释器解释为汇编指令，然后转译为CPU可以识别的机器指令。



## 进程有哪些状态？

进程一共有`5`种状态，分别是创建、就绪、运行（执行）、终止、阻塞。 

![进程五种状态转换图](http://blog-img.coolsen.cn/img/A61F5B5322ED49038C64BDD82D341987)

- 创建状态(new) ：进程正在被创建，尚未到就绪状态。
- 就绪状态(ready) ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
- 运行状态(running) ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
- 阻塞状态(waiting) ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
- 结束状态(terminated) ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。


**运行态→阻塞态**：往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。
**阻塞态→就绪态**：则是等待的条件已满足，只需分配到处理器后就能运行。
**运行态→就绪态**：不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程来抢占处理器等。
**就绪态→运行态**：系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态。

## 进程调度策略有哪几种？

https://blog.csdn.net/qq_34039868/article/details/104977470

* **先来先服务FCFS**：
  * 非抢占式，按照请求的顺序进行调度。
  * 有利于长作业，但不利于短作业，
    * 短作业必须等待前面的长作业执行完毕才能执行
  * 对`I/O`密集型进程也不利，因为这种进程每次进行`I/O`操作之后又得重新排队。

* **短作业优先SJF**：
  * 非抢占式，按**估计运行时间最短**的顺序进行调度。
  * 长作业有可能会饿死
  * **平均等待时间最短、平均周转时间最短**

* **最短剩余时间优先**：
  * 最短作业优先的抢占式版本，按**剩余运行时间**的顺序进行调度。
  * 当一个新的作业到达时，将其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则**挂起当前进程**，运行新的进程。否则新的进程等待。

* **时间片轮转**：
  * 将所有就绪进程按 `FCFS` 的原则排成一个队列，每次调度时，把 一个CPU时间片分配给队首进程
  * 当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并**将它送往就绪队列的末尾**，同时继续把CPU时间片分配给队首的进程。
  - 时间片轮转算法的效率和**时间片大小**有很大关系：因为进程切换的开销较大，如果时间片太小，会导致进程切换得太频繁

* **优先级调度**：
  * 为每个进程分配一个**优先级**，按优先级进行调度。
  * 为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

* **高响应比优先调度算法**：
  * 是FCFS与SJF的平衡，同时考虑每个作业的**等待时间与预估的运行时间**，在每次进行作业调度前计算后背作业队列中每个作业的响应比，选择最高的投入运行
  $响应比R_p=\frac{等待的时间+要求的运行时间}{要求的运行时间}$

* **多级反馈队列调度算法**：
  * 是时间片轮转调度算法与优先级调度算法的综合与发展，通过**动态调整进程优先级与时间片大小**，兼顾多方面的系统目标
  * 设置多个就绪队列，赋予不同的优先级，每个队列中进程执行的时间片大小不同，优先级越高则时间片越小
  * 当一个新进程进入内存，首先放入第1级队列末尾，按FCFS原则等待调度，若它不能在分配的时间片内完成，则转入第二级末尾
  * 当第一级队列为空，转为执行第二级队列中的进程       

* CFS算法（完全公平调度程序，Linux使用的算法）
  * **并不采用严格规则来为一个优先级分配某个长度的时间片，而是为每个任务分配一定比例的CPU处理时间**
    每个任务分配的具体比例取决于**友好值**
      > 友好值取值为`[-20, +19]`，默认为0，友好值越高，优先级越低，对其他进程越友好
      > **数值较低的友好值表示较高的相对优先级，分配更多的CPU处理时间**
  * CFS 调度程序没有直接分配优先级。相反，它通过每个任务的变量 vruntime 以便维护虚拟运行时间，进而记录每个任务运行多久。
    * 虚拟运行时间与**基于任务友好值的衰减因子**有关，更高友好值的任务比更低友好值的任务具有更高衰减速率。
      * 对于正常优先级的任务（友好值为 0），虚拟运行时间与实际物理运行时间是相同的。
      * **友好值越高，则优先级越低，虚拟运行时间越长**
  * **当决定下步运行哪个任务时，调度程序只需选择具有最小虚拟运行时间的任务，即友好值越低的任务**
  * 当一个更低友好值的任务成为可行时，就会抢占高友好值的任务

  * CFS通过**红黑树**进行调度，红黑树最左端的节点是**友好值最低的节点，即优先级最高的节点**，不可运行的任务从红黑树上删除，
http://c.biancheng.net/view/1255.html

## 进程间通信方式有哪些？

https://blog.csdn.net/weixin_39953236/article/details/111061719

分为**消息传递模型**与**共享内存模型**两类：

- 共享内存：共享内存就是**映射一段能被其他进程所访问的内存**，这段共享内存由一个进程创建，但多个进程都可以访问。
  - 共享内存是最快的进程通信方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。
  - 每个进程都有属于自己的**进程控制块（PCB）**和**地址空间（Addr Space）**，并且都有一个与之对应的**页表**，负责**将进程的虚拟地址与物理地址进行映射**，通过内存管理单元（MMU）进行管理。
   ==两个不同的虚拟地址通过页表映射到物理空间的同一区域，它们所指向的这块区域即共享内存==


- 管道：有两种限制，一是**半双工**的通信，**数据只能单向流动**，二是**只能在具有亲缘关系的进程间使用**，进程的亲缘关系通常是指父子进程关系。
  - 匿名管道：单向管道，只能在有亲缘关系的进程间通信；
  - 命名管道：以磁盘文件的方式存在，可以实现本机**任意两个进程通信**。

- 消息队列：消息队列是消息的链表。
  - 消息队列可以实现消息的随机查询，消息**不一定要以先进先出的次序读取**，也可以按消息的类型读取。
  - 比 FIFO 更有优势。消息队列**克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点**。
  - 与管道不同的是：**消息队列存放在内核中**，只有在内核重启或者显示地删除一个消息队列时，该消息队列才会被真正的删除。

- 信号：信号是一种比较复杂的通信方式，信号可以在任何时候发给某一进程，而无需知道该进程的状态。
  - 对一个进程发送一个信号以后，**其实并没有硬中断发生**，只是简单把信号挂载到目标进程的信号 pending 队列上去，信号真正得到执行的时机是**进程执行完异常/中断返回到用户态的时刻**，而正常的进程会频繁地在用户态与内核态之间切换，所以信号能够很快的得到响应

  >  **Linux系统中常用信号**：
  >  （1）**SIGHUP**：用户从终端注销，所有已启动进程都将收到该进程。系统缺省状态下对该信号的处理是终止进程。
  >  （2）**SIGINT**：程序终止信号。程序运行过程中，按`Ctrl+C`键将产生该信号。
  >  （3）**SIGQUIT**：程序退出信号。程序运行过程中，按`Ctrl+\\`键将产生该信号。
  >  （4）**SIGBUS和SIGSEGV**：进程访问非法地址。
  >  （5）**SIGFPE**：运算中出现致命错误，如除零操作、数据溢出等。
  >  （6）**SIGKILL**：用户终止进程执行信号。shell下执行`kill -9`发送该信号。
  >  （7）**SIGTERM**：结束进程信号。shell下执行`kill 进程pid`发送该信号。
  >  （8）**SIGALRM**：定时器信号。 
  >  （9）**SIGCLD**：子进程退出信号。如果其父进程没有忽略该信号也没有处理该信号，则子进程退出后将形成僵尸进程。

- 信号量：信号量是一个**计数器**，可以用来控制多个进程对共享资源的访问。 
  - 它常作为一种**锁机制**，防止某进程正在访问共享资源时，其他进程也访问该资源
  - 因此，主要作为进程间以及同一进程内不同线程之间的同步手段


- Socket：主要用于客户端与服务器之间的网络通信，是支持TCP/IP的网络通信的基本操作单元。

**优缺点**：

* 共享内存：能够很容易控制容量，**速度快**，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存。
  
* 管道：以字符流的形式传输，速度慢，容量有限；

* Socket：任何进程间都能通讯，但速度慢；

* 消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题；

* 信号量：不能传递复杂消息，只能用来同步；


## 进程间同步的方式有哪些？

通信是为了实现数据共享，而同步是为了实现协同处理

1. 临界区：当**多个线程访问一个独占性共享资源**时，可以使用临界区对象。
  - 拥有临界区的线程可以访问被保护起来的资源或代码段，其他线程若想访问，则被挂起，直到拥有临界区的线程放弃临界区为止，以此达到用原子方式操 作共享资源的目的。

2. 互斥量：为协调共同对一个共享资源的单独访问而设计的。互斥对象和临界区对象非常相似，只是**其允许在进程间使用**，而**临界区只限制于同一进程的各个线程之间使用**，但是更节省资源，更有效率。**互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限。**

   - 优点：使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。

   - 缺点：
     * 互斥量是可以命名的，也就是说它可以**跨越进程**使用，所以**创建互斥量需要的资源更多**，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量。

     * 通过互斥量可以指定资源被独占的方式使用，但有时通过互斥就无法处理：
       * 比如现在一位用户购买了一份三个并发访问许可的数据库系统，根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，而作为资源计数器的信号量对象可以实现

3. 信号量：为**控制一个具有有限数量用户资源**而设计。
   - 它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，**当信号量的最大资源数=1就是互斥量**。

   - 优点：适用于对Socket（套接字）程序中线程的同步。
   - 缺点:

     * 信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点；

     * 信号量机制功能强大，但使用时对信号量的操作分散， 而且难以控制，读写和维护都很困难，加重了程序员的编码负担；

     * 核心操作P-V分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严重，且不易发现和纠正。

4. 事件：用来通知线程有一些事件已发生，从而启动后继任务的开始。

   - 优点：事件对象通过通知操作的方式来保持线程的同步，并且可以实现不同进程中的线程同步操作。

区别：

* 互斥量与临界区的作用非常相似，但互斥量是可以命名的，也就是说互斥量可以跨越进程使用，但创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量 。因为互斥量是跨进程的互斥量一旦被创建，就可以通过名字打开它。

* 互斥量，信号量，事件都可以被跨越进程使用来进行同步数据操作。

## 什么是临界区，如何解决冲突？

每个进程中访问临界资源的那段程序称为临界区，**一次仅允许一个进程使用的资源称为临界资源。**

解决冲突的办法：

- 如果有若干进程要求进入空闲的临界区，**一次仅允许一个进程进入**，如已有进程进入自己的临界区，则其它所有试图进入临界区的进程必须等待；
- 进入临界区的进程要在**有限时间内退出**。
- 如果进程不能进入自己的临界区，则应**让出CPU**，避免进程出现“忙等”现象。



## 什么是死锁？死锁产生的条件？

**什么是死锁**：

在两个或者多个并发进程中，如果**每个进程持有某种资源而又等待其它进程释放其保持着的资源**，导致程序的运行不能向前推进，称这一组进程产生了死锁。通俗的讲就是两个或多个进程无限期的阻塞、相互等待的一种状态。

**死锁产生的四个必要条件**：（有一个条件不成立，则不会产生死锁）

- **互斥**条件：一个资源一次只能被一个进程使用
- **请求与保持**条件：一个进程**因请求资源而阻塞**时，对已获得资源保持不放
- **不剥夺**条件：进程获得的资源，在未完全使用完之前，**不能强行剥夺**
- **循环等待**条件：若干进程之间形成一种头尾相接的环形等待资源关系

## 如何处理死锁问题

常用的处理死锁的方法有：死锁预防、死锁避免、死锁检测、死锁解除、鸵鸟策略。

**（1）死锁的预防：**基本思想就是确保死锁发生的四个必要条件中至少有一个不成立：

> - 破除资源互斥条件
> - 破除“请求与保持”条件：实行资源预分配策略，进程在运行之前，必须一次性获取所有的资源。缺点：在很多情况下，无法预知进程执行前所需的全部资源，因为进程是动态执行的，同时也会降低资源利用率，导致降低了进程的并发性。
> - 破除“不可剥夺”条件：允许进程强行从占有者那里夺取某些资源。当一个已经保持了某些不可被抢占资源的进程，提出新的资源请求而不能得到满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。这意味着进程已经占有的资源会被暂时被释放，或者说被抢占了。
> - 破除“循环等待”条件：实行资源有序分配策略，对所有资源排序编号，按照顺序获取资源，将紧缺的，稀少的采用较大的编号，在申请资源时必须按照编号的顺序进行，一个进程只有获得较小编号的进程才能申请较大编号的进程。

**（2）死锁避免：**

死锁预防通过约束资源请求，防止4个必要条件中至少一个的发生，可以通过直接或间接预防方法，但是都会导致低效的资源使用和低效的进程执行。
而死锁避免则**允许前三个必要条件，但是通过动态地检测资源分配状态，以确保循环等待条件不成立**，从而确保系统处于**安全状态**。
所谓安全状态是指：**如果存在某种资源分配顺序，可以保证不出现死锁，那么系统状态是安全的**，换句话说就是，如果存在一个安全序列，那么系统处于安全状态。银行家算法是经典的死锁避免的算法。

**（3）死锁检测：**

死锁预防策略是非常保守的，他们通过限制访问资源和在进程上强加约束来解决死锁的问题。
死锁检测则是完全相反，它不限制资源访问或约束进程行为，只要有可能，被请求的资源就被授权给进程。但是**操作系统会周期性地执行一个算法检测前面的循环等待的条件**。
死锁检测算法是通过资源分配图来检测是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有存在环，也就是检测到死锁的发生。

> - 如果进程-资源分配图中无环路，此时系统没有死锁。 
> - 如果进程-资源分配图中有环路，且每个资源类中只有一个资源，则系统发生死锁。 
> - 如果进程-资源分配图中有环路，且所涉及的资源类有多个资源，则不一定会发生死锁。

**（4）死锁解除：**

死锁解除的常用方法就是**终止进程和资源抢占**，回滚。所谓进程终止就是简单地终止一个或多个进程以打破循环等待，包括两种方式：终止所有死锁进程和一次只终止一个进程直到取消死锁循环为止；所谓资源抢占就是从一个或者多个死锁进程那里抢占一个或多个资源。

**（5）鸵鸟策略：**

把头埋在沙子里，假装根本没发生问题。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任何措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。

## 内存的分配方式有哪些

- **连续分配管理方式**：即为一个用户程序分配一块连续的内存空间，例如块式管理
  - 块式管理：将内存分为几个固定大小的块，每个块中只包含一个进程。 
     如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。
     - 这些在每个块中未被利用的空间，我们称之为碎片。

- **非连续分配管理方式**：允许一个程序使用的内存分布在离散或者说不相邻的内存中，划分为：基本分页管理方式、基本分段管理方式、段页式管理方式
  - 页式管理：把主存分为大小相等且固定的一页一页的形式，页较小，相比于块式管理的划分粒度更小，提高了内存利用率，减少了碎片。
    - 通过页表对应逻辑地址与物理地址
  - 段式管理：把内存按照实际意义划分为一段一段的，每一段定义了一组逻辑信息
    - 通过段表对应逻辑地址与物理地址
  - 段页式管理：结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页

## 什么是分页？

把内存空间划分为**大小相等且固定的块**，作为主存的基本单位。
因为程序数据存储在不同的页面中，而页面又离散的分布在内存中，**因此需要一个页表来记录映射关系，以实现从页号到物理块号的映射，即页表**

访问分页系统中内存数据需要**两次的内存访问** (一次是**从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址**；第二次就是**根据第一次得到的物理地址访问内存取出数据**)。

![](http://blog-img.coolsen.cn/img/image-20210610173249387.png)

> 与分区的区别
> 每个进程也以块为单位进行划分，进程执行时，以块为单位地逐个申请主存中的块空间，形式上像分区相等的固定分区技术，**但由于块比分区小很多，分页管理不会产生外部碎片**

## 单级页表的缺点

为了提高内存利用率，减少内存碎片的产生，应当将每一页分的尽量小，但**内存空间中的每一页都需要在页表里有一个项与其对应**，即单级页表需要维护**整个内存空间的映射**，就会**导致页表过大**，浪费内存（存放页表的内存是不能给程序使用的，一直存放在进程PCB中），且大部分情况下，进程只需要几十MB的内存，剩下的逻辑地址很少被用到，造成了浪费。

 计算机根据页号查询页表的方法：K号页对应的页表项存在的位置 = 页表初始地址 + K * 页表项长度
 因此，==必须让所有页表项连续存放，并让整个页表常驻于内存==
 > 保存在主存中的页表承担的职责是**将虚拟地址翻译成物理地址**；假如**虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了**
 > 所以==页表一定要覆盖全部虚拟地址空间==

## 多级页表与快表是什么

为了克服单级页表浪费内存的缺点，提出了**多级页表**。
在多级页表中，**常驻于内存的不是庞大的类似单级页表的二级页表，而是其页目录：一级页表**

多级页表的结构如下图所示：

![](../images/OS/多级页表.jfif)

其中，一个逻辑地址由**10bits的页目录号**+**10bits的页号**+**12bits的页内偏移**组成

> 页内偏移取决于一个页面能够映射多大的内存：12bit对应`4KB `的内存（计算机按字节寻址）

这种方式能节省大量内存；并且保证了章目录和节目录都是连续的，这就意味着可以使用偏移量的形式查找对应的页

 **多级页表为什么能节省内存？在已有的页表项的基础上再建立一级页表，不是更消耗空间吗？**
 单级页表中，需要对整个内存空间的所有页面建立页表项，且页表项需要连续存储，并常驻于CPU中，但大部分内存空间实际上是用不到的，就导致了空间浪费
 而多级页表的改进可以从两方面出发：
 1. **二级页表可以懒惰初始化**
   大多数程序用不到4G的内存空间，没必要映射那些不可能用到的空间
   也就是说：只通过一级页表覆盖4GB的内存空间，且只在需要时才创建二级页表，不使用则不创建
 
 2. **二级页表可以不常驻于主存**
   其实就是把页表当做页面来处理，将二级页表存储在磁盘中，需要用到时发出**缺页中断**，从磁盘中取
   且根据局部性原理，虚拟地址存在局部性，其对应的二级页表也存在局部性，所以二级页表只有局部会被经常使用

**多级页表的缺点：**
- 每一次访问时，都要**根据一级页表找到找到页目录，再根据二级页表找到具体的页，然后去读取**。
 也就是需要**访问三次内存**；cpu每一条指令执行的时间其实大部分都是浪费在访问内存上，cpu的执行速度是非常快的，就导致**访问内存的时间占了大部分**

为此，进一步引入**相连快速存储TLB（快表）**

TLB可以直接理解为**页式内存管理的高速缓存**，用于加速虚拟地址到物理地址的转换。
TLB位于CPU与内存之间，TLB是一组寄存器，用来**存放最近使用过的页对应的页框号**；这样如果CPU需要访问某一页首先在TLB里面找，如果TLB里面有就不用访问内存了，且TLB的访问速度远高于内存。

原理：当使用TLB，有时**只要访问一次高速缓存器**，就可以得到所需页对应的页框号，**只需要再访问一次内存**，这样就可以加速查找并提高指令执行速度
   > 单级页表需要访问两次内存，多级页表则更多了
 
 使用快表之后的地址转换流程：
 
 1. 根据虚拟地址中的页号查找快表
 2. 若该页在块表中，则**直接从块表中读取对应的物理内存地址**
 3. 若该页不在快表中，则访问内存中的**页表**，再从页表中读取物理地址，同时将该页表中的物理地址映射到快表中
 4. 当块表填满时，又要增加新的页表，就按照一定的淘汰策略删掉一页
 
 总结：块表就是一个作为页表的高速Cache，存储着页表的内容，地址转换先查块表

## 什么是分段？

**分页是为了提高内存利用率**
**分段除了为了提高内存利用率之外，也是为了满足程序员在编写代码的时候的一些逻辑需求(比如数据共享，数据保护，动态链接等)**

分段内存管理当中，每个段都拥有自己的名字，但为了方便，直接用段号替代。
**其逻辑地址是二维的，一维是段号，二维是段内地址；其中每个段的长度是不一样的，而且每个段内部都是从0开始编址的**。
由于分段管理中，**每个段内部是连续内存分配，但是段和段之间是离散分配的**，因此也存在一个逻辑地址到物理地址的映射关系，相应的就是段表机制。

![](http://blog-img.coolsen.cn/img/image-20210610173410509.png)

## 分页和分段有什么共同点与区别？

共同点：
- 分页和分段都是为了提高内存利用率，减少内存碎片
- 存储方式都是离散存储，但**页内与段内是连续的**

区别：
- 分页对程序员是透明的，但是分段需要程序员显式划分每个段。 
- 分页的地址空间是一维地址空间，分段是二维的。 
- 页的大小不可变，段的大小可以动态改变。 
- 分页主要用于实现虚拟内存，从而获得更大的地址空间，并实现非连续分配；
  - 分段主要是为了**使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护**，段是逻辑信息的单位，具有具体的意义。

## 段页式存储方式

段页式存储管理方式融合了分段与分页，**首先对内存空间进行分段，在每一个段内，通过分页的方式进行内存空间的划分**

## 逻辑地址与物理地址分别是什么

逻辑地址即**虚拟地址**，我们在编程时一般都是接触逻辑地址，例如C中的指针，指向内存中的一个地址，而这个地址由OS决定

物理地址即真实物理内存中的地址

## 了解CPU寻址吗，为什么需要虚拟地址空间

现代处理器使用的是一种称为 **虚拟寻址** 的寻址方式。
> 使用虚拟寻址，CPU需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。

实际上，完成虚拟地址到物理地址的转换的硬件就是CPU中的 **内存管理单元（MMU）**

使用虚拟寻址的原因：
如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害，以及**给同时运行多个程序造成困难**。
> 在多个程序中，如果使用了相同的真实地址，会导致先赋值的被后赋值的覆盖

通过虚拟地址访问内存有以下优势：
- 程序可以使用一系列**相邻的虚拟地址**来访问物理内存中**不相邻的大内存缓冲区**
- 程序可以使用一系列**虚拟地址**来访问**大于可用物理内存的内存缓冲区**。
  当物理内存的供应量变小时，内存管理器会**将物理内存页（通常大小为 4 KB）保存到磁盘文件**。**数据或代码页会根据需要在物理内存与磁盘之间移动**。
    - 即通过磁盘来扩充内存，依赖于磁盘的读写速度
- 不同进程使用的虚拟地址彼此**隔离**。
  **一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存**。从而便于多个程序同时执行

## 为什么虚拟地址空间切换会比较耗时？

进程都有自己的虚拟地址空间，把虚拟地址转换为物理地址需要查找页表，而页表查找是一个很慢的过程，因此通常使用快表来缓存常用的地址映射。

由于每个进程都有自己的虚拟地址空间，那么显然每个进程都有自己的页表，那么**当进程切换后页表也要进行切换，==页表切换后TLB就失效==了**，Cache失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢，

**线程切换则不会导致TLB失效，因为线程无需切换地址空间**，因此我们通常说**线程切换要比较进程切换快**，原因就在这里。

## 什么是虚拟内存？

虚拟内存技术使得应用程序认为它拥有**4G的连续的虚拟地址空间**，然而实际上，这个地址空间是不存在的，只是进程**认为**自己拥有4G的连续内存
而实际上，进程用了多少空间，操作系统就在内存上划出多少空间给它，等到进程真正运行的时候，需要某些数据并且数据不在物理内存中，才会触发缺页中断，进行数据拷贝

除此之外，虚拟内存技术，从而让程序获得更多的可用内存。
虚拟内存使用==部分加载==的技术，**让物理内存扩充成更大的逻辑内存**，即**让一个进程或者资源的某些页面加载进内存，从而能够加载更多的进程，甚至能加载比内存大的进程，如果内存中缺少某些数据，再去磁盘中取**。

虚拟内存的作用：
- 扩大了逻辑内存
  - 通过部分加载技术，只加载进程当前需要的数据到内存，**没有时产生缺页中断**
- 简便的内存管理
  - 每个进程拥有独立的页表，即独立的虚拟内存空间，不会互相干扰，也便于编码时的内存管理
- 内存保护
  - 向用户屏蔽了内存的细节，防止用户直接读写某些不具备权限的内存数据

实际上，虚拟内存对应的就是linux中的swap分区


## 什么是交换空间？

操作系统把物理内存(physical RAM)分成一块一块的小内存，每一块内存被称为**页(page)**。当内存资源不足时，**Linux把某些页的内容转移至硬盘上的一块空间上，以释放内存空间**。硬盘上的那块空间叫做**交换空间**(swap space),而这一过程被称为交换(swapping)。**物理内存和交换空间的总容量就是虚拟内存的可用容量。**

用途：
- 物理内存不足时一些不常用的页可以被交换出去，腾给系统。
- 程序启动时很多内存页被用来初始化，之后便不再需要，可以交换出去。

## 虚拟内存的实现方式有哪些?

虚拟内存中，允许将一个作业分多次调入内存。
釆用连续分配方式时，会使相当一部分内存空间都处于暂时或`永久`的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量。
因此，虚拟内存的实需要建立在**离散分配的内存管理方式**的基础上。虚拟内存的实现有以下三种方式：

- 请求分页存储管理
- 请求分段存储管理
- 请求段页式存储管理

而无论哪种技术，都有以下三个必要条件：
- 一定容量的内存与外存
- 缺页中断
  > 若需要执行的程序未在内存中（即“缺页/段”），则处理器会通知操作系统将相应的页/段调入到内存中，与此同时也会将不常用的页/段调出到外外存中
- 虚拟地址空间
  > 只有在虚拟地址空间技术的基础上，操作系统才能使得程序分多次将数据调入内存

## 页面替换算法有哪些？ 

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

![image-20210807152232136](http://blog-img.coolsen.cn/img/image-20210807152232136.png)

- `最优置换算法 OPT`：置换**以后最长时间内不再访问的页面**。
  - 不幸的是，没有办法来判定哪个页面是最后一个要访问的，`因此实际上该算法不能使用`。然而，它可以作为衡量其他算法的标准。
- `先入先出算法FIFO` ：置换最早进入内存中的页面
  - 但有可能删除**存在时间最长但是还在使用**的页面，因此这个算法也不是一个很好的选择
- `最近最久未使用算法LRU` ：置换最久没有使用的页面
  - 但是没有`特殊的硬件(TLB)`很难实现。如果没有硬件，就不能使用 LRU 算法。
- `第二次机会算法`
  - 对 FIFO 的一个修改，它会**在删除页面之前检查这个页面是否仍在使用**。
  - 如果页面正在使用，就会进行保留。这个改进大大提高了性能。
- `时钟置换算法`
  - 即最近未用（NRU）算法，是第二次机会算法的另外一种实现形式，时钟算法和第二次算法的性能差不多，但是会花费更少的时间来执行算法

**最好的算法是老化算法和WSClock算法**。他们分别是基于 LRU 和工作集算法。他们都具有良好的性能并且能够被有效的实现。还存在其他一些好的算法，但实际上这两个可能是最重要的。

## 物理地址、逻辑地址、有效地址、线性地址、虚拟地址的区别?

物理地址就是内存中真正的地址，它就相当于是你家的门牌号，你家就肯定有这个门牌号，具有唯一性。**不管哪种地址，最终都会映射为物理地址**。

在`实模式`下，段基址 + 段内偏移经过地址加法器的处理，经过地址总线传输，最终也会转换为`物理地址`。

但是在`保护模式`下，段基址 + 段内偏移被称为`线性地址`，不过此时的段基址不能称为真正的地址，而是会被称作为一个`选择子`的东西，选择子就是个索引，相当于数组的下标，通过这个索引能够在 GDT 中找到相应的段描述符，段描述符记录了**段的起始、段的大小**等信息，这样便得到了基地址。如果此时没有开启内存分页功能，那么这个线性地址可以直接当做物理地址来使用，直接访问内存。如果开启了分页功能，那么这个线性地址又多了一个名字，这个名字就是`虚拟地址`。

不论在实模式还是保护模式下，段内偏移地址都叫做`有效地址`。有效地址也是逻辑地址。

线性地址可以看作是`虚拟地址`，虚拟地址不是真正的物理地址，但是虚拟地址会最终被映射为物理地址。下面是虚拟地址 -> 物理地址的映射。

![image-20210807152300643](http://blog-img.coolsen.cn/img/image-20210807152300643.png)


## 什么是缓冲区溢出？有什么危害？

缓冲区溢出是指当计算机向缓冲区填充数据时超出了缓冲区本身的容量，**溢出的数据覆盖在合法数据上**

危害有以下两点：

- 程序崩溃，导致拒绝服务
- 跳转并且执行一段恶意代码

造成缓冲区溢出的主要原因是程序中没有仔细检查用户输入。


## Unix 常见的IO模型：

对于一次IO访问（以read举例），数据会**先被拷贝到操作系统内核的缓冲区**中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：

> - 等待数据准备就绪 (Waiting for the data to be ready)
> - 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)

正式因为这两个阶段，linux系统产生了下面五种网络模式的方案：

> - 阻塞式IO模型(BIO，blocking IO model)
> - 非阻塞式IO模型(NIO，noblocking IO model)
> - IO多路复用式模型(IO multiplexing model)，亦称Event Driven IO
> - 信号驱动式IO模型(signal-driven IO model)
> - 异步IO式IO模型(AIO，asynchronous IO model)

对于这几种 IO 模型的详细说明，可以参考这篇文章：https://juejin.cn/post/6942686874301857800#heading-13

其中，IO多路复用模型指的是：使用单个进程同时处理多个网络连接IO，他的原理就是select、poll、epoll 不断轮询所负责的所有 socket，当某个socket有数据到达了，就通知用户进程。该模型的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。

## select、poll 和 epoll 之间的区别?

（1）select：时间复杂度 O(n)

当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。
select 仅仅知道有 I/O 事件发生，但并不知道是哪几个流，所以只能无差别轮询所有流，找出能读出数据或者写入数据的流，并对其进行操作。所以 select 具有 O(n) 的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。

（2）poll：时间复杂度 O(n)

poll 本质上和 select 没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个 fd 对应的设备状态， 但是它没有最大连接数的限制，原因是它是基于链表来存储的。

（3）epoll：时间复杂度 O(1)

epoll 可以理解为 event poll，不同于忙轮询和无差别轮询，epoll 会把哪个流发生了怎样的 I/O 事件通知我们。所以说 epoll 实际上是事件驱动（每个事件关联上 fd）的。

> select，poll，epoll 都是 IO 多路复用的机制。I/O 多路复用就是通过一种机制监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），就通知程序进行相应的读写操作。但 select，poll，epoll 本质上都是同步 I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步 I/O 则无需自己负责进行读写，异步 I/O 的实现会负责把数据从内核拷贝到用户空间。



## 讲一讲IO多路复用？

IO多路复用是指**内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。IO多路复用适用如下场合**：

- 当客户处理多个描述字时（一般是交互式输入和网络套接口），必须使用I/O复用。
- 当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。
- 如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。
- 如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。
- 如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。
- 与多进程和多线程技术相比，I/O多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销。

## 输入URl后，操作系统做了什么事情？Socket过程描述三次握手？

https://blog.csdn.net/weixin_51601437/article/details/118852370?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-1.pc_relevant_default&spm=1001.2101.3001.4242.2&utm_relevant_index=4
https://blog.csdn.net/weixin_43902449/article/details/105523383

## 是不是计算机通过加核的方式以及其它所有硬件资源都无限制就可以解决无法处理的任务？


## 父进程的文件描述符和子进程共享吗

共享，父子进程都是从同一个文件描述符中读取数据，并且，相互更新偏移量

> 文件表项只有在所有引用它的fd（即文件描述符）**全部关闭**的情况下才会真正关闭。
> 如果子进程关闭父、子进程共享的文件描述符，所以子进程关闭后，父进程仍可以使用对应的文件表项

## 文件描述符具体是什么东西

Linux 中一切都可以看作文件，包括普通文件、链接文件、Socket 以及设备驱动等，对其进行相关操作时，都可能会创建对应的文件描述符。
文件描述符（file descriptor）是内核为了**高效管理已被打开的文件所创建的索引，用于指代被打开的文件，对文件所有 I/O 操作相关的系统调用都需要通过文件描述符**。

而实际上，**文件描述符仅仅是文件描述符表的下标**，通过文件描述符，就可以找到文件描述符表中对应的内容，也节省了存储空间（使用文件描述符表中元素时，只需要下标即可）

> 每一个进程都有一个数据结构 `task_struct`，该结构体里有一个指向「文件描述符数组」的成员指针。
> 该数组里列出这个进程打开的所有文件的文件描述符，文件描述符就是该数组的下标，是一个非负整数，而数组的内容是一个指针，指向内核中所有打开的文件的列表，也就是说**内核可以通过文件描述符找到对应打开的文件**

![](../images/OS/文件描述符.jpg)

- **进程级别的文件描述符**：每一个进程都有一个数据结构 `task_struct`，该结构体里有一个指向文件描述符表的成员指针，内核为**每个进程**维护一个文件描述符表，记录了文件描述符与指向打开文件表中的指针
- **系统级别的打开文件表**：内核对**所有打开文件**维护的一个进程共享的打开文件描述表，表中存储了处于打开状态文件的相关信息，包括**文件类型、访问权限、文件操作函数**等
- **系统级别的inode表**：记录了文件的相关信息，包括文件长度，文件所在设备，文件物理位置，创建、修改和更新时间等



# Linux

## Linux、Windows的开机流程



## linux文件有哪些属性

Linux系统中，文件或目录的属性主要包括：
- 文件或目录的索引节点（inode）号
- 文件类型与权限
- 硬链接数
- 所归属的用户和用户组
- 文件或目录的大小
- 最近修改时间
- 文件或目录名

## Linux中的inode指的是什么

inode中文意思是索引节点，每个存储设备或存储设备的分区（存储设备可以是硬盘、U盘....）被格式化为文件系统后，都应该有两部分：一部分是inode，另一部分是Block。
Block是用来存储数据用的。而inode就是用来存储这些数据信息的，这些信息包括文件大小、属主、归属的用户组、读写权限。

inode为每个文件进行信息索引，所以就有了inode的数值。操作系统根据指令，能通过inode值最快的找到相对应的文件。

硬盘的最小存储单位是扇区（Sector），块（Block）由多个扇区组成。文件数据存储在块中。块的最常见大小为4Kb，约为8个连续的扇区组成（每个扇区512字节）。一个文件可能占据多个Block，但一个Block只能存放一个文件

由于文件是保存在Block中的，我们还需要一个空间来存储文件的元信息metadata：例如文件被分为几块存储，每一块所在的地址，文件的拥有者，创建时间，权限，大小等。这种存储文件元信息的区域就叫inode，即i(ndex) node，每个文件有一个inode。

可以通过stat命令查看文件的inode信息，Linux\Unix系统不使用文件名区分文件，而是使用inode区分文件。

## 硬链接和软链接有什么区别？

- 硬链接就是在目录下创建一个条目，记录着文件名与 `inode` 编号，这个 `inode` 就是源文件的 `inode`。删除任意一个条目，文件还是存在，只要引用数量不为 `0`。但是硬链接有限制，它不能跨越文件系统，也不能对目录进行链接。
- 符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 `Windows` 的快捷方式。当源文件被删除了，链接文件就打不开了。因为记录的是路径，所以可以为目录建立符号链接。

## 二进制文件与文本文件的区别

- 文本文件
包含用户可读信息的文件。这些文件以**ASCII**码方式存储，可显示和打印。
文本文件的行不能包括空字符(即码中的NULL)，行的最大长度(包括换行符在内)也不能超过(LINE_MAX)所定义的字节数。
不过文本文件中并不限制使用除空字符以外的控制字符或其它不可打印字符。

- 二进制文件（实际上应该叫非文本文件）
二进制文件是包含计算机可读信息的文件。二进制文件可以是可执行的文件，使系统根据其中的指令完成某项工作。
命令和程序都是以可执行的而进制文件方式存储。
二进制文件没有行的长度限制，也可包含空字符。

## linux 执行二进制文件过程（直到加载到CPU）

https://www.cnblogs.com/icecri/p/4438351.html
## 什么是僵尸进程

僵尸进程是**已经完成且处于终止状态，但在进程表中仍然存在的进程**。
僵尸进程通常存在于**父子关系**的进程中，子进程先于父进程退出，同时父进程太忙了，无瑕回收子进程的资源，子进程残留资源（PCB）存放于内核中，变成僵尸（Zombie）进程

僵尸进程的罪魁祸首是父进程没有回收它的资源，可以直接杀死父进程，init 进程就会很善良地把那些僵尸进程领养过来，并合理的回收它们的资源，那些僵尸进程就得到了妥善的处理了

## 讲几个熟悉的指令


## top命令中，各个指标是什么意思


## 查找文件中美团二次出现的次数？kill -9和kill -15 应用场景？查看某个端口是否被占用？netstat是用来干什么的？关闭服务器命令？查找服务器大于100M的日志并且删除？


## 创建一个文件夹并在其里面创建文件、查看文件、修改权限（命令含义）、统计行数，grep使用方法，管道用法？查看内存使用情况、查看磁盘使用情况


## 除了用top，还能怎么看内存使用情况

- htop
- `cat /proc/meminfo`
- `free -h`：

## Linux是怎么解包的，你刚才讲到里面有两个过程，一个是中断，一个是复制，你会怎么处理这两个过程，使其加速？


## 管道符的作用

管道符的作用是将前一条命令的结果作为后一条命令的输入

## 硬链接与软连接

创建语句：`ln -s 源文件 目标文件`

![](./../images/linux/硬链接.png)

硬链接访问步骤(以访问/root/test为例)：
1. 找到**根目录的inode**，判断用户是否有权限读取对应block
2. 如果有，在**根目录的block**中找到**1/root的文件名与对应的inode号**
3. 通过/root/目录的**inode号**，查找/root/目录的**inode信息**，判断用户是否有权限读取block
4. 如果有，在/root/目录的**block**中读取test文件的文件名与相应inode
5. 通过test文件的inode号，找到对应的inode信息，判断用户权限
6. 如果有，读取block中数据，完成访问

硬链接的特点：
- 不论是修改源文件，还是硬链接文件，都会同步的修改另一个文件
- 不论是删除源文件，还是硬链接文件，只要还有一个文件存在，这个文件都可以被访问
- 不会建立新的inode信息，也不会改变inode总数（==源文件和硬链接文件的inode是一样的==）
- 不能跨文件系统（分区）简历，因为在不同的文件系统里，inode是重新计算的
- 不能链接目录，因为如果给目录建立硬链接，需要对目录下的所有文件建立硬链接

![](./../images/linux/软连接.png)

软链接访问步骤(以访问/root/test为例)：
就是首先用类似的方法，找到链接文件的inode，读取对应block，发现block里存的是源文件的inode号，从而找到源文件

软链接的特点：
- 修改、删除软链接文件，不影响源文件
- 软链接会建立自己的inode和block，block中存储源文件的文件名与inode号
- 可以链接目录
- 可以跨分区


## 用户缓冲区与内核缓冲区是什么

![](./../images/OS/用户缓冲区.png)

- 用户进程缓存区：可以理解为内存数组，即在当前线程开辟的一块虚拟内存空间。
   - 目的是为了减少系统调用次数，从而降低操作系统在用户态与核心态切换所耗费的时间
- 内核缓冲区：
  - 用户从磁盘读取数据时，内核一般不直接读取硬盘，而是将内核缓冲区中的数据复制到进程缓冲区中。
  - `read`是把数据从内核缓冲区复制到用户进程缓冲区，write是把进程缓冲区复制到内核缓冲区。
    - 当然，`write`并不一定导致内核的写动作（不等价于写入磁盘），比如os可能会把内核缓冲区的数据积累到一定量后，再一次写入。
    - 这也就是为什么断电有时会导致数据丢失。所以说内核缓冲区，是为了在OS级别，提高磁盘IO效率，优化磁盘写操作。