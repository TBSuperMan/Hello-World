# 计算机网络

## 计算机网络的各层协议及作用？

计算机网络体系可以大致分为以下三种，OSI七层模型、TCP/IP四层模型和五层模型。

* OSI七层模型：大而全，但是比较复杂、而且是先有了理论模型，没有实际应用。
* TCP/IP四层模型：是由实际应用发展总结出来的，从实质上讲，TCP/IP只有最上面三层，最下面一层没有什么具体内容，TCP/IP参考模型没有真正描述这一层的实现。
* 五层模型：五层模型只出现在计算机网络教学过程中，这是对七层模型和四层模型的一个折中，既简洁又能将概念阐述清楚。

![计算机网络体系结构](http://blog-img.coolsen.cn/img/image-20210519165421341.png)

七层网络体系结构各层的主要功能：

- **应用层**：**为应用程序提供交互服务**。在互联网中的应用层协议很多，如域名系统DNS，支持万维网应用的HTTP协议，支持电子邮件的SMTP协议等。
- **表示层**：主要**负责数据格式的转换**，如加密解密、转换翻译、压缩解压缩等。
- **会话层**：负责**在网络中的两节点之间建立、维持和终止通信**，如服务器验证用户登录便是由会话层完成的。
- **运输层**：有时也译为**传输层**，向主机进程提供**通用的数据传输服务**。该层主要有以下两种协议：
  - TCP：提供面向连接的、可靠的数据传输服务；
  - UDP：提供无连接的、尽最大努力的数据传输服务，但不保证数据传输的可靠性。

- **网络层**：**选择合适的路由和交换结点**，确保数据及时传送。主要包括IP协议、ARP协议、ICMP、IGMP。
- **数据链路层**：数据链路层通常简称为链路层。将网络层传下来的IP数据包组装成帧，并再相邻节点的链路上传送帧。
  - 主要包含CSMA/CD协议、PPP协议

- **物理层**：实现相邻节点间**比特流的透明传输**，尽可能屏蔽传输介质和通信手段的差异。

在TCP/IP四层协议栈中，其省略了部分细节：
- 将应用层、表示层、会话层同一封装为应用层
  - 都是与应用程序会话建立强相关的层
- 将物理层与数据链路层封装为网络接口层，对网络协议栈进行了简化，
  - 都是提供基础的网络数据传输服务的层

除此之外，还有运输层与网际层，分别明确了：
- 怎样传输数据
- 将数据传输到哪里

而五层模型则是将网络接口层重新分化为数据链路层与物理层，既保留了底层的细节，又省略了高层的琐碎的点。

## 在五层模型中，各层分别有哪些主要协议，分别有哪些设备

- 物理层：
  - 物理层
- 数据链路层
    - 基本任务：
        - **封装成帧**：将网络层传下来的分组添加首部与尾部，用于标记帧的开始和结束
        - **差错检测**：使用循环冗余检验（CRC）来检查比特错，**比特流在物理层传输时，是非常容易出现误差的，因此在物理层之上引入数据链路层，向网络层提供高质量的数据传输服务**
        - **透明传输**：让用户察觉不到转义符（防止IP数据报中有和首部、尾部相同的字符）
    - 主要协议
        **CSMA/CD协议**：载波监听多点接入/碰撞检测协议
            - 多点接入：在总线型网络中，主机以多点的方式接入到总线上
            - **载波监听**：**每个主机不停的监听信道，在发送前如果检测到信道忙，则必须等待**
            - **碰撞检测**：在发送中，如果监听到已有其他主机正在发送数据，就代表发生了碰撞。（尽管发送前在监听，但由于电磁波的传播时延等因素，还是会碰撞）
        **PPP协议**：用户计算机和 ISP 进行通信时所使用的数据链路层协议
    - MAC地址：**链路层地址**，长6字节，用于唯一标识网络适配器（网卡）
    - 设备：
      - 交换机：具有自学习能力的设备，替代物理层的集线器，不会发生碰撞，根据MAC地址进行转发

- 网络层
  - **IP协议**
    - IP数据报的首部为==20B==
      **版本**：IPV4与V6
      **首部长度**：首部有一个可变部分
      **总长度**：首部长度与数据长度
      **生存时间**：TTL，以路由器跳数为单位
      **协议**：携带的数据应当上交给哪个协议处理（例如ICMP、TCP）
      **标识与片偏移**：在分片时，相同数据报的不同分片具有相同的标识符
    - IP地址编址的发展
      第一阶段：地址分类；**IP地址={网络号，主机号}**，不同分类具有不同网络号长度
      第二阶段：子网划分；**IP地址={网络号，子网号，主机号}**，必须使用子网掩码（外部网络看不到子网的存在）
      第三阶段：无分类编址CIDR；**IP地址={网络前缀号，主机号}**，网络前缀(子网掩码)的长度可变，从而在路由表中只需要一个路由就可以代表原先的多个路由
  - **ARP协议（地址解析协议，广播）**
    ARP协议的作用：**由IP地址得到MAC地址**
    每个主机都有一个 **ARP 高速缓存**，里面有本局域网上的各主机和路由器的 **IP 地址到 MAC 地址的映射表**
    如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过**广播**的方式发送**ARP请求分组**，主机 B 收到该请求后会发送**ARP响应分组**给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射

  - **ICMP协议（网际控制报文协议）**

    功能：**确认IP包是否成功到达目标地址，通知在发送过程中IP包被丢弃的原因**
    ICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议。
    ICMP 报文分为**差错报告报文**和**询问报文**
    - PING：向目的主机发送ICMP Echo请求报文，受到ICMP Echo回答报文。PING根据时间和成功响应的次数估算数据包的往返时间以及丢包率
      
    - 虚拟专用内网（VPN）：将{`10.0.0.0~10.255.255.255`；`172.16.0.0~172.31.255.255`；`192.168.0.0~192.168.255.255`}作为内网专用地址块。
    > VPN 使用公用的互联网作为本机构各专用网之间的通信载体。专用指机构内的主机只与本机构内的其它主机通信；虚拟指好像是，而实际上并不是，它有经过公用的互联网。
    > ![](../images/计网/VPN.jfif)
    > 上图中，场所 A 和 B 的通信经过互联网，如果场所 A 的主机 X 要和另一个场所 B 的主机 Y 通信，IP 数据报的源地址是 10.1.0.1，目的地址是 10.2.0.3。数据报先发送到与互联网相连的路由器 R1，R1 对内部数据进行加密，然后重新加上数据报的首部，源地址是路由器 R1 的全球地址 125.1.2.3，目的地址是路由器 R2 的全球地址 194.4.5.6。路由器 R2 收到数据报后将数据 部分进行解密，恢复原来的数据报，此时目的地址为 10.2.0.3，就交付给 Y。

    - 网络地址转换NAT：
        专用网内部的主机使用本地 IP 地址又想和互联网上的主机通信时，可以使用 NAT 来将本地 IP 转换为全球 IP。
        NAT在进行地址替换时不仅仅包含IP地址，还有端口号。NAT的端口号和局域网中的主机一一对应，同时NAT设备维护一张端口号和主机对应的表。

  - **IGMP协议（网际组管理协议）**
  - 路由器
    路由器的功能包含路由选择与分组转发
    路由器会根据数据报首部中的目的主机IP地址，得到目标网络的地址，并根据路由表中的表项进行数据报的转发
- 运输层
  - **TCP**
    TCP是**面向连接的，提供可靠交付，有流量控制、拥塞控制，提供点对单全双工通信**，面向**字节流**（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块）
    TCP首部为==20B==，包含源与目的端口号、序号（对字节流进行编号）、确认号（期望受到的下一个报文段的序号）、数据偏移（即首部长度）、用于握手与挥手的确认ACK、同步SYN、终止FIN
  - **UDP**
    UDP是**无连接的，尽最大可能交付，没有拥塞控制**，面向**报文**（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部）
    UDP首部为==8B==，包括源与目的端口号、长度、校验和。
- 应用层
  - **DNS**
    DNS是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务，大多数情况采用UDP进行传输，分别使用迭代式与递归式的传输方法
  - **DHCP**
    DHCP提供了即插即用的联网方式，用户不需要手动配置IP、子网掩码等信息

除此之外，**RIP基于UDP，OSPF基于IP，BGP基于TCP，这些在TCP/IP协议栈中定义的路由选择协议用于在路由表中发现与维护前往目的IP地址的最短路径**
- RIP（路由信息协议）
  - RIP是一种分布式的基于距离向量的路由选择协议，选择的是跳数短的路径（每经过一个路由器，跳数+1）
- OSPF
  - 使用链路状态路由算法，

因此，RIP与BGP划分为应用层，而OSPF划分为传输层协议

## PING命令的详细过程

1. 假定主机 A 的 IP 地址是 `192.168.1.1`，主机 B 的 IP 地址是 `192.168.1.2`，它们都在同一个子网。
    那当你在主机 A 上运行“ping 192.168.1.2”后，会发生什么呢?
2. ping 命令执行的时候，源主机构建一个 **ICMP 请求数据包**
3. 由 ICMP 协议将这个数据包连同目的地址 `192.168.1.2` 一起交给 IP 层。
    IP 层将以 `192.168.1.2` 作为目的地址，本机 IP 地址作为源地址，加上一些其他控制信息，构建一个 IP 数据包。
4. 加入 MAC 头。
    如果在本节点 ARP 映射表中查找出 IP 地址 `192.168.1.2` 所对应的 MAC 地址，则可以直接使用；
    如果没有，则需要广播ARP请求分组，查询 MAC 地址
    获得 MAC 地址后，由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；
5. 主机 B 收到这个数据帧后，先**检查它的目的 MAC 地址，并和本机的 MAC 地址对比**，如符合，则接收，否则就丢弃。
    接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。
6. 主机 B 构建一个 **ICMP 应答数据包**，然后发送出去给主机 A。
    **在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；**
    **如果接收到了ICMP 应答包，则说明目标主机可达。**

在ICMP请求与响应报文内，最重要的字段为：类型字段（标识为ICMP数据报） 与 顺序号（区分连续PING时的多个数据报）

## MAC地址有什么作用

![](../images计网/../images/计网/MAC与IP.png)

MAC地址用于**在网络中唯一标示一个网卡，用于定义网络设备的位置，MAC地址是在一个局域网内才有效的地址**

访问另一个IP地址的过程：
1. 通过CIDR和子网掩码，判断该IP地址与当前机器的IP地址是否在同一个网段
    - 是同一个网段，直接将源地址和目标地址放入 IP 头中，通过 ARP 获得 MAC 地址，将源 MAC 和目的 MAC 放入 MAC 头中，发出去就可以了。
    - 如果不是同一网段，需要发往默认网关`Gateway`。
       Gateway 的地址一定是和源 IP 地址是一个网段的。
2. 如何发往默认网关Gateway呢？网关和源 IP 地址是一个网段，同样是通过ARP根据IP获得MAC地址，来发送数据。
3. 网关往往是一个路由器，是一个三层转发的设备，就是把 MAC 头和 IP头都取下来，然后根据里面的内容，看看接下来把包往哪里转发的设备。

## 在传输过程中，IP头和MAC头哪些改变，哪些不变

MAC 地址是一个局域网内才有效的地址。
因而，**MAC 地址只要过网关，就必定会改变**，因为已经换了局域网。

在路由器的路由转发规则中，**不会改变源与目的IP地址**，只是通过修改MAC地址，找到下一跳的目标

![](../images/计网/MAC传输.png)

> **但是，如果有NAT的参与，就会改变源与目的IP地址**


## Linux中统计当前各种状态的连接的数量的命令
`#netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'`

返回结果如下：

LAST_ACK 14
SYN_RECV 348
ESTABLISHED 70
FIN_WAIT1 229
FIN_WAIT2 30
CLOSING 33
TIME_WAIT 18122

对上述结果的解释：

CLOSED：无连接是活动的或正在进行
LISTEN：服务器在等待进入呼叫
SYN_RECV：一个连接请求已经到达，等待确认
SYN_SENT：应用已经开始，打开一个连接
ESTABLISHED：正常数据传输状态
FIN_WAIT1：应用说它已经完成
FIN_WAIT2：另一边已同意释放
ITMED_WAIT：等待所有分组死掉
CLOSING：两边同时尝试关闭
TIME_WAIT：另一边已初始化一个释放
LAST_ACK：等待所有分组死掉


## TCP和UDP的区别？

**对比如下**：

|  | UDP  | TCP  |
| :-- | :-- | :-- |
| 是否连接 | 无连接 | 面向连接|
| 是否可靠 | 不可靠传输，不使用流量控制和拥塞控制 | 可靠传输，使用流量控制和拥塞控制 |
| 是否有序 | 无序 | 有序，消息在传输过程中可能会乱序，TCP 会重新排序 |
| 传输速度 | 快 | 慢 |
| 连接对象个数 | 支持一对一，一对多，多对一和多对多交互通信 | 只能是一对一通信                                 |
| 传输方式 | 面向报文 | 面向字节流|
| 首部开销 | 首部开销小，仅8字节 | 首部最小20字节，最大60字节 |
| 适用场景 | 适用于实时应用（IP电话、视频会议、直播等） | 适用于要求可靠传输的应用，例如文件传输 |

**总结**：

TCP 用于在传输层有必要实现可靠传输的情况，UDP 用于对高速传输和实时性有较高要求的通信。TCP 和 UDP 应该根据应用目的按需使用。

## UDP 和 TCP 对应的应用场景是什么？

 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

- FTP文件传输
- HTTP / HTTPS

UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：

- 包总量较少的通信，如 DNS 、SNMP等
- 视频、音频等多媒体通信
- 广播通信

![image-20210519180008296](http://blog-img.coolsen.cn/img/image-20210519180008296.png)

## 详细介绍一下 TCP 的三次握手机制？

![](http://blog-img.coolsen.cn/img/image-20210520161056918.png)

* 第一次握手：客户端请求建立连接
  * 向服务端发送一个**同步报文**（`SYN=1`），同时选择一个随机数 `seq = x` 作为**初始序列号**，并进入`SYN_SENT`状态，等待服务器确认。

* 第二次握手：服务端收到连接请求报文后，如果同意建立连接，则向客户端发送**同步确认报文**（`SYN=1，ACK=1`），确认号为 `ack = x + 1`，同时选择一个随机数 `seq = y` 作为初始序列号，此时服务器进入`SYN_RECV`状态。
* 第三次握手：客户端收到服务端的确认后，向服务端发送一个**确认报文**（ACK=1），确认号为 `ack = y + 1`，序列号为 `seq = x + 1`，客户端和服务器进入`ESTABLISHED`状态，完成三次握手。

理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。

## 为什么需要三次握手，而不是两次？

主要有三个原因：

1. 防止已过期的连接请求报文突然传送到服务器，因而产生错误和资源浪费。

   - 在双方两次握手即可建立连接的情况下，假设客户端发送 A 报文段请求建立连接，由于网络原因造成 **A 暂时无法到达服务器，服务器接收不到请求报文段就不会返回确认报文段**。
   - 客户端在长时间得不到应答，**重新发送请求报文段 B**，这次 B 顺利到达服务器，三步握手建立连接，**之后正常断开连接**。
   - 此时姗姗来迟的 A 报文段才到达服务器，服务器随即返回确认报文并进入 ESTABLISHED 状态，但是已经进入 `CLOSED` 状态的客户端无法再接受确认报文段，更无法进入 ESTABLISHED 状态，这将**导致服务器长时间单方面等待，造成资源浪费**。

2. 三次握手才能让双方均**确认自己和对方的发送和接收能力都正常**

   - 第一次握手：客户端只是发送请求报文段，什么都无法确认，而服务器可以确认自己的接收能力和对方的发送能力正常；

   - 第二次握手：客户端可以确认自己发送能力和接收能力正常，对方发送能力和接收能力正常；

   - 第三次握手：服务器可以确认自己发送能力和接收能力正常，对方发送能力和接收能力正常；


3. **告知对方自己的初始序号值，并确认收到对方的初始序号值**。
   - TCP 实现了**可靠的数据传输**，原因之一就是 **TCP 报文段中维护了序号字段和确认序号字段**，通过这两个字段双方都可以知道，**在自己发出的数据中，哪些是已经被对方确认接收的**。这两个字段的值会在初始序号值得基础递增，如果是两次握手，**只有发起方的初始序号可以得到确认，而另一方的初始序号则得不到确认**。

## 为什么要三次握手，而不是四次？

因为**三次握手已经可以确认双方的发送接收能力正常，双方都知道彼此已经准备好，而且也可以完成对双方初始序号值得确认**，也就无需再第四次握手了。

## 什么是 SYN洪泛攻击？如何防范？

SYN洪泛攻击属于 DOS 攻击的一种，它**利用 TCP 协议缺陷，通过发送大量的半连接请求，耗费 CPU 和内存资源**。

原理：
- 半连接：在三次握手过程中，服务器发送 `[SYN/ACK]` 包（**第二个包**）之后，收到客户端的 `[ACK]` 包（**第三个包**）之前的 TCP 连接状态
  - 此时服务器处于 `SYN_RECV`（等待客户端响应）状态。
  - 如果接收到客户端的 `[ACK]`，则 TCP 连接成功，如果未接受到，则会**不断重发请求**直至成功。
- SYN 攻击的攻击者在短时间内**伪造大量不存在的 IP 地址**，向服务器不断地发送 `[SYN]` 包，服务器回复 `[SYN/ACK]` 包，并等待客户的确认。
  - **由于源地址是不存在的，服务器需要不断的重发直至超时**

这些伪造的 `[SYN]` 包将**长时间占用半连接队列**，影响了正常的 SYN，导致目标系统运行缓慢、网络堵塞甚至系统瘫痪。

检测：当在服务器上看到**大量的半连接状态**时，特别是源 IP 地址是随机的，基本上可以断定这是一次 SYN 攻击。

防范：

* 通过防火墙、路由器等过滤网关防护。
* 通过加固 TCP/IP 协议栈防范，如**增加最大半连接数，缩短超时时间**。
* SYN cookies技术。
  * SYN Cookies 是对 TCP 服务器端的三次握手做一些修改，专门用来防范 SYN 洪泛攻击的一种手段。
  
  
**SYN Cookies技术：**
> 在完成三步握手之前，不为任何一个连接分配资源

在TCP服务器接收到TCP `SYN`包并返回TCP `SYN + ACK`包时，**不分配一个专门的数据区，而是根据这个SYN包计算出一个cookie值**，这个cookie作为将要返回的`SYN + ACK`包的**初始序列号**。
当客户端返回一个`ACK`包时，**根据包头信息计算cookie，与返回的确认序列号(初始序列号 + 1)进行对比**，如果相同，则是一个正常连接，然后，分配资源，建立连接。

## 三次握手连接阶段，最后一次ACK包丢失，会发生什么？

**服务端：**
* 第三次的ACK在网络中丢失，那么服务端该TCP连接的状态为`SYN_RECV`，并且会根据 **TCP的超时重传机制**，会等待3秒、6秒、12秒后重新发送`SYN+ACK`包，以便客户端重新发送ACK包。
* 如果重发指定次数之后，仍然未收到 客户端的ACK应答，那么一段时间后，服务端自动关闭这个连接。

**客户端：**

客户端认为这个连接已经建立，如果客户端向服务端发送数据，**服务端将以RST包（Reset，标示复位，用于异常的关闭连接）响应**。此时，客户端知道第三次握手失败。

## 详细介绍一下 TCP 的四次挥手过程？

![](http://blog-img.coolsen.cn/img/image-20210520180127547.png)

- 第一次挥手：客户端向服务端发送**连接释放报文**（`FIN=1，ACK=1`），**主动关闭连接**，同时等待服务端的确认。
  - 序列号 seq = u，即客户端上次发送的报文的最后一个字节的序号 + 1
  - 确认号 ack = k, 即服务端上次发送的报文的最后一个字节的序号 + 1

- 第二次挥手：服务端收到连接释放报文后，立即发出**确认报文**（ACK=1），序列号 seq = k，确认号 ack = u + 1。
  这时 TCP 连接处于**半关闭状态**，即客户端到服务端的连接已经释放了，但是服务端到客户端的连接还未释放。
  这表示客户端已经没有数据发送了，但是服务端可能还要给客户端发送数据。

- 第三次挥手：服务端向客户端发送**连接释放报文**（`FIN=1，ACK=1`），**主动关闭连接**，同时等待 A 的确认。
  - 序列号 seq = w，即服务端上次发送的报文的最后一个字节的序号 + 1。
  - 确认号 ack = u + 1，与第二次挥手相同，因为这段时间客户端没有发送数据

- 第四次挥手：客户端收到服务端的连接释放报文后，立即发出**确认报文**（ACK=1），序列号 seq = u + 1，确认号为 ack = w + 1。
  此时，客户端就进入了 `TIME-WAIT` 状态。
  注意：此时客户端到 TCP 连接**还没有释放**，必须经过 `2*MSL`（**最长报文段寿命**）的时间后，才进入 `CLOSED` 状态。
  而服务端只要收到客户端发出的确认，就立即进入 `CLOSED` 状态。
  可以看到，服务端结束 TCP 连接的时间要比客户端早一些。

## 为什么连接的时候是三次握手，关闭的时候却是四次握手？

服务器在收到客户端的 FIN 报文段后，可能还有一些数据要传输，所以**不能马上关闭连接**，但是会做出应答，返回 ACK 报文段.

接下来可能会继续发送数据，在数据发送完后，服务器会向客户单发送 FIN 报文，表示数据已经发送完毕，请求关闭连接。服务器的**ACK和FIN一般都会分开发送**，从而导致多了一次，因此一共需要四次挥手。


## TCP中，进行TIME_WAIT的理由

- TIME_WAIT
    在四步挥手的过程中，客户端在收到第三条报文（服务端发出的连接释放报文）后，并不是直接关闭，而是进入TIME_WAIT状态，等待2MSL（最大报文存活时间）后释放连接。

1. 可靠地实现TCP全双工连接的终止，**确保最后一个确认报文能够到达**。
   - 接收假设网络是不可靠的，Client发出的最后一个ACK丢失，Server会**重发`FIN-ACK`报文**，Client需要响应这个`FIN-ACK`，重发最后的`ACK`
2. **防止已失效的连接终止确认报文出现在之后的连接中**
   1. 等待一段时间是为了**让本连接持续时间内所产生的所有报文都从网络中消失**，使得下一个在同一IP与端口建立的新连接不会出现旧的连接请求报文。

## 为什么客户端的 TIME-WAIT 状态必须等待 2MSL ？

> MSL指的是一个片段在网络中存活的最大时间，2MSL就是一个发送和一个回复的最大时间

主要有两个原因：

1. 确保 ACK 报文能够到达服务端，从而使服务端正常关闭连接。
   MSL 是报文段在网络上存活的最长时间。
   客户端等待 2MSL 时间，即`「客户端 ACK 报文 1MSL 超时 + 服务端 FIN 报文 1MSL 传输」`，就能够收到服务端重传的 `FIN/ACK` 报文，然后客户端重传一次 ACK 报文，并重新启动 2MSL 计时器。
   如此保证服务端能够正常关闭。

2.  **防止已失效的连接终止报文段出现在之后的连接中**。
   TCP 要求**在 2MSL 内不使用相同的序列号**。
   客户端在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以保证**本连接持续的时间内产生的所有报文段都从网络中消失**。
   这样就可以使下一个连接中**不会出现这种旧的连接终止报文段**，或者即使收到这些过时的报文，也可以不处理它。

## 如果已经建立了连接，但是客户端出现故障了怎么办？

具体而言，TCP 设有一个**保活计时器**。
服务器每收到一次客户端的数据，都会重新复位这个计时器，时间通常是设置为 2 小时。
若 2 小时还没有收到客户端的任何数据，服务器就开始重试：每隔 75 分钟发送一个**探测报文段**，若一连发送 10 个探测报文后客户端依然没有回应，那么服务器就认为连接已经断开了。

## TIME-WAIT 状态过多会产生什么后果？怎样处理？

https://www.jianshu.com/p/a2938fc35573

- 从服务器来讲，短时间内关闭了大量的Client连接，就会造成服务器上出现大量的TIME_WAIT连接，严重消耗着服务器的资源，此时部分客户端就会显示连接不上。

- 从客户端来讲，客户端TIME_WAIT过多，就会导致**端口资源被占用**，因为端口就65536个，被占满就会导致无法创建新的连接。

> 由于TCP的四个要素：源IP地址，源端口，目的IP地址，目的端口中只要有一个不同，就可以建立新的连接，理论上，一个服务器能接受的TCP连接数量是没有上限的，但**端口数是有限的**


**原因**：**TCP服务器上的并发量较高，且多数为短连接**，就会出现大量`TIME_WAIT`状态的连接（可以通过netstat -tanlp发现大量TIME_WAIT的连接）

> 短连接：业务处理+数据传输的时间 << TIME_WAIT的超时时间



**解决办法：**

* 启用多台机器，进行负载均衡
* 修改短连接为长连接方式
* 设置TIME_WAIT的数量上限，系统清理多余的TIME_WAIT连接
  * 可能导致系统回收正常的`TIME_WAIT`连接，导致连接异常
* 快速回收，降低回收`TIME_WAIT`等待的时间
  ```bash
  net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
  net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。
  ```
* 开启重用机制
  * 可以通过重用机制，允许将TIME-WAIT sockets重新用于新的TCP连接
  * **优于快速回收**，因为重用机制在协议角度是安全的
  * 缺点：只有在客户端主动断开连接时才有效

> 当服务器进程被终止，会关闭其打开的所有文件描述符，此时会向客户端发送一个FIN报文，客户端响应ACK，即**四步挥手的前两步**
> 客户端还可以继续发送数据，但由于服务器的套接字已经关闭了，服务端会向客户端发送RST报文，请求将处于异常状态的连接复位
> 如果客户端继续发送数据，会诱发服务端TCP向服务端发送SIGPIPE信号，其默认处理为终止程序

https://www.jianshu.com/p/a2938fc35573
https://blog.csdn.net/yusiguyuan/article/details/21445883


## CLOSE_WAIT状态过多会产生什么结果，怎么解决



## TCP的back_log是指什么

在三步握手过程中，TCP backlog创建了两个队列，来负责缓存**已经收到的首个SYN和已经完成握手且待应用层接收的连接**
- 负责缓存SYN的队列叫SYN QUEUE
  - SYN QUEUE的长度即`back_log`
  - 如果满了，直接丢弃请求报文，让客户端重传
    - 如果太长，同样会导致超时重传，还会浪费内存
    - 如果太短，会触发大量TCP重传
- 负责缓存已完成连接叫ACCEPT QUEUE

https://zhuanlan.zhihu.com/p/136234069

## 发送方如何收到接收方发来的重传消息的？中间有一个丢失了，那么发送方还需要重传后边的数据么？

TCP通过**连续arq协议**与**滑动窗口协议**保证数据传输的正确性。
- ARQ协议，即自动重传请求（Automatic Repeat-reQuest），是OSI模型中数据链路层和传输层的错误纠正协议之一。
 它通过使用**确认**和**超时**这两个机制，**在不可靠服务的基础上实现可靠的信息传输**。
- 如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。
- ARQ包括**停止等待ARQ协议**和**连续ARQ协议**，拥有错误检测、正面确认、超时重传和 负面确认及重传等机制。

![](../images/计网/停止等待arq.png)
**停止等待ARQ：**
如果出现差错，B在接受时M1报文段时，**会抛弃M1**，**且不通知A**，又或者A发出的M1丢失了。
在上述情况下，A只要超过了一段时间仍然没有收到确认，就**认为刚才发送的分组丢失了**，所以它会重传刚刚的发送过的分组，也就是所谓的**超时重传**。

**连续ARQ：**
 ![](../images/计网/连续ARQ.png)
 发送方采用流水线传输，不必等待接收方的确认信息，并采用**累积确认机制**。
 通常结合**滑动窗口协议**使用，发送方维持一个窗口，通过**累计确认**的方式移动窗口
 如果发送方发送了5个分组，而中间的第3个分组丢失了，则需要重传后面3个分组（**go-back-N**)


**滑动窗口协议（Go-back N）**
如果中间有一个数据包丢失了，那么发送方就**必须重传该包后边所有的数据包**，这也叫==go-back-n==。
缺点：通信线路质量不好时，连续arq会带来负面影响

重发原因：
1. 发送方发送的数据出现差错
2. 接收方回复的确认信息丢失或延迟，导致确认信息在a超时之后才到达，此时A会丢弃这个确认信息，而B在A重传的分组到达后，丢弃旧的分组，重新发送确认信息

注意：在GBN协议中，会丢弃正确接收但失序的分组，因为接收方必须将数据按序交付给上层。
直接丢弃失序分组的话，就**不需要缓存任何失序分组**，唯一需要维护的信息就是下一个按序接收的分组的序号。
但会造成更多的重传

**选择重传**
选择重传协议**只重传真正丢失的分组**，从而避免了不必要的重传。
选择重传的特性：
- 发送方与接收方都需要维护一个窗口，用于进行分组的缓存
- 选择重传也无法使用`Go-back N`协议，接收方必须对每个正确接收的分组进行响应
- 接收端为维护一个数据帧计时器，如果其超时，则认为数据帧丢失或损坏，将出错的帧丢弃，并**向发送端恢复NAK**，让发送端重新发送

> 窗口长度必须小于或等于序号空间大小的一半
> 如果滑动窗口的大小过大，可能导致旧一代的分组被混淆为新一代的分组

## 如果发送方发送的数据包是乱序的那么接收方怎么处理？接收方接收到数据包自己会不会进行一个调整 排序？

TCP为了提供可靠的数据传输，它给发送的每个数据包做顺序化。

主机每次发送数据时，TCP就给每个数据包分配一个**序列号**，并且在一个特定的时间内等待接收主机对这个序列号的确认。
如果发送主机在一个特定时间内没有收到接收主机的确认，则发送主机会重传此数据包。

接收主机利用序列号对接收的数据进行确认，以便检测对方发送的数据是否有丢失或者乱序等，接收主机一旦收到顺序化的数据，它就将这些数据按正确的顺序重组成数据流并传递到高层进行处理。

对于不按序到达的数据应该如何处理，**tcp并无明确规定**

- 如果接受方把不按序到达的数据一律丢弃，那么接收窗口的管理将会比较简单，但这样做对网络资源的利用不利（因为发送方会重复传送比较多的数据）。
- tcp通常对不按序到达的数据先是临时存放在接收窗口中，等到字节流中所缺少的字节收到后，再按序交付上层的应用进程。

## TIME_WAIT 是服务器端的状态?还是客户端的状态?

TIME_WAIT 是**主动断开连接的一方**的状态，一般情况下，都是客户端所处的状态;服务器端一般设置不主动关闭连接。

## TCP协议如何保证可靠性？

TCP主要提供了**检验和**、**序列号/确认应答**、**超时重传**、**滑动窗口**、**拥塞控制**和 **流量控制**等方法实现了可靠性传输。

* **序列号/确认应答**：（可靠传输、顺序问题）
  - 序列号的作用不仅仅是应答的作用，有了序列号能够**将接收到的数据根据序列号排序**，并且**去掉重复序列号的数据**。
  
  TCP传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答，也就是**发送ACK报文**，这个ACK报文当中带有**对应的确认序列号**，即接收到了哪些数据，以及下次需要的数据的序号

* 滑动窗口：（流量控制）
  * 滑动窗口既提高了报文传输的效率，也**避免了发送方发送过多的数据**而导致接收方无法正常处理的异常。

* 超时重传：
  * 超时重传是指发送出去的数据包到接收到确认包之间的时间，如果超过了这个时间会被认为是丢包了，需要重传。最大超时时间是动态计算的。
    * 对同一数据包，当需要多次重传时，TCP 的策略是超时间隔加倍。
    * 如果连续收到三个冗余的对相同序号的ACK，则在定时器过期前**快速重传**，立即重传

* 拥塞控制：
  * 在数据传输过程中，可能由于网络状态的问题，造成网络拥堵，此时引入拥塞控制机制，在保证TCP可靠性的同时，提高性能。

*  流量控制：
   *  如果主机A一直向主机B发送数据，不考虑主机B的接受能力，则可能导致**主机B的接受缓冲区满了而无法再接受数据**，从而会导致大量的数据丢包，引发重传机制。
   *  而在重传的过程中，若主机B的接收缓冲区情况仍未好转，则会**将大量的时间浪费在重传数据上**，降低传送数据的效率。
   *  所以引入流量控制机制，**主机B通过告诉主机A自己接收缓冲区的大小，来使主机A控制发送的数据量**。流量控制与TCP协议报头中的窗口大小有关。

* 检验和：
  * 通过检验和的方式，接收端可以**检测出来数据是否有差错和异常**，假如有差错就会**直接丢弃TCP段**，重新发送。

## 详细讲一下TCP的滑动窗口？

TCP通过窗口形式的缓存，暂时存放字节流。
发送方与接收方都会维护一个窗口，**发送方的窗口大小取决于接收方在窗口字段中返回的窗口大小**。
> 窗口大小指的是**不需要等待确认应答包而可以继续发送数据包的最大值**

发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。
如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，**直到左部第一个字节不是已发送并且已确认的状态**；

接收方**只会对接受窗口中的最后一个按序到达的字节进行确认**，例如{31,33,34}，只会对31返回确认报文。

![](http://blog-img.coolsen.cn/img/image-20210520214432214.png)

> 滑动窗口的大小取决于**拥塞控制窗口**和**流量控制窗口**间的最小值。

## 详细讲一下拥塞控制？

TCP 一共使用了四种算法来实现拥塞控制：

* 慢开始与拥塞避免；
  * 发送开始时，发送方的状态变量：**拥塞窗口大小**`cwnd=1`，收到确认后，**cwnd加倍**
  * 同时设置慢开始门限，当`cwnd>=ssthresh`，每次收到确认，`cwnd+1`
  * 若出现超时，`ssthresh /= 2`，重新执行慢开始（`cwnd=1`）

* 快速重传与快速恢复：
  * 在发送方，连续收到**三个同一报文段的重复确认**，则可认为**下一个报文段丢失**，立即执行重传，而不需要等到超时。
  * 这种情况下，只是丢失了个别报文段，而不是拥塞，因此可以进行快恢复：令`ssthresh = cwnd / 2`，`cwnd = ssthresh`，即直接进入拥塞避免阶段

![](http://blog-img.coolsen.cn/img/image-20210520214146324.png)

## UDP有哪些应用场景？

UDP的特点：
1. 需要的资源少，适用于网络情况较好的内网，或对于丢包不敏感的应用
2. 不需要一对一沟通，可以使用广播或多播的方式
3. 处理速度快，延时低

具体场景：
- 网页或APP的访问：原先访问网页与手机APP都是基于HTTP协议的，而HTTP基于TCP，不适用于时延较大的移动互联网（建立连接的时间长，且重连次数多）。而且现在的HTTP采用的是多个数据通道共享一个连接的情况，但TCP的严格顺序策略导致后来的数据会因之前的数据没传送到而阻塞。
- 流媒体的协议：直播协议使用RTMP，其也是基于TCP的，但TCP的顺序控制同样导致了直播流的卡顿，而且在网络不好时，TCP会主动降低发送速度，导致更加卡顿。因此很多直播应用实现了基于UDP的视频传输协议



## 视频面试用到了哪些协议，UDP用在哪，TCP用在哪



## 拆包与粘包的问题，自定义协议怎么解决粘包问题

TCP粘包/拆包即基于TCP发送数据是，出现了**多个字符串“粘”在了一起，或者一个长字符串被“拆”开来**的情况。

粘包/拆包的原因：
- 应用程序写入的数据**大于套接字缓冲区**的大小，导致拆包
- 应用程序写入的数据**小于套接字缓冲区**的大小，网卡会将应用多次写入的数据一起发到网络上，导致粘包
- 进行MSS（最大报文长度）大小的TCP分段，当$TCP报文长度 - TCP首部长度 > MSS$时，将发生拆包
- 接收方法不及时读取套接字缓冲区数据，这将发生粘包

本质原因：
- 发送方的原因：
  - TCP默认会使用`Nagle`算法，其主要任务为：
    1. 只有上一个分组得到确认，才会发送下一个分组；
    2. **收集多个小分组，在一个确认到来时一起发送**。
    
  - 所以，正是Nagle算法造成了发送方有可能造成粘包现象。

- 接收方的原因：
  - TCP接收方采用**缓存**方式读取数据包，一次性读取多个缓存中的数据包。自然出现前一个数据包的尾和后一个收据包的头粘到一起。

解决方案：（以使用Netty自带的解码器为例）
 1. ==定长消息==（`FixedLengthFrameDecoder`）
   - 基于固定长度的数据包实现，**按照指定的长度，对消息进行相应的拆包**，如果不够指定的长度，则进行补全
   > 如果包内容超过指定字节数，则又需要进行拆包，并在接收方组装，需要增加额外的处理逻辑
   
 2. ==利用特殊标志作为数据包的结束标志==（`LineBasedFrameDecoder`）
   - 发送端发送数据包时，每个数据包之间**以特殊标志（例如换行符）作为分隔符**。
   - 解码时通过遍历`ByteBuf` 中的可读字节，当读取到指定的特殊标志时，说明到了包尾
   > 需要对结束标志符进行转义或其他特殊处理，防止协议数据包部分出现了设定的包结束标志，导致错误的判断
 3. ==在包头设定长度字段==（`LengthFieldBasedFrameDecoder`）
   - 基于长度字段的解码器，**在消息头中定义长度字段，来标识消息的总长度**，即==包头+包体的方式==
   - 接收方解包时，首先尝试获取包头以及其中的长度字段，如果连包头都被拆分了，就继续拼接后续的数据，并根据包头的数据向后取包体的数据


# HTTP


## 介绍一下DNS

DNS即域名解析服务

## HTTP常见的状态码有哪些？

常见状态码：

* 100：Continue，通知客户端它的**部分请求已经被服务器接收，且仍未被拒绝**。客户端应当继续发送请求的剩余部分，或者如果请求已经完成，忽略这个响应.服务器必须在请求完成后向客户端发送一个最终响应
* 101：Switching Protocol(切换协议)，服务器已经理解了客户端的请求，并将通过Upgrade消息头通知客户端采用不同的协议来完成这个请求
* 200：**服务器已成功处理了请求**。 通常，这表示服务器提供了请求的网页。
* 301 ： (**永久转移**) 
  * 请求的网页已永久移动到新位置，且URL发生改变
  * 服务器返回此响应(对 GET 或 HEAD 请求的响应)时，会**自动将请求者转到新位置**
* 302：(**临时转移**) 
  * 服务器目前从不同位置的网页响应请求，但**请求者应继续使用原有位置来进行以后的请求**
* 304：`Not Modified`，自从上次请求后，请求的资源没有修改过，客户端请求的资源的缓存仍然是有效的，浏览器自动识别并读取缓存中的资源，服务端不返回其他任何数据
  * 服务器会读取HTTP请求头中的`If-Modified-Since`、`If-None-Match`，从而判断客户端中的缓存是不是最新的
  * 如果是，则返回304响应。如果过期了，则返回200，由服务器发送资源的最新版本
* 400 ：`Bad Request`，**客户端请求有语法错误**，不能被服务器所理解。
* 401：未授权，用户未经过身份验证，或没有通过授权测试
* 403 ：服务器理解请求，但是由于**权限不足**等原因，**拒绝提供服务**。
* 404 ：**服务器未找到目标资源**
  * 被广泛用于服务器不想解释为什么拒绝请求，或没有其他可用的响应的情况
* 500： **服务器内部错误**，无法完成请求。
* 502：bad gateway，作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到**无效的响应**，可能是应用挂掉了，tomcat服务器没启动成功
* 503：服务不可用，**由于临时的服务器维护或者过载，服务器当前无法处理请求**。这个状况是临时的，并且将在一段时间以后恢复。
* 504：gateway time-out，一般指nginx做反向代理服务器时，**所连接的上游服务器的响应超时**的。
  

> 502意味着使用了上游服务器和网关/代理不同意的协议交换数据
> 504意味着上游服务器已关闭（不响应网关 / 代理）

![](http://blog-img.coolsen.cn/img/image-20210525114439748.png)

## 状态码301和302的区别是什么？

- **共同点**：
  - 301和302状态码都表示**重定向**，就是说浏览器在拿到服务器返回的这个状态码后会自动跳转到一个新的URL地址，这个地址可以从响应的Location首部中获取（**用户看到的效果就是他输入的地址A瞬间变成了另一个地址B**）。
- **不同点**：
  - 301表示**旧地址A的资源已经被永久地移除了**(这个资源不可访问了)，搜索引擎在抓取新内容的同时也**将旧的网址交换为重定向之后的网址**；
  - 302表示**旧地址A的资源还在（仍然可以访问）**，这个重定向只是临时地从旧地址A跳转到地址B，搜索引擎会抓取新的内容而保存旧的网址。

**补充，重定向原因**：

1. 网站调整（如改变网页目录结构）；
2. 网页被移到一个新地址；
3. 网页扩展名改变(如应用需要把.php改成.Html或.shtml)。 

## HTTP 常用的请求方式？

| 方法    | 作用                                                    |
| ------- | ------------------------------------------------------- |
| GET     | 获取资源 |
| POST    | 传输实体主体|
| PUT     | 上传文件|
| DELETE  | 删除文件|
| HEAD    | 和GET方法类似，但**只返回报文首部，不返回报文实体主体部分** |
| PATCH   | 对资源进行**部分修改**                                      |
| OPTIONS | 查询指定的URL支持的方法                                 |
| CONNECT | 要求用隧道协议连接代理                                  |
| TRACE   | 服务器会将通信路径返回给客户端                          |

为了方便记忆，可以将PUT、DELETE、POST、GET理解为客户端对服务端的增删改查。

- PUT：上传文件，向服务器添加数据，可以看作增
- DELETE：删除文件
- POST：传输数据，向服务器提交数据，对服务器数据进行更新。
- GET：获取资源，查询服务器资源

## GET请求和POST请求的区别？

**使用上的区别**：

* 在使用浏览器发出请求时，GET使用`URL`或`Cookie`传参，而POST将数据放在`HTTp BODY`中
  * 这个是因为HTTP协议用法的约定，并不是GET只能用url传参，而是**浏览器直接发出的GET只能由一个url触发**
  * 而**浏览器直接发出的POST请求都来自表单提交**
* GET方式提交的数据有长度限制，则POST的数据则可以非常大，
  * 这个是因为它们使用的操作系统和浏览器设置的不同引起的区别

* POST比GET安全，因为数据在地址栏上不可见，这个说法没毛病，但依然不是GET和POST本身的区别。
* POST不能作为书签，但GET可以
* POST不能进行缓存，但GET可以

**本质区别**

GET和POST最大的区别主要是**GET请求是幂等性的，POST请求不是**

> 幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果。

根据浏览器的定义：
- GET用于**读取一个资源**，反复读取不应该对访问的数据有副作用，即幂等性
- POST用于**传输一个资源到服务器**，这件事往往是有副作用的，不幂等。
  - 例如提交表单时，提示“确认重新提交表单”

因此，也就有了将POST实现为**幂等**的需求，幂等的POST可以避免误触、BUG带来的重复提交

## 解释一下HTTP长连接和短连接？

**在HTTP/1.0中，默认使用的是短连接**。
也就是说，**浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接**。
如果客户端浏览器访问的某个HTML或其他类型的 Web页中包含有其他的Web资源，如JavaScript文件、图像文件、CSS文件等；当浏览器每遇到这样一个Web资源，就会建立一个HTTP会话。

但从 **HTTP/1.1起，默认使用长连接**，用以保持连接特性。
使用长连接的HTTP协议，会在响应头有加入这行代码：`Connection:keep-alive`

在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的**TCP连接不会关闭**，如果客户端再次访问这个服务器上的网页，**会继续使用这一条已经建立的连接**。
Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接要客户端和服务端都支持长连接。

**HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。**

## HTTP请求报文和响应报文的格式？

**请求报文格式**：

1. 请求行（请求方法+URI协议+版本）
2. 请求头部
3. 空行
4. 请求主体

```html
GET/sample.jspHTTP/1.1 请求行
Accept:image/gif.image/jpeg, 请求头部
Accept-Language:zh-cn
Connection:Keep-Alive
Host:localhost
User-Agent:Mozila/4.0(compatible;MSIE5.01;Window NT5.0)
Accept-Encoding:gzip,deflate

username=jinqiao&password=1234 请求主体
```

**响应报文**：

1. 状态行（版本+状态码+原因短语）
2. 响应首部
3. 空行
4. 响应主体

```html
HTTP/1.1 200 OK
Server:Apache Tomcat/5.0.12
Date:Mon,6Oct2003 13:23:42 GMT
Content-Length:112

<html>
    <head>
        <title>HTTP响应示例<title>
    </head>
    <body>
        Hello HTTP!
    </body>
</html>
```

## HTTP1.0和HTTP1.1的区别?

* **长连接、管线化传输**：
  * HTTP 1.1支持**长连接**和**请求的流水线**处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启`Connection： keep-alive`，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。
    * 长连接：一次TCP连接，可以发送、接受多次HTTP请求
    * 请求的流水线：默认情况下，HTTP是按顺序发出的，下一个请求只有在当前请求接到应答后才能发出，**流水线模式是在同一条长连接上发出连续的请求，不需要等待应答**

* **缓存处理**：
  * 在HTTP1.0中主要使用header里的`If-Modified-Since`,`Expires`来做为缓存判断的标准
  * HTTP1.1则引入了更多可供选择的缓存头，提供更多的缓存控制策略，例如强制不使用缓存

* **数据的部分传输**：
  * HTTP1.0不支持数据的部分传输，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能
  * HTTP1.1则在请求头引入了`range`标签，它允许**只请求资源的某个部分**，即返回码是`206（Partial Content）`，这样就方便了开发者自由的选择以便于充分利用带宽和连接。

*  **主机名Host标签**：
   *  在HTTP1.0中认为**每台服务器都绑定一个唯一的IP地址**，因此，**请求消息中的URL并没有传递主机名（`hostname`）**。
    但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个IP地址。
    * HTTP1.1的请求消息和响应消息都应支持`Host`标签，且请求消息中如果没有`Host`标签会报告一个错误（`400 Bad Request`）。
  
* **错误通知的管理**：
  * 在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。


## HTTP1.1和 HTTP2的区别？

HTTP2中，有两个重要概念：
- 帧：帧代表着最小的数据单位，每个帧会标识出该帧属于哪个流
- 流：流就是多个帧组成的数据流
> 每个http2连接上传输的帧都关联到一个流。流是一个逻辑上的结合，是一个独立的，双向的帧序列。
> **每个单独的http2连接都可以包含多个并发的流**，任何一端都可以交错地插入帧。流可以被客户端\服务端单方面占有，也可以被共享


HTTP2将 HTTP 消息分解为独立的帧，交错发送，然后在另一端重新组装。
- 并行交错地发送多个请求，请求之间互不影响。
- 并行交错地发送多个响应，响应之间互不干扰。
- 使用一个连接并行发送多个请求和响应。

HTTP2.0相比HTTP1.1支持的特性：

* **采用二进制协议**：
  * HTTP1.1的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多
  * HTTP2采用的二进制编码只由0和1的组成，消息头与消息体编码为二进制的帧Frame，实现方便且健壮。

* **多路复用**（将多个请求复用同一个tcp链接中）
  * 在一个TCP连接里，客户端和服务器端都可以同时发生多个请求或者响应，
    * 对于HTTP/1.1来说，==各个请求和响应都是有严格的次序要求的==
    * 而在HTTP/2中，==不用按照次序一一对应==，而且**并发的多个请求或者响应中任何一个请求阻塞了不会影响其他的请求或者响应**，这样也就避免了"**队头阻塞**"。
  * 一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。
> 注意：
> 在HTTP1.1的管线化传输中，尽管可以连续地发送多条HTTP请求，但**HTTP响应的接收还是有着严格的顺序要求，如果前一个请求阻塞了，后面的请求即使已经处理完毕，也必须等待之前的请求处理完毕**，即队头阻塞
> 而
![](../images/计网/管线化.png)

* **头部压缩**
  * HTTP1.1的头部（header）带有大量信息，而且**每次都要重复发送**；
  * HTTP2.0使用encoder来减少需要传输的header大小，**通讯双方各自cache一份header fields表**，既避免了重复header的传输，又减小了需要传输的大小。

* **服务端推送**：服务器除了对最初请求的响应外，服务器还可以额外的向客户端推送资源，而无需客户端明确的请求。

## HTTP 与 HTTPS 的区别？

|              |HTTP| HTTPS|
| :----------: | :----------------: | :---------------------------------------: |
|     端口     |80| 443|
|    安全性    | 无加密，安全性较差 | 有加密机制，安全性较高|
|   资源消耗   |较少| 由于加密处理，资源消耗更多|
| 是否需要证书 |不需要| 需要|
|     协议     | 运行在TCP协议之上  | 运行在SSL协议之上，SSL运行在TCP协议之上 |

## HTTPS 的优缺点?

**优点**：

* 安全性：

  * 使用HTTPS协议可**认证用户和服务器**，确保数据发送到正确的客户机和服务器；

  * HTTPS协议是由`SSL+HTTP`协议构建的可进行**加密传输**、**身份认证**的网络协议，要比http协议安全，可防止数据在传输过程中不被窃取、改变，**确保数据的完整性**。

**缺点**：

- 在相同网络环境中，HTTPS 相比 HTTP 无论是响应时间还是耗电量都有大幅度上升。
- HTTPS 的安全是有范围的，在黑客攻击、服务器劫持等情况下几乎起不到作用。
- 在现有的证书机制下，中间人攻击依然有可能发生。
- HTTPS 需要更多的服务器资源，也会导致成本的升高。

## 讲一讲HTTPS 的原理？

![](http://blog-img.coolsen.cn/img/image-20210525160006424.png)

加密流程按图中的序号分为：

1. 客户端请求 HTTPS 网址，然后连接到 server 的 443 端口 (HTTPS 默认端口，类似于 HTTP 的80端口)。

2. 服务器必须要有一套数字CA证书。颁发证书的同时会产生一个私钥和公钥。
    - 私钥由服务端自己保存，不可泄漏。
    - 公钥则是附带在证书的信息中，可以公开的。
    
    证书本身也附带一个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被篡改。

3. 服务器响应客户端请求，将证书传递给客户端，证书包含公钥和大量其他信息，比如证书颁发机构信息，公司信息和证书有效期等。

4. 客户端解析证书并对其进行验证。如果证书不是可信机构颁布，或者证书中的域名与实际域名不一致，或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。

   如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥A。然后客户端还会生成一个随机码 KEY，并使用公钥A将其加密。

5. 客户端把加密后的随机码 KEY 发送给服务器，作为后面对称加密的密钥。

6. 服务器在收到随机码 KEY 之后会使用私钥B将其解密。经过以上这些步骤，客户端和服务器终于建立了安全连接，完美解决了对称加密的密钥泄露问题，接下来就可以用对称加密愉快地进行通信了。

7. 服务器使用密钥 (随机码 KEY)对数据进行对称加密并发送给客户端，客户端使用相同的密钥 (随机码 KEY)解密数据。

8. 双方使用对称加密愉快地传输所有数据。

## CA证书是什么，上面有啥内容，用户怎么验证

CA是由第三方的负责管理和签发用于HTTPS证书的机构，而HTTP证书就是CA对服务方签发的证书。


证书中包含以下信息：
1. 服务器的公钥
2. 服务器组织信息和个人信息
3. 签发机构CA的信息
4. 证书的有效时间
5. 证书序列号
6. 签名

签发过程：
1. CA会使用散列函数计算上述明文信息的信息摘要，然后，**采用CA的私钥对信息摘要进行加密，密文即签名**。
2. 服务器收到证书后，采用相同的散列函数计算得到信息摘要，然后**利用对应 CA 的公钥解密签名数据，对比证书的信息摘要**，如果一致，则可以确认证书的合法性，即公钥合法

==证书的合法性同样依赖于非对称加密算法==


实际上，证书的签发还涉及到**证书信任链**，因为向CA申请的证书，通常都是由中间证书签发的，而客户端通常只会保存根证书的信息

因此，客户端会根据证书中的信息找到证书的签发者，即CA，并向CA请求对应的中间证书。
当如此一步步寻找到根证书时，会检查该根证书是否存在于本地的根证书清单上，如果有，则利用根证书中的公钥去验证根证书是否可信，并进一步利用其中的公钥验证链中其余证书是否可信


## DDOS攻击是怎么样的

DDoS即分布式拒绝服务攻击，主要是利用大量被劫持的机器，向被攻击者发送大量请求，大规模的消耗被攻击者的服务器资源，让它无法正常服务。

其中典型的就是SYN Flood攻击，以及HTTP Flood、UDP Flood等多种类型

## 抓取过HTTP报文吧，怎么抓取HTTPS明文



## 介绍一下SSL/TLS

SSL：位于可靠的面向连接的网络层协议和应用层协议之间的一种协议层。SSL通过**互相认证**、**使用数字签名确保完整性**、**使用加密确保私密性**，以实现客户端和服务器之间的安全通讯。

![](../images/计网/SSL.png)

SSL协议主要分为两层：
- **SSL记录协议层**
  - 为高层协议提供基本的安全服务。
  - SSL纪录协议封装各种高层协议，提供压缩解压缩、加密解密、计算和校验MAC等与安全有关的功能
- SSL握手协议层
  - 包含：
    - SSL握手协议：建立在SSL记录协议之上，用于在实际的数据传输开始之前，通讯双方进行身份认证、协商加密算法、交换加密密钥等，**协调客户和服务器的状态，使双方能够达到状态的同步**
    - SSL密码变化协议：
    - SSL警告协议：
  - 用于SSL管理信息的交换，允许应用协议传送数据之间相互验证，协商加密算法和生成密钥等。

其中，最重要的是**纪录协议**与**握手协议**
- **SSL纪录协议**：建立在可靠的传输（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能
- **SSL握手协议**：建立在SSL记录协议之上，用于**在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等**

SSL/TLS握手的工作流程：

1. 客户端向服务端发送ClientHello消息，其中包含SessionID、客户端生成的随机数 `Random1`、`SSL Version`、==支持的加密协议==等信息。
   > 其中，加密协议决定了加密和生成摘要时具体使用哪些算法 
2. 服务器收到消息后，选定加密协议，并将加密协议与数字证书放在ServerHello消息中，返回给客户端
3. 客户根据收到的服务器的响应，产生一个随机数（**秘密数**），并**基于秘密数，根据服务器选择的加密协议生成会话秘钥**
4. 客户端使用**服务器的公钥**对**秘密数**加密，并发给服务器
5. 服务器对**加密的秘密数**进行解密，**同样基于秘密数与加密协议生成会话秘钥**
> 至此，SSL结束，服务端和客户端**使用相同的会话秘钥对数据进行加密（对称加密）**

 总而言之，就是客户端生成秘密数，对秘密数进行非对称加密：用服务器的公钥加密，然后传给服务器，服务器用私钥解密。
 之后客户端与服务器对数据进行对称加密，即**基于相同的秘密数与加密协议，生成会话秘钥，用于加密与解密**


TLS：传输层安全协议，用于两个应用程序之间提供**保密性和数据完整性**

> TLS的目的：使SSL更安全，并使协议的规范更精确和完善

TLS包含两层协议：TLS 记录协议（TLS Record）和 TLS 握手协议（TLS Handshake）



## 介绍一下加密算法

SSL/TLS规定的合法算法：
1. 握手期间使用的非对称加密算法（RSA算法）
2. 加密算法（握手成功后的对称加密，AES、3DES等）
3. 信息摘要算法（SHA-1、SHA-256、MD5等）

## 讲一下对称加密算法与非对称加密算法，非对称加密如何保证安全性

> 加密和解密可以理解为某种**互逆的**数学运算，加密将明文变为密文，解密将密文变为明文，其中最关键的组件就是**秘钥**

- 对称加密：加密与解密使用**相同的秘钥**
  - 性能好，但需要将秘钥放在网络上传输，不太安全，通常在**对秘钥进行非对称加密**的基础上，用于数据的加密
- 非对称加密：加密与解密使用**不同的秘钥**
  - 一般指的是：加密时使用公钥，解密时使用私钥
  - 限制了公钥的能力，使解密的能力保留在服务端，但**非对称加密**涉及复杂的数学问题，性能较差，**通常用于密钥交换**

## WEB页面请求的全过程

1. 为主机申请IP：DHCP 配置主机信息
   - 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。
   1. 主机生成 DHCP 请求报文（应用层）
   2. 将报文放入UDP 报文段中（传输层）
      - 源端口：67为DHCP服务器的固定端口
      - 目的端口68位DHCP客户端的固定端口 
   3. 网络层添加头部，封装为IP数据报
      - 源 IP 地址：`0.0.0.0`
      - 目的IP地址：`255.255.255.255`（广播IP）
   4. 数据链路层添加头部，封装为以太网帧
      - 源MAC地址：主机的MAC 
      - 目的地址 `FF:FF:FF:FF:FF:FF`
   5. 以太网帧被发送到交换机（交换机与主机用网线连接），交换机修改转发表来记录请求主机的MAC地址，并在其所有出口广播这个帧，将这个帧发给与交换机相连的所有设备
   6. 与交换机相连的默认网关路由器收到这个广播帧，进行解析，发现目的IP是广播IP，将其中的DHCP请求交给DHCP服务器
      - 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。
   7. DHCP服务器生成一个DHCP ACK报文，并将目的MAC地址设置为接受DHCP请求帧的路由器的端口MAC地址，DHCP ACK报文主要包含：
      - 分配给DHCP请求的IP
      - DNS服务器的IP
      - 默认网关路由器的IP
      - 子网掩码
   8. DHCP ACK以太网帧由默认网关路由器发送给交换机，交换机根据转发表转发回给我的主机
   9. 主机收到该帧后，不断分解得到 DHCP 报文。解析后得到了自己的IP地址、DNS服务器IP、默认网关路由器IP

2. 查找默认网关路由器的MAC地址：ARP 解析 MAC 地址
   - 此时，已经有源IP了，还需要目的IP。已知条件为域名，可以去DNS服务器根据域名查询，但首先需要走出所处的局域网，这就需要局域网默认网关路由器的MAC地址
    > 每一个主机都在一个局域网里，要访问局域网以外的主机就需要先离开这个局域网，而离开局域网就需要通过路由器实现
    > 而局域网内，是通过MAC地址定位的，而之前直到了默认网关路由器的IP地址，现在就需要通过ARP将其解析为MAC地址
  1. 主机生成 **ARP 查询报文**，目的 IP 是**默认网关路由器**，然后把帧发给交换机，交换机看到是广播地址就给广播出去
     - 目的MAC地址： `FF:FF:FF:FF:FF:FF`（广播地址）
  2. 默认网关路由器接收到这个帧，提取得到 ARP 报文，发现**目的 IP 与其中某个接口的 IP 匹配**，就发送回去一个 ARP 应答报文给主机，这里包含他自己的 MAC地址

3. 查找目的域名的IP：DNS域名系统 
   1. 主机生成一个 DNS 查询报文，并将其放入以太网帧，发送到网关路由器
      - 目的端口： 53 号端口（DNS服务器的端口）
      - 目的IP地址：DNS服务器的IP地址
   2. 网关路由器接收到该帧后，提取其中的IP地址，根据路由表进行转发。
      - 路由器具有**内部网关协议（RIP路由信息协议、OSPF开放最短路径优先协议）**和**外部网关协议（BGP边界网关协议）**，因此路由表中已经配置了**从路由器到达 DNS 服务器的路由表项**
   3. DNS服务器收到帧后，提取出DNS查询报文，并在 DNS 数据库中查找待解析域名对应的 IP 
   4. 找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 ==UDP== 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机
      > DNS在域名解析时使用DNS，但在区域传送时使用TCP 
      > 区域传送：**辅域名服务器**会定时向**主域名服务器**进行查询以便了解数据是否有变动，有变动则执行区域传送，进行数据同步（数据量较大，所以用TCP）

4. TCP三步握手 与 HTTP 请求页面
   - 有了 HTTP 服务器的 IP 地址之后，主机就能够**生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文**。
   - 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行**三次握手**来建立连接。
   - 连接建立之后，浏览器生成 `HTTP GET` 报文，并交付给 HTTP 服务器。
   - HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。
   - 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。

附一张形象的图片：![](http://blog-img.coolsen.cn/img/image-20210525172545204.png)

## 域名解析的详细流程

以www.baidu.com为例

1. **浏览器搜索自己的DNS缓存**（维护一张域名与IP的对应表）；
2. 若没有，则搜索**操作系统的DNS缓存**（维护一张域名与IP的对应表）；
3. 若没有，则搜索操作系统的**hosts文件**（维护一张域名与IP的对应表）。
4. 若都没有，则找 tcp/ip 参数中设置的**首选 dns 服务器**，即**本地 dns 服务器**（**递归查询**）
5. **本地域名服务器查询自己的dns缓存**，如果没有，则进行**迭代查询**，分别向根域名服务器、顶级域名服务器、权限域名服务器发起查询，并将结果返回给主机

## 什么是 Cookie 和 Session ?

**什么是 Cookie**

HTTP Cookie（也叫 Web Cookie或浏览器 Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。**Cookie 使基于无状态的 HTTP 协议记录稳定的状态信息成为了可能**。

- 如果设置了过期时间，则保存在硬盘中，直到过期时间结束才消失
- 如果没有设置过期时间，则保存在内存中，生命周期随着浏览器的关闭而结束（简称会话Cookie）

Cookie 主要用于以下三个方面：

- 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
- 个性化设置（如用户自定义设置、主题等）
- 浏览器行为跟踪（如跟踪分析用户行为等）

**什么是 Session**

Session代表Server和Client的一次**会话过程**，存储特用户会话所需的属性与配置信息，当用户在应用程序的Web页之间跳转时，存储在Session对象中的变量不会丢失。

Session是身份认证的重要凭证，在用户登录后由服务器分发给用户，保存在客户端（客户端存个ID就可以了）与服务端，用户在请求时需要附带SessionID，以辨识自己的身份。
当服务器收到请求，需要创建Session对象时，会检查请求中是否包含SessionId，如果有，则直接根据该ID返回Session对象。

session将信息存储在服务端，解决了cookie的不安全问题

## Cookie 和 Session 是如何配合的呢？

用户第一次请求服务器，服务器根据用户提交的相关信息，创建对应的 `Session`，请求返回时将此 Session 的唯一标识信息 `SessionID` 返回给浏览器，浏览器接收到服务器返回的 `SessionID` 信息后，会将此信息存入到 `Cookie` 中，同时 Cookie 记录此 `SessionID` 属于哪个域名。

当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 `Cookie` 信息，如果存在自动将 `Cookie` 信息也发送给服务端，服务端会从 Cookie 中获取 `SessionID`，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。

根据以上流程可知，SessionID 是连接 Cookie 和 Session 的一道桥梁，大部分系统也是根据此原理来验证用户登录状态。

> 如果用户禁用Cookie，可以通过`response.encodeURL(url)`实现URL重写，**将SessionID拼接到URL之后**

## Cookie和Session的区别？

- **作用范围**不同，Cookie 保存在客户端（浏览器），Session 保存在服务器端。
- **存取方式**的不同，Cookie 只能保存 ASCII，Session 可以存任意数据类型，一般情况下我们可以在 Session 中保持一些常用变量信息，比如说 UserId 等。
- **有效期**不同，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。
- **隐私策略**不同，Cookie 存储在客户端，比较容易遭到不法获取，早期有人将用户的登录名和密码存储在 Cookie 中导致信息被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。
- **存储大小**不同， 单个 Cookie 保存的数据不能超过 4K，Session 可存储数据远高于 Cookie。


## 为什么Cookie不安全

1. Cookie欺骗：
   - 虽然Cookie中的内容通常都是加密的，即时被被人截获了，也不会暴露信息，但它可以将Cookie提交给服务器，从而冒充受害人的身份，从而访问用户的填写过的一些信息（Email、账户信息等）
2. Cookie截获：
   - Cookie以纯文本的形式在浏览器和服务器之间传送，很容易被他人非法截获和利用。
   - Cookie被非法用户截获后，然后在其有效期内重放，则此非法用户将享有合法用户的权益 

## 为什么Session更安全

1. SessionID存储在Cookie中，需要先攻破Cookie，才能获得SessionID。
   而且只有在登录后，或启动`session_start`时，cookie中才会有Session 
2. SessionID的有效时间较短，即时被别人获得了SessionID，也很有可能是失效的
3. SessionID是加密的 

## 如何考虑分布式 Session 问题？

在互联网公司为了可以支撑更大的流量，后端往往需要多台服务器共同来支撑前端用户请求，那如果用户在 A 服务器登录了，第二次请求跑到服务 B 就会出现登录失效问题。

分布式 Session 一般会有以下几种解决方案：

- **客户端存储**：
  - 直接将信息存储在cookie中，可保存不敏感信息
  - 但Cookie保存数据的大小与类型受限，且会增大网络开销

- **Nginx ip_hash 策略**：
  - 服务端使用 Nginx 代理，每个请求**按访问 IP 的 hash 分配**，这样**来自同一 IP 固定访问一个后台服务器**，避免了在服务器 A 创建 Session，第二次分发到服务器 B 的现象。
  - 但容易导致服务器的负载不均衡
- **Session 复制**：
  - 任何一个服务器上的 Session 发生改变（增删改），该节点会把这个 Session 的所有内容序列化，然后广播给所有其它节点。
  - 会严重增大网络开销，且占用内存较大
- **共享 Session**：
  - 服务端无状态化，将用户的 Session 等信息使用缓存中间件（如Redis）来统一管理，保障分发到每一个服务器的响应结果都一致。


## 什么是DDos攻击？

DDos全称Distributed Denial of Service，分布式拒绝服务攻击。最基本的DOS攻击过程如下：

1. 客户端向服务端发送**请求连接数据包**。
2. 服务端向客户端发送**确认数据包**。
3. 客户端**不向服务端发送确认数据包**，服务器一直等待来自客户端的确认，产生大量半连接，占用端口号与连接资源

DDoS则是采用分布式的方法，通过在网络上占领多台“肉鸡”，用多台计算机发起攻击。

DOS攻击现在基本没啥作用了，因为服务器的性能都很好，而且是多台服务器共同作用，1V1的模式黑客无法占上风。对于DDOS攻击，预防方法有：

- **减少SYN timeout时间**。在握手的第三步，服务器会等待30秒-120秒的时间，减少这个等待时间就能释放更多的资源。
- **限制同时打开的SYN半连接数目。**

## 什么是XSS攻击？

XSS也称 cross-site scripting，**跨站脚本**。这种攻击是**由于服务器将攻击者存储的数据原原本本地显示给其他用户所致的**。比如一个存在XSS漏洞的论坛，用户发帖时就可以引入**带有＜script＞标签的代码**，导致恶意代码的执行。

预防措施有：

- 前端：过滤。
- 后端：转义，比如go自带的处理器就具有转义功能。

## 什么是CSRF攻击

CSRF（Cross-site request forgery），中文名称：**跨站请求伪造**

CSRF攻击者在**用户已经登录目标网站**之后，诱使用户**访问一个攻击页面**，**利用目标网站对用户的信任，以用户身份在攻击页面对目标网站发起伪造用户操作的请求**，达到攻击目的。

​ CSRF 攻击的原理大致描述如下：
1. 有两个网站，其中A网站是真实受信任的网站，而B网站是危险网站。
2. 在用户登陆了受信任的A网站是，本地会存储A网站相关的Cookie，并且浏览器也维护这一个Session会话。
3. 如果用户在没有登出A网站的情况下访问危险网站B，那么**危险网站B就可以模拟发出一个对A网站的请求（跨域请求）对A网站进行操作**，
   - 在A网站的角度来看，并不知道请求是由B网站发出来的（**Session和Cookie均为A网站的**），这时便成功发动一次CSRF 攻击。

​ 因而 CSRF 攻击可以简单理解为：攻击者盗用了你的身份，以你的名义发送而已请求。CSRF能够做的事情包括：以你名义发送邮件，发消息，盗取你的账号，甚至于购买商品，虚拟货币转账......造成的问题包括：个人隐私泄露以及财产安全。

​因此，**大多数浏览器都会跨域请求作出限制**，这是从浏览器层面上的对 CSRF 攻击的一种防御，但是需要注意的是在复杂的网络环境中借助浏览器来防御 CSRF 攻击并不足够，还需要从服务端或者客户端方面入手防御。

https://www.cnblogs.com/hyddd/archive/2009/04/09/1432744.html

## 跨域请求问题

同源策略：如果两个页面的**域名、端口、使用的协议**都相同，则认为两个页面具有相同的源。

同源策略限制了从同一个源加载的文档或脚本与来自另一个源的资源进行交互的行为。这是一个用于隔离潜在恶意文件的重要安全机制。

产生跨域错误信息的条件：
- 浏览器端对跨域访问的限制，而不是服务端的限制（服务端收到了请求并正确返回）
- 请求了不同源的资源
- 发送的是 `XMLHttpRequest` 请求（使用 img 标签发送的请求为 json 类型，并不会报错）

只有同时满足了这三个条件，浏览器才会产生跨域错误。

为了防止CSRF攻击的发生，对跨域请求通常都会有许多限制：
1. 无法读取**非同源网页的 Cookie、LocalStorage 和 IndexedDB**
2. 无法**接触非同源网页的 DOM**
3. 无法**向非同源地址发送 AJAX 请求（可以发送，但浏览器会拒绝接受响应）** 
   - 可以通过JSONP请求代替AJAX请求，但不实用

最好的方法：修改服务器端（包括HTTP服务器和应用服务器）

## Cookie共享问题

cookie的主要属性有：
- name：名称
- value：cookie的值
- domain：可以访问此cookie的域名
  - 顶级域名设置的cookie可以共享给二级域名（需要指定domain主域名的host），也可以自己私有（不指定domain）
    - 例如，指定domain为`jd.com`之后，其`cookie`可以共享给`a.jd.com`
    - 同样，如果domain设置为`jd.com`，则`a.jd.com`和`b.jd.com`可以共享cookie
- path：可以访问此cookie的页面路径。
  - 比如domain是`abc.com`，path是`/test`，那么只有`/test`路径下的页面可以读取此cookie
- expires/Max-Age
其他的不写了

例如，对`game.yangbai.com`这个域名，其cookie有以下几种情况：
```java
//只有自己可以看到
setcookie("game", "yangbai");

//*.yangbai.com都可以看到
setcookie("game1", "yangbai", time() + 1000, "/", "yangbai.com");

//设置无效
setcookie("game2", "yangbai", time() + 1000, "/", "chip.game.yangbai.com");
```

## 介绍一下CDN

CDN即内容分发网络，是**将源站内容分发至全国的CDN节点**，从而**缩短用户查看对象的延迟**，**提高用户访问网站的响应速度与网站的可用性**的技术。

CDN分发的源站内容为静态资源：image、html、js、css等

而在实现静态内容分发的同时，CDN也实现了：
- 跨地域的全网覆盖
- 负载均衡
- 异地灾备
- 网站安全保障

![](./../images/计网/CDN.jpg)

CDN原理：
1. 用户点击页面上的内容URL时，经过本地DNS解析，**DNS 系统会最终将域名的解析权交给 CNAME 指向的 CDN 专用 DNS 服务器**
2. CDN 的 DNS 服务器将 **CDN 的全局负载均衡设备 IP 地址**返回用户
3. 用户向 CDN 的全局负载均衡设备发起内容 URL 访问请求
4. CDN全局负载均衡设备根据用户的IP地址、用户请求内容的URL进行分析，选择用户所属区域的**区域负载均衡设备**，
5. **区域负载均衡设备**会向**全局负载均衡设备**返回一台缓存服务器的IP地址
   - **该缓存服务器是离用户最近的、包含用户需要的内容的、有服务能力的缓存服务器**
6. 全局xx将区域xx的IP地址返回给用户，让用户对其发起请求
7. 用户向缓存服务器发起请求，缓存服务器返回用户请求的资源
   - 如果这台缓存服务器没有用户需要的资源，它就会向其上一级的缓存服务器请求内容，直至**追溯到网站的源服务器**，将内容拉到本地。 

## 有没有了解过交换机和集线器的区别？



## 冲突域和广播域的定义和区别？ 冲突域里面是什么发生了冲突？



## 怎么理解Servlet

servlet接口定义的是**一套处理网络请求的规范**，所有实现servlet的类，都需要实现它那五个方法，其中最主要的是两个生命周期方法 init()和destroy()，还有一个处理请求的service()

但servlet并不直接和客户端打交道，tomcat才是与客户端直接打交道的家伙，他监听了端口，请求过来后，根据url等信息，确定要将请求交给哪个servlet去处理，然后调用那个servlet的service方法，service方法返回一个response对象，tomcat再把这个response返回给客户端






















