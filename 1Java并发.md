# 补充

## 如果一个线程死亡了，怎么让它再次运行

线程死亡不能复生，只能节哀顺变

## notify和notifyAll的区别

notify()与wait()一起使用，即随机唤醒Monitor的waitSet中的一个线程，去竞争对象锁

而notifyAll()是唤醒所有线程去竞争

## CountDownLatch说一下



## CycliBarrier说一下（循环栅栏，一组线程达到同步点阻塞等待同组其他线程）


## 说一下reactor网络框架（select+read+业务处理+write）








## 实现线程安全的单例模式注意点？（存在问题，双重检测，volatile、synchronized、私有构造器）

实现方式：
1. 静态内部final对象
   - 饿汉式，类加载时就会初始化 
3. 静态内部final volatile对象，但通过双重判断获取
   - 懒汉式 
   - 一定要使用volatile对象，不然会由于指令重排序导致出错
2. **内部类**中的静态final对象
   - 懒汉式，内部类在真正用到时才会初始化 

值得注意的点：
1. 三种单例模式的方法都是向外暴露`getInstance()`接口，隐藏私有的构造函数，从而实现将对象的生命周期控制权掌握在自己手中。
2. 需要通过`final`防止子类继承，破坏单例
3. 如果实现了序列化接口
   - 要在反序列化时直接返回内部的单例对象，防止反序列化通过字节码生成新的对象，破坏单例


>饿汉式：类加载时就会导致该单例对象被创建
懒汉式：类加载不会导致该单例对象被创建，而是首次使用该对象时才创建

```java
//问题1：为什么加final？
//答案1：为了防止子类继承破坏单例
//问题2：如果实现了序列化接口，还要做什么来防止反序列化破坏单例
//答案2：重写public Object readResolve()方法，直接返回INSTANCE，这样就可以不将反序列化通过字节码生成的对象作为返回结果，防止破坏单例
public final class Singleton implements Serializable{
    //问题3：为什么构造函数是私有的？能否防止反射创建新的实例？
    //答案3：为了防止外部调用构造函数，破坏单例；不能防止反射创建新实例，反射可以得到构造器对象，设置构造器对象的Accessable为True，从而破坏单例
    private Singleton(){}
    //问题4：这样初始化是否能保证单例对象创建时的线程安全？
    //答案4：可以的，因为这里的单例对象是静态的，会在类加载时就调用，且只执行一次。
    private static final Singleton INSTANCE = new Singleton();
    //问题5：为什么提供静态方法，而不是将INSTANCE设置为public
    //答案5：1.用方法来实现单例，可以提供更好的扩展性，例如扩展为懒汉式；2.可以自定义控制方法；3.可以提供泛型的支持；
    public static Singleton getInstance(){
        return INSTANCE;
    }
}
```


```java
//单例模式的一个范例
public final class Singleton{
    private Singleton(){}

    //问题1：属于懒汉式还是饿汉式
    //答案1：懒汉式，因为内部类在调用时才会执行类加载等流程，进行静态内部成员的初始化
    private static class LazyHolder{
        static final Singleton INSTANCE = new Singleton();
    }

    public static Singleton getInstance(){
        return LazyHolder.INSTANCE;
    }
}
```

```java
//显然，等到调用getInstance()时，才会初始化，是懒汉式
public final class Singleton{
    private static volatile Singleton INSTANCE = null;
    public static Singleton getInstance(){
        if(INSTANCE == null){
            synchronized(Singleton.class){
                if(INSTANCE == null){
                    INSTANCE = new Singleton();
                }
            }
        }
        return INSTANCE;
    }
}
```

```java
//问题1：枚举单例是如何限制实例个数的？
//答案1：枚举类是通过静态成员变量实现单例的
//问题2：枚举单例在创建时是否有并发问题？
//答案2：没有，因为枚举类内的成员变量是静态的
//问题3：枚举单例能否被反射破坏单例？
//答案3：不能，因为反射通过Class#newInstance()方法创建对象时，会检查该类是否被ENUM修饰，如果是则抛出异常
//问题4：枚举单例能否被反序列化破坏单例？
//答案4：不能，因为枚举类的父类中，反序列化是通过valueOf实现的，不是通过反射实现的
//问题5：枚举单例属于懒汉式还是饿汉式？
//答案5：静态成员变量，饿汉式
//问题6：枚举单例如果希望加入一些单例创建时的初始化逻辑，应该怎么做？
//答案6：写一个构造方法即可
enum Singleton{
    INSTANCE;
}
```

## ReentrankLock底层用了哪些jvm有关的操作

AQS的state、head指针、tail指针都是volatile的，保证了其可见性与有序性

而AQS加锁的操作时基于LockSupport的用于阻塞线程的`park()\unpark()`方法的

而LockSupport的阻塞、解除阻塞是基于`UNSAFE`的静态方法实现的，它是直接操作内存的底层接口，由JVM提供支持。（实际上就是生产与消费许可的过程）

https://baijiahao.baidu.com/s?id=1666548481761194849&wfr=spider&for=pc

## 如果ReentrankLock中存在一个非volatile的属性，线程一访问后释放锁，线程二去获取，是否保持可见性

不能保证可见性

# 应用


## 写出基于可重入锁的阻塞队列
## 2个线程交替打印A1B2C3D4...

### Synchronized、wait、notify
```java
public static void main(String[] args) {
    final Object o = new Object();

    char[] aI="1234567".toCharArray();
    char[] aC="ABCDEFG".toCharArray();

    new Thread(()->{
        synchronized (o){
            for (char c : aI) {
                try {
                    System.out.println(c);
                    o.wait();
                    o.notify();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
            o.notify();
        }
    },"t1").start();

    new Thread(()->{
        synchronized (o){
            for (char c : aC) {
                System.out.println(c);
                o.notify();
                try {
                    o.wait();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
            o.notify();
        }
    },"t1").start();

}
```
### LockSupport
```java
public class TestLockSupport {

    static Thread t1=null,t2=null;

    public static void main(String[] args) {

        char[] aI="1234567".toCharArray();
        char[] aC="ABCDEFG".toCharArray();

        t1=new Thread(()->{
            for (char c : aI) {
                System.out.println(c);
                LockSupport.unpark(t2);
                LockSupport.park();
            }
        },"t1");


        t2=new Thread(()->{
            for (char c : aC) {
                LockSupport.park();
                System.out.println(c);
                LockSupport.unpark(t1);
            }
        },"t1");
        t1.start();
        t2.start();
    }
}
```
### CAS自旋锁+volatile
```java
 enum  ReadyToRun {T1,T2}

//先定义T1准备运行  而且要设置volatile 线程可见
static volatile ReadyToRun r=ReadyToRun.T1;

public static void main(String[] args) {

    char[] aI="1234567".toCharArray();
    char[] aC="ABCDEFG".toCharArray();


    new Thread(()->{
        for (char c : aI) {
            //如果不是T1准备运行 就一直返回空，直到T1运行打印，打印完之后把准备运行的变为T2
            while (r!=ReadyToRun.T1){}
            System.out.println(c);
            r=ReadyToRun.T2;
        }

    },"t1").start();


    new Thread(()->{
        for (char c : aC) {
            //如果不是T2准备运行 就一直返回空，直到T2运行打印，打印完之后把准备运行的变为T1
            while (r!=ReadyToRun.T2){}
            System.out.println(c);
            r=ReadyToRun.T1;
        }

    },"t1").start();

}

```
### AtomicInteger
```java
public class TestLockSupport {

    
    //定义一个原子性的对象
    static AtomicInteger thredNo=new AtomicInteger(1);

    public static void main(String[] args) {


        char[] aI="1234567".toCharArray();
        char[] aC="ABCDEFG".toCharArray();


        new Thread(()->{
            for (char c : aI) {
                //如果不是1就一直返回空，直到运行打印，打印完之后把原子对象变成2
                while (thredNo.get()!=1){}
                System.out.println(c);
                thredNo.set(2);
            }

        },"t1").start();


        new Thread(()->{
            for (char c : aC) {
                //如果不是2就一直返回空，直到运行打印，打印完之后把原子对象变成1
                while (thredNo.get()!=2){}
                System.out.println(c);
                thredNo.set(1);
            }

        },"t1").start();

    }
}


```
## 三个线程交替打印ABCABCABC。。。

### Synchronized、wait、notify

### LockSupport

### CAS自旋锁+volatile

### AtomicInteger

## 写一个生产者消费者模型

## 写一个阻塞队列（还是啥来着）

## 写一个线程池

# 基础


## 线程中的常见方法

|  方法名 |  功能说明 |  注意| 
| --| --| --| 
| `start()`| 启动一个新线程，在新的线程运行`run()`方法中的代码 | start方法只是让线程进入就绪状态，代码并不一定立即执行（CPU的时间片还没分配给他）。**每个线程对象的start方法只能调用一次**，如果调用多次，会出现IllegalThreadStateException| 
| `run()`| 新线程启动后会调用的方法| 如果在构造Thread对象时传递了Runnable参数，则线程启动后会调用Runnable中的run方法，否则默认不执行任何操作。但可以创建Thread的子类对象，来覆盖默认行为| 
|  `join()`|  等待线程运行结束（可带参数，表示等待的毫秒数）| `join()`方法内部会调用`obj.wait()`，因此会释放对象锁。超时则进入`TIME_WAIT` | 
|  `sleep(long n)`|  让当前执行（占用CPU）的线程休眠n毫秒，让出时间片，但==不会让出锁==| 则进入`TIME_WAIT` | 
| `yield()`：让步|  提示线程调度器，让出当前线程对cpu的使用权限| 重新回到`RUNNABLE`状态| 
|  `interrupt()`|  请求打断线程|  如果被打断线程正在`sleep`、`wait`，`join`会导致被打断的线程抛出`InterruptedException`，并**清除打断标记**；如果打断的是**正在运行的线程**，则会**设置打断标记**；**park的线程**被打断，也会**设置打断标记**| 
|  `isInterrupted()`|  判断线程是否被打断|  | 
|  `(static)interrupted()`|  判断线程是否被打断|   ==会清除打断标记== | 
|  |  |  | 
|  `obj.wait()`|  让进入obj的monitor的线程到waitset等待|   会释放对象锁 | 
|  `obj.wait(long time)`|  释放对象锁，进入waitset等待，如果经过time时间后，还没有被notify，则进入EntryList，重新竞争锁|  | 
|  `obj.notify()`|  将waitset中的线程选择一个唤醒|  | 
|  `obj.notifyAll()`|  将waitset中的所有线程唤醒|  | 
|  |  |  | 
|  `concidion1.await()`|  用于条件变量Condition，与wait()原理类似|  | 
|  `concidion1.signal()`|  与notify()、notifyAll()类似 |  | 
|  |  |  | 
|  `fork()` |  |  | 
|  `join()` |  |  | 
|  |  |  | 
|  `LockSupport.park()` |  |  | 
|  `LockSupport.unpark()` |  |  | 
|  |  |  | 
|  不推荐的方法|  |  | 
|  `stop()`|  真正的杀死线程，而不是像interrupt一样，给线程传一个中断信号|   因为被终止的线程会立刻释放锁，可能导致一致性被破坏 | 
|  `suspend()`|  挂起线程|  | 
|  `resume()`|  恢复线程运行|  |


## 线程和进程有什么区别？

- 进程：一个程序执行的过程，执行前需要将改程序放到内存中，才能被CPU处理（单处理机系统中，同一时刻只能有一个进程占用处理机）
  - 进程是程序的一次执行过程；
  - 是一个程序及其数据在处理机上顺序执行时发生的活动；
  - 是具有独立功能的程序在一个数据集合上运行的过程；
  - 是系统进行==资源分配的基本单位==
- 线程：基本的CPU执行单元，也是程序执行流的最小单元，是进程中的一个实体，是被系统==独立调度与分派的基本单位==，拥有一些运行时必不可少的资源
  - 线程切换只需要保存与设置少量寄存器内容，开销很小
  - 同一进程内的多个线程共享进程的地址空间，线程间的同步与通信很容易实现

## 说说你对并发编程的理解（Java 如何进行并发控制）（这种开放题其实不好回答，很容易给自己挖坑）

并发编程主要就是要解决在多线程环境下的线程安全问题。

而Java的线程通信与同步方式是通过共享内存的方式实现的，因此，在一些被多个线程共享的变量的读写上，就可能出现与单线程情况下不同的情况，导致出现错误；
而Java的并发编程手段主要就是针对Java中方法的一些同步手段。

其中，主要可以分为基于锁的同步与无锁同步两大块。前者主要包含`Synchronized`以及`JUC`并发包下的`Lock`接口的一众实现类，而后者主要是基于`Volatile`变量、`CAS`操作实现的类。

## 简单说一下什么是线程安全

> 进程是资源分配的最小单位，线程是调度的最小单位；
> 同一进程内的多个线程是并行执行的，即在同一时间，可能有多个线程在执行；
> 

而Java的线程通信与同步方式是通过共享内存的方式实现的，因此，在一些被多个线程共享的变量的读写上，就可能出现与单线程情况下不同的情况，导致出现错误；

而线程安全指的就是：在调用这些方法时，不需要对这些方法的调用增加额外的同步措施，就说明这个方法或类是线程安全的


成员变量和静态变量是否线程安全？
- 没有被共享或不可变：安全
- 被共享
  - 只读，安全
  - 读写，则这段代码是临界区，需要考虑线程安全问题

局部变量是否线程安全：
- 局部变量是线程安全的
- 但局部变量引用的对象未必
  - 如果该对象没有逃离方法的作用范围，则线程安全

## 如何定义原子性

即拥有原子性的一条语句或一组语句同时成功或同时失败，视作一个不可再分的语句。

## 多线程会产生哪些并发问题（什么情况下会有线程安全的问题）

1. 安全性问题
   - 所谓安全性问题，即正确性，是指程序有没有按照我们的期待执行
   1. 可见性问题
      -  一个线程对共享变量的更改，可能不会被另一个线程看到，导致可见性受到影响
   2. 有序性问题
      - 在并发环境下，代码中的各个方法会经过编译器、处理器的优化，导致代码的运行顺序改变，行为与单线程环境下不同
   3. 原子性问题  
      - 操作系统只为线程分配了一定长度的时间片，如果线程运行时间超过了时间片长度，就需要回到RUNNABLE状态，重新竞争CPU，这会导致线程的语句被打断，出现很多奇怪的问题 
2. 活跃性问题
   - 多线程环境下，如果编码不当，会出现死锁、饥饿的等情况，影响程序活跃性 
3. 性能问题
   - 线程的切换需要进行上下文的切换：首先挂起当前线程，然后把当前线程状态存在某处，以便线程切换回来知道执行到哪里了，这个线程状态包含当前线程执行的指令和位置，这个状态就是上下文
   - 内存同步：JMM规定了主内存与线程内存，线程内存会缓存数据以加快计算速度；但多线程使用了synchronized、volatile等关键字，会影响线程缓存、指令重排序、编译器优化、处理器优化等手段，降低性能

## 怎么获取线程的返回值

1. 调用Future接口的实现类

## 创建线程的三种方式的对比？

**1）采用实现Runnable、Callable接口的方式创建多线程。**

**优势**：
线程类只是实现了`Runnable`接口或`Callable`接口，还可以继承其他类。
在这种方式下，**多个线程可以共享同一个target对象**，所以非常适合多个相同线程来处理同一份资源的情况，从而可以将CPU、代码和数据分开，形成清晰的模型，较好地体现了面向对象的思想。

**劣势：**
编程稍微复杂，如果要访问当前线程，则必须使用Thread.currentThread()方法。

**2）使用继承Thread类的方式创建多线程**

**优势：**
编写简单，如果需要访问当前线程，则无需使用Thread.currentThread()方法，直接使用`this`即可获得当前线程。

**劣势：**
线程类已经继承了Thread类，所以不能再继承其他父类。

**3）Runnable和Callable的区别**

-  Callable规定**重写**的方法是`call()`，Runnable规定**重写**的方法是`run()`。
-  **Callable的任务执行后可返回值**，而Runnable的任务是不能返回值的。
-  Call方法可以**抛出异常**，run方法不可以。
-  运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。

## 为什么要使用多线程呢?

- 从计算机底层来说： 线程可以比作是轻量级的进程，是程序执行的最小单位，**线程间的切换和调度的成本远远小于进程**。
- 另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。
- 从当代互联网发展趋势来说： 现在的系统动不动就要求百万级甚至千万级的并发量，而**多线程并发编程正是开发高并发系统的基础**，利用多线程机制可以大大提高系统整体的并发能力以及性能。

从计算机底层来说：

- 单核时代： **在单核时代多线程主要是为了提高 CPU 和 IO 设备的综合利用率**。 
> 举个例子：当只有一个线程的时候会导致 CPU 计算时，IO 设备空闲；进行 IO 操作时，CPU 空闲。我们可以简单地说这两者的利用率目前都是 50%左右。但是当有两个线程的时候就不一样了，当一个线程执行 CPU 计算时，另外一个线程可以进行 IO 操作，这样两个的利用率就可以在理想情况下达到 100%了。
- 多核时代:**多核时代多线程主要是为了提高 CPU 利用率**。
> 举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，CPU 只会一个 CPU 核心被利用到，而创建多个线程就可以让多个 CPU 核心被利用到，这样就提高了 CPU 的利用率。

## Java 线程有哪些状态？

![](https://images-shf.oss-cn-beijing.aliyuncs.com/并发编程/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E6%8D%A2.png?versionId=CAEQHhiBgIDOlaCE.RciIGVmNjk0NDBiNTAzNjRjODE5ZjIyNWZmN2UwOTNhNDZi)

**Java线程具有六种基本状态**

1. **新建状态（New）**：当线程对象对创建后，即进入了新建状态，如：Thread t = new MyThread();

2. **就绪状态（Runnable）**：当调用线程对象的`start()`方法，线程即进入就绪状态。获得CPU时间片后也是RUNNABLE状态
  处于就绪状态的线程，只是说明此线程已经做好了准备，随时等待CPU调度执行，并不是说执行了t.start()此线程立即就会执行；
  > 注意：Java不区分Ready与Running，都划分到了Runnable中

3. **阻塞状态（Blocked）**：处于运行状态中的线程由于某种原因，暂时放弃对CPU的使用权，停止执行，此时进入阻塞状态。直到其进入到就绪状态，才有机会再次被CPU调用以进入到运行状态。
   1. 调用synchronized(object)获取锁失败，则进入Blocked状态

4. **等待状态（WAITING）**：
    1. t线程代用synchronized(obj)获得对象锁后：
       - 调用obj.wait()，t线程变为WAITING
       - 对处于WAITING的线程：调用obj.notify()、obj.notifyAll()、t.interrupt()时：
         - 竞争锁成功，变为RUNNABLE
         - 竞争锁失败，变为BLOCKED 
    2. **当前线程**调用`t.join()`方法时，**当前线程**变为 WAITING
       - 注意，是**当前线程**在**t线程对象的Monitor**上等待
       - t线程运行结束，或调用了当前线程的interrupt()时，当前线程从WAITING 变为 RUNNABLe 
    3. 当前线程调用LockSupport.park()方法，会使当前线程变为WAITING
       - 调用LockSupport.unpark(目标线程)，线程的interrupt()，会让目标线程变回RUNNABLE

5. **TIMED_WAITING**： 
    1. t线程调用synchronized(obj)获取对象锁后
       - 调用obj.wait(long n)，使t线程变为`TIMED_WAITING`
          > t线程等待时间超过n毫秒，或调用obj.notify()、obj.notifyAll()、t.interrupt()时，则与`WAIT`状态一样，发起对锁的竞争
    2. 调用`Thread.sleep(long n)`、`t.join(long n)`等带有超时时间的方法
6. **Terminated**：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。


## time-waiting是什么？结束后变成什么状态，在什么情况下回进入time-waiting？

time-wait：线程调用`Thrread.sleep(long)`、`Object.wait(long)`等带有超时时间参数的方法后，由于仍未获得等待的对象的锁，所以进入了`TIME_WAIT`的状态
在此状态下，不会释放已经持有的锁（等待锁应该是进入BLOCKED状态）
在time-waiting之后，线程重新回到`RUNNABLE`状态，开始竞争锁

进入time-waiting的方式：
1. 通过synchronized获得锁后，调用`obj.wait(long n)`；或在其他情况下，使用带有时间参数的加锁方法
2. 调用`join(long n)`方法
3. 调用`Thread.sleep(long n)`方法

## 怎么停止一个线程

1. 使用标志位终止线程
   - 在 run() 方法执行完毕后，该线程就终止了。但是在某些特殊的情况下，run() 方法会被一直执行（`while true`），此时可以通过标志位终止线程
   > 在run()方法中，不使用`while true`，而是使用`while !标志位`
2. 使用`stop()`终止线程
   - 但`stop()`作为强制终止线程的方法，现已被弃用（会导致线程中断，出现很多问题）    
3. 使用`interrupt()`终止线程
   - 比较合适的方法，`interrupt()`是利用线程的标志位，实现通知线程应当中断，而中断的时机由线程自己决定

## Java线程状态和操作系统线程状态有什么不同？

Java线程中，`RUNNABLE`包含了操作系统线程状态的`就绪READY`+`运行RUNNING`。

在操作系统中，当线程处于`READY`状态，说明已经做好了准备，可以等待CPU的时间片，而得到时间片开始运行后，就到了`RUNNING`状态，

> 注意：操作系统内核调度的对象的确是==线程==，且调度算法具有普适性，因此线程调度算法与进程调度算法类似。

> 个人认为，这么设计是因为JAVA实现多线程与操作系统进程、线程调度算法的区别

## 两个线程，一个线程OOM，另一个线程能不能正常运行

取决于发生OOM的区域，如果发生OOM的是线程独占的虚拟机栈，则只会影响对应的线程，但如果发生OOM的是堆、方法区、直接内存，就可能影响到其他线程的运行

## 常见的对比

### Runnable vs Callable

- Callable仅在 Java 1.5 中引入，目的就是为了来处理Runnable不支持的用例。
- Callable 接口可以返回结果或抛出检查异常；Runnable 接口不会返回结果或抛出检查异常，
- 工具类 Executors 可以实现 Runnable 对象和 Callable 对象之间的相互转换。（Executors.callable（Runnable task）或 Executors.callable（Runnable task，Object resule））

### execute() vs submit()

- execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；
- submit()方法用于提交需要返回值的任务。线程池会返回一个 Future 类型的对象，通过这个 Future 对象可以判断任务是否执行成功
  > 可以通过 Future 的 get()方法来获取返回值，
  get()方法会阻塞当前线程直到任务完成，
  而使用 get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。

### shutdown() VS shutdownNow()

- shutdown（） :关闭线程池，线程池的状态变为 `SHUTDOWN`。线程池不再接受新任务了，但是队列里的任务得执行完毕。
- shutdownNow（） :关闭线程池，线程的状态变为 `STOP`。线程池会终止当前正在运行的任务，并停止处理排队的任务并返回正在等待执行的 List。 
  > shutdownNow的原理是遍历线程池中的工作线程，然后逐个调用线程的`interrupt`方法来中断线程，所以无法响应中断的任务可能永远无法终

### isTerminated() VS isShutdown()

- isShutDown 当调用 shutdown() 方法后返回为 true。
- isTerminated 当调用 shutdown() 方法后，并且**所有提交的任务完成后**返回为 true

## sleep() 方法和 wait() 方法的区别和共同点?

### 区别

- sleep方法：是`Thread`类的静态方法，当前线程将睡眠n毫秒，线程进入`TIMED_WAITING`状态。当睡眠时间到了，会进入`RUNNABLE`状态，等待CPU的到来。==睡眠不释放锁（如果有的话）==。
- wait方法：是`Object`的方法，必须与`synchronized`关键字一起使用，线程进入`WAITING`或`TIMED_WAITING`状态，当`interrupt`、`notify`或者`notifyall`被调用后，会进行锁的竞争，成功则`RUNNABLE`，失败则`BLOCKED`。==睡眠时，会释放互斥锁==。

- sleep() 通常被用于暂停执行；wait() 通常被用于线程间交互/通信
- sleep() 方法到时间后，线程会自动苏醒；wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法（WAIT(long n)会自动苏醒）

## 如何对线程进行分析，用什么命令

1. ps -ef | grep java
2. top -Hp $pid
   - shift+t：查看cpu时间最多的几个线程，记录线程ID 
3. 把上诉线程ID转换成16进制小写  printf "%X\n"
4. jstack $pid|grep A -10  16进制线程id

## 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法

当我们通过`new`实例化Thread时，线程进入`NEW`新建状态;

-  调用`start()` 会执行线程的相应准备工作，启动线程，并进入就绪状态`RUNNABLE`，然后**Thread将自动执行 run() 方法的内容**，这是真正的多线程工作。
   
- 直接执行 `run()` 方法，会把 `run()` 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 
  
## 进程通信的几种方式

### 管道

可以看出**管道传输数据是单向的**，如果想相互通信，我们需要创建两个管道才行。

**管道这种通信方式效率低，不适合进程间频繁地交换数据**

**所谓的管道，就是内核里面的一串缓存**。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限。

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZckxn1SzJ697nE1m1wJzmPQmsrxa4AwDelPGglhe3DMPTKEpmGW7icSDnozDo7plETZlTWQJmcDVug/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img" style="zoom:50%;" />

### 消息队列

比如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。

**消息队列是保存在内核中的消息链表**，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。

消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。

**消息队列不适合比较大数据的传输**，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 `MSGMAX` 和 `MSGMNB`，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。

**消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销**，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。

### 共享内存

消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那**共享内存**的方式，就很好的解决了这一问题。

现代操作系统，对于内存管理，采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和 进程 B 的虚拟地址是一样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。

**共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中**。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。

### 信号量（访问共享资源的保护机制）

用了共享内存通信方式，带来新的问题，那就是如果多个进程同时修改同一个共享内存，很有可能就冲突了。例如两个进程都同时写一个地址，那先写的那个进程会发现内容被别人覆盖了。

为了防止多进程竞争共享资源，而造成的数据错乱，所以需要**保护机制**，使得共享的资源，在任意时刻只能被一个进程访问。正好，**信号量**就实现了这一保护机制。

**信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据**。

信号量表示资源的数量，控制信号量的方式有两种原子操作：

- 一个是 **P 操作**，这个操作会把信号量减去 -1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。
- 另一个是 **V 操作**，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；

### 信号

**对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。**

运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如

- Ctrl+C 产生 `SIGINT` 信号，表示终止该进程；
- Ctrl+Z 产生 `SIGTSTP` 信号，表示停止该进程，但还未结束；

信号是进程间通信机制中**唯一的异步通信机制**，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。

**1.执行默认操作**。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。Core 的意思是 Core Dump，也即终止进程后，通过 Core Dump 将当前进程的运行状态保存在文件里面，方便程序员事后进行分析问题在哪里。

**2.捕捉信号**。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。

**3.忽略信号**。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，它们用于在任何时候中断或结束某一进程。

### socket

前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想**跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。**

### 总结

由于每个进程的用户空间都是独立的，不能相互访问，这时就需要借助内核空间来实现进程间通信，原因很简单，每个进程都是共享一个内核空间。

Linux 内核提供了不少进程间通信的方式，其中最简单的方式就是管道，管道分为「匿名管道」和「命名管道」。

**匿名管道**顾名思义，它没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中，shell 命令中的「`|`」竖线就是匿名管道，通信的数据是**无格式的流并且大小受限**，通信的方式是**单向**的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道，再来**匿名管道是只能用于存在父子关系的进程间通信**，匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。

**命名管道**突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，那么毫无关系的进程就可以通过这个设备文件进行通信。另外，不管是匿名管道还是命名管道，进程写入的数据都是**缓存在内核**中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循**先进先出**原则，不支持 lseek 之类的文件定位操作。

**消息队列**克服了管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟**每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。**

**共享内存**可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，**它直接分配一个共享空间，每个进程都可以直接访问**，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有**最快**的进程间通信方式之名。但是便捷高效的共享内存通信，**带来新的问题，多进程竞争同个共享资源会造成数据的错乱。**

那么，就需要**信号量**来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。**信号量不仅可以实现访问的互斥性，还可以实现进程间的同步**，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 **P 操作和 V 操作**。

与信号量名字很相似的叫**信号**，它俩名字虽然相似，但功能一点儿都不一样。信号是进程间通信机制中**唯一的异步通信机制**，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），一旦有信号发生，**进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号**。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，这是为了方便我们能在任何时候结束或停止某个进程。

前面说到的通信机制，都是工作于同一台主机，如果**要与不同主机的进程间通信，那么就需要 Socket 通信了**。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。

## 线程通信的几种方式

线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。

### 1. 等待通知机制

两个线程通过对同一对象调用等待 wait() 和通知 notify() 方法来进行通讯。

等待通知有着一个经典范式：

线程 A 作为消费者：

1. 获取对象的锁。
2. 进入 while(判断条件)，并调用 wait() 方法。
3. 当条件满足跳出循环执行具体处理逻辑。

线程 B 作为生产者:

1. 获取对象锁。
2. 更改与线程 A 共用的判断条件。
3. 调用 notify() 方法。

伪代码如下:

```
//Thread A

synchronized(Object){
    while(条件){
        Object.wait();
    }
    //do something
}

//Thread B
synchronized(Object){
    条件=false;//改变条件
    Object.notify();
}
```

### 2. join() 方法

在 join 线程完成后会调用 notifyAll() 方法，是在 JVM 实现中调用，所以这里看不出来。

### 3. volatile 共享内存

### 4. 管道通信

### 5. 并发工具

CountDownLatch 并发工具

CyclicBarrier 并发工具

# Thread

## 介绍一下Thread中的各个方法

　Thread类实现了Runnable接口，在Thread类中，有一些比较关键的属性，比如name是表示Thread的名字，可以通过Thread类的构造器中的参数来指定线程名字，priority表示线程的优先级（最大值为10，最小值为1，默认值为5），daemon表示线程是否是守护线程，target表示要执行的任务

常用方法：
- start
- run
- sleep：sleep相当于让线程睡眠，交出CPU，让CPU去执行其他的任务
  - sleep不会释放锁
- join：假如在main线程中，调用`thread.join`方法，则main方法会等待`thread`线程执行完毕或者等待一定的时间。
- yield：调用yield方法会让当前线程交出CPU权限，让CPU去执行其他的线程。它跟sleep方法类似，同样不会释放锁。但是yield不能控制具体的交出CPU的时间，另外，yield方法只能让拥有相同优先级的线程有获取CPU执行时间的机会。
  - 注意，调用yield方法并不会让线程进入阻塞状态，而是让线程重回就绪状态，它只需要等待重新获取CPU执行时间，这一点是和sleep方法不一样的
- interrupt：单独调用interrupt方法可以使得处于阻塞状态的线程抛出一个异常，也就说，它可以用来中断一个正处于阻塞状态的线程；另外，通过interrupt方法和isInterrupted()方法来停止正在运行的线程
- stop、destroy：已废弃的方法

## Thread类中的yield方法有什么作用？

`yield方法可以**暂停当前正在执行的线程对象**  ，**让其它有相同优先级的线程执行**。它是一个静态方法而且只保证当前线程放弃CPU占用而不能保证使其它线程一定能占用CPU，执行yield()的线程有可能在进入到暂停状态后马上又被执行。


# synchronized

## Java 线程的同步方式有哪些

主要包含基于锁的阻塞同步与无锁同步两类：

其中，基于锁的同步方式包含：
- 基于synchronized的同步方法、同步代码块
- 基于Lock接口的wait、notify
- 使用ReentrantLocal等JUC类实现的同步

无锁同步方式包含：（大多基于CAS、Volatile实现）
- 使用volatile变量实现的同步
- 使用ThreadLock变量实现的同步
- 使用阻塞队列实现的同步
- 使用原子变量实现的同步

## Java 是怎么加锁的，有哪些锁？分别在哪些场景使用？（各种分类，乐观锁、悲观锁...）

Java可以通过synchronized加锁，也可以通过Lock接口的实现类提供的方法进行加锁；

锁类型：
- 偏向锁/轻量级锁/重量级锁
  - 这三种是锁的状态，且使用于synchronized
  - 偏向锁：一段同步代码被同一个线程访问时，可以自动获得锁，不需要通过CAS进行同步
  - 轻量级锁：当其他线程竞争偏向锁时，会升级为轻量级锁，轻量级锁基于栈帧中的锁记录实现，通过CAS对对象头与锁记录中的域进行修改，来实现加锁
    > 轻量级锁考虑的是**竞争锁对象的线程不多，而且线程持有锁的时间也不长的情景**。
    因为阻塞线程需要 CPU 从用户态转到内核态，代价较大，如果刚刚阻塞不久这个锁就被释放了，那这个代价就有点得不偿失了，因此这个时候就干脆不阻塞这个线程，让它自旋的等待锁释放 
  - 重量级锁：当其他线程竞争轻量级锁时，如果经过一定次数的自旋仍未成功获取锁，则进入阻塞，锁膨胀为重量级锁，重量级锁基于锁记录与Monitor实现。
- 自旋锁
- 公平锁/非公平锁
  - 公平即多个线程按照申请锁的顺利获得锁，非公平指后申请的线程可能比前申请的线程先获得锁，即可能出现优先级反转或饥饿现象
  - ReentrantLock在AQS的基础上，可以通过构造函数指定是公平还是非公平，而由于synchronized没有基于AQS的支持，无法实现复杂的机制，只能是非公平锁
- 可重入锁
  - 重入指的是同一个线程在获得同一个锁时，不会因为自己已经获得锁而阻塞自己，而是可以多次获得同一个锁
- 独占锁/共享锁（互斥锁/读写锁）
  - 独占锁：只能被一个线程持有的锁；共享锁：可以同时被多个线程持有的锁
  - ReentrantLock是独占锁，但ReadWriteLock的读锁是共享锁，写锁是独占锁
  > 共享锁是为了尽可能的提高并发程度 
- 乐观锁/悲观锁
  - 乐观锁：乐观的认为，并发读取同一个数据时，这个数据不会被其他线程修改，不加锁的并发操作是不会有问题的，只要在对数据更新时判断在此期间变量是否改变即可。
  - 悲观锁：悲观地，并发读取同一个数据时，这个数据一定会被其他线程修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。
- 分段锁
   - 分段锁其实是一种细化锁粒度的设计，在JDK7之前的ConcurrentHashMap中使用，
    > 其中，实现了类似HashMap结构的Segment，其内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。
    进行put()时，并不对整个HashMap加锁，而是通过hashCode知道目标在哪个分段，然后对分段单独加锁

## 加锁会不会太重？（锁升级？）

从偏向锁、轻量级锁、重量级锁的膨胀角度回答，也可以考虑从共享锁的角度回答

## 锁降级与升级是啥

降级与升级是针对读写锁的

锁降级：重入时，写锁降级为读锁；即当一个线程获取了写锁与读锁（获取写锁的线程可以获取读锁），那么当该线程释放了写锁时，该线程拥有的锁就会进行降级，变为了读锁

锁降级的原因：只有当线程既需要写操作又需要读操作的时候，锁降级才有必要性。

> 读锁是共享锁，写锁是排它锁。如果在释放写锁之后再获得读锁，可能会有别的线程先抢着获得写锁，然后阻塞了读锁，造成数据的不可控性（感知不到数据的变化），也造成了不必要的cpu资源浪费。
> **使用锁降级可以在释放写锁前获取读锁，这样其他的线程就只能获取读锁**，对这个数据进行读取，但是不能获取写锁进行修改，只有当前线程释放了读锁之后才可以进行修改。

锁升级：重入时，读锁升级为写锁。**ReadWriteLock不支持锁升级**

## synchronized 原理

![](../images/并发编程/原理-Monitor.png)

JVM基于`Monitor`对象来实现方法同步和代码块同步，其中，代码块同步是使用`monitorenter`与`monitorexit`指令实现的，分别在编译后插入到同步代码块开始的位置与方法结束处、异常处。

- **进入synchronized代码块时，会将代码块内用到的变量从该线程的工作内存中清除，转而从主内存中获取**
- **退出synchronized代码块时，会将代码块内用到的变量的修改，刷新到主内存中**

任何对象都有一个`monitor`与之关联，当一个`monitor`被持有后，它将处于锁定状态。
线程执行到`monitorenter`指令时，将会尝试获取对象所对应的`monitor`的所有权，即尝试获得对象的锁。

除此之外，由于加锁存在较大的性能损耗，因此synchronized也进行了优化。即偏向锁、轻量级锁、重量锁与自旋锁

这些优化的基础是Java对象的对象头中的32bit的mark word，mark word中包含了锁的类型与其他相关的域。在锁升级的过程中，通过CAS来栈帧中的锁记录与mark word的内容。

https://blog.csdn.net/weixin_41430914/article/details/123218816


## 为什么加锁和释放锁会导致上下文切换

Synchronized是通过对象内部的一个叫做监视器锁（`monitor`）来实现的。
但是监视器锁本质又是依赖于底层的操作系统的`Mutex Lock`来实现的。
但是由于使用Mutex Lock**需要将当前线程挂起并从用户态切换到内核态来执行**，这种切换的代价是非常昂贵的，因此，这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”。

## synchronized 锁升级过程

![](https://images-shf.oss-cn-beijing.aliyuncs.com/并发编程/Mark%20Word%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96.png?versionId=CAEQHhiBgIDyoqCE.RciIDI5ZDIzNDg4NGVlMDRjZGVhMWFmNzNiMjg3MTU1MWMw)

![](../images/并发编程/原理-轻量级锁-2.png)
![](../images/并发编程/原理-轻量级锁-3.png)
- 轻量级锁
  1. synchronized首先会创建每个线程独有的LockRecord对象，其中可以存储锁定对象的mark word。
  2. 之后，修改LockRecord对象，将其中的Object reference指向锁定对象，并尝试通过CAS交换锁定对象的`mark word`
  3. 如果`CAS`替换成功，则被加锁对象的对象头中存储了**锁记录地址与状态00**，表示由该线程给对象加锁
  4. 如果`CAS`失败，若`object reference`指向其他对象，则说明存在竞争，**需要膨胀为重量级锁**；如果是自己，这说明发生了重入，则再创建一个lock record，记录重入次数
  > 解锁时，如果存在内容为null的锁记录，则代表存在重入，将其弹出；
  如果内容不为null，说明是最后一个锁记录，需要通过CAS将内容恢复到对象头中，**若恢复失败，说明发生锁膨胀**

![](../images/并发编程/原理-锁膨胀-2.png)
- 重量级锁
  1.  当Thread-1进行轻量级锁加锁时，Thread-0已经对该对象加锁了
  2.  此时Thread-1加锁失败，进入锁膨胀流程
        - 为Object对象申请`Monitor`锁，将Object的`mark word`替换为`Monitor`的地址
        -  然后将`Thread-1`加入Monitor的`EntryList`，进入`BLOCKED`状态
        -  而`Monitor`的`Owner`域指向当前正在持有锁的线程的`Lock Record`
  3. 当Thread-0退出同步代码块时，使用`CAS`将`Mark Word`的值恢复给对象头，==失败==。
   这时会进入重量级锁解锁的流程，即按照`Monitor`的地址找到锁对象，唤醒`EntryList`中的`BLOCKED`线程，将之前持有锁的线程的`Lock Record`锁记录内容替换到该线程的锁记录中，设置`Owner`为`null`，
   
- 自旋锁
  - 在重量级锁中，如果线程没有获得锁，就要加入EntryList，并进入BLOCKED状态，直到能够获得锁了，才被唤醒，这期间需要进行上下文的切换与用户态-内核态的切换，这会耗费一定的时间。
  - 因此，引入自旋锁，即在未获得锁时，不直接阻塞，而是继续尝试几次获取锁，最后才进入BLOCKED

- 偏向锁
  - 轻量级锁在没有竞争的情况下，每次重入仍然需要CAS操作，于是在Java6引入偏向锁进行优化
  - 偏向锁：只有在第一次使用`CAS`将线程ID设置到对象头的Mark Word头，**发现这个线程ID是自己的，就表示没有竞争，不需要CAS**，直接获取锁

## WAIT与synchronized是一个队列吗

WAIT是条件队列，synchronized是锁队列可以类比aqs的CONDITION条件队列和正常上锁的等待队列。

而且两个的状态也不同，

# volatile

## volatile 的作用、原理 (volatile 线程安全吗、volatile 能不能保证原子性......)

**volatile的两层语义**：

1、volatile保证**变量对所有线程的==可见性==**：
  - 修改volatile变量时，新值会立即同步到主内存中
  - 读取volatile变量时，会直接用主内存中的值更新工作内存中的值

2、jdk1.5后，**volatile完全避免了指令重排优化，实现了==有序性==**。

> 注意：Volatile只能保证**单次写入、读取的原子性**
> 当不能保证对`i++`这类操作的原子性，因为`i++`包含了三个步骤：
> 1. 读取i的值；2. 令i的值+1；3. 将i的值写回内存
> 其中`+1`操作的原子性需要由AtomicInteger或Synchronized保证

**volatile的原理:**

Java多线程中，每个线程都有自己的工作内存，需要和主存进行交互。
**这里的工作内存和计算机硬件的缓存并不是一回事儿**，只是可以相互类比。
所以，并发编程的可见性问题，是因为**各个线程之间的本地内存数据不一致导致的**，和计算机缓存并无关系。

**可见性的实现：**
线程**不直接与主内存进行数据的交互**，而是**通过线程的工作内存来完成相应的操作**，这也是导致数据可见性的原因。

- 对volatile变量的**写指令后**会加入**写**屏障
> 写屏障保证**在该屏障之前，对共享变量的改动，都同步到主存中**。
> 因此，**再读取该变量值的时候就需要重新从读取主内存中的值**。

- 对volatile变量的**读指令前**会加入**读**屏障
> 读屏障保证**在该屏障之后，对共享变量的读取，加载的都是主存中的最新数据**。

**有序性的实现：**

为了实现volatile内存语义，JMM会对volatile变量限制重排序。
- **写屏障**会保证指令重排序时，**不会将 写屏障之前的代码 排序到 写屏障之后**
- **读屏障**会保证，**读屏障之后的代码 不会排序到 读屏障之前**
> 写管前，读管后

但不能解决**指令交错**的问题
- 写屏障只能保证之后的读能读到最新结果，不能保证读操作跑不到它之前去
- 有序性的保证也只保证了**本线程内的代码不被重排序**

## Java中的内存屏障

Java级别的内存屏障是用于解决高速缓存引入导致的**可见性问题**与**重排序问题**：

> 硬件层面的内存屏障主要有两种：
> - Load屏障，在其他指令前插入ifence指令，可以让高速缓存中的数据失效，**强制当前线程从主内存里面加载数据**
> - Store屏障，在其他指令后插入sfence指令，能让**当前线程对高速缓存中的最新数据更新写入主内存**，让其他线程可见。

Java中的内存屏障主要有四种，由上述两种屏障组合而成：
- LoadLoad：例如`Load1; LoadLoad; Load2`，要求在Load2加载代码在要读取的数据之前，保证Load1加载代码要从主内存里面读取的数据读取完毕
- StoreStore：例如`Store1; StoreStore; Store2`，要求在Store2存储代码进行写入操作执行前，保证Store1的写入操作已经把数据写入到主内存里面，确认Store1的写入操作对其它处理器可见
- LoadStore：例如` Load1; LoadStore; Store2`，要求在Store2存储代码进行写入操作执行前，保证Load1加载代码要从主内存里面读取的数据读取完毕。
- StoreLoad：例如`Store1; StoreLoad; Load2`，要求在Load2加载代码在从主内存里面读取的数据之前，保证Store1的写入操作已经把数据写入到主内存里面，确认Store1的写入操作对其它处理器可见。

在Java中，内存屏障主要显式应用于两处：
- `synchronized`：
  - 当线程进入synchronized包围的区域时，**保证变量读取的值均为最新值**
    > 这是因为在同步区内对变量的写入操作，**在离开同步区时就将当前线程内的数据刷新到内存中**；
    而对数据的读取也**不能从缓存读取，只能从内存中读取**，保证了数据的读有效性。这就是插入了StoreStore屏障 
- `volatile`
  - 对`Volatile`变量的写操作会插入`StoreLoad`屏障，而其余的操作必须通过`Unsafe`这个类来执行


## mesi 协议

![](./../images/并发编程/CPU.jpg)

现代CPU的架构通常如上图所述，包含每个核独享的L1指令缓存、L1数据缓存、L2缓存以及所有核心共享的L3缓存

在此基础上，为了尽可能快地保持各个核的缓存与内存之间的一致性，CPU核心与L1缓存之间实际上还存在一层Buffer：
- CPU实现各个核的缓存与内存间的数据一致性的思路有点像socket的三次握手：
    1. CPU0修改某个数据，并广播给其他CPU
    2. CPU0进入阻塞状态，并**等待其他CPU修改其缓存中的状态**
    3. 待其他CPU完成缓存修改，并返回应答消息后，CPU0重新回到运行就绪状态
- 虽然阻塞的时间很短，但对于运行速度极快的CPU来说，仍然是不可忍受的
- 因此，为了保证这部分阻塞时间得到充分利用，加入了一层Buffer，在CPU阻塞期间，将**预读信息**存储进去，这样CPU解除阻塞后就可以直接处理buffer中的请求 

在此基础上，就进一步引出了MESI协议，即缓存一致性协议。
MESI协议保证了**每个缓存中使用的共享变量的副本是一致的**

MESI的实现思路：
- 如果CPU0修改了某个数据，需要广播给其他CPU
- 缓存中**没有这个数据的CPU丢弃这个广播消息**
- 缓存中有这个数据的CPU监听到这个广播后会，**将相应的缓存行改为invalid状态**，这样CPU在下次读取这个数据的时候**发现缓存行失效**，就去内存中读取

即存在数据修改，就要求CPU使用自己的缓存中的数据，而是去内存中重新读取数据

> 在此基础上，AMD和Intel实现了让CPU直接去修改数据的CPU0的缓存中获取数据的技术

https://zhuanlan.zhihu.com/p/270269628

## 内存屏障

[内存屏障](https://www.jb51.net/article/211749.htm#:~:text=Store%E5%B1%8F%E9%9A%9C%EF%BC%8C%E6%98%AFx86%E7%9A%84%E2%80%9Dsfence%E2%80%9C%E6%8C%87%E4%BB%A4%EF%BC%8C%E5%9C%A8%E5%85%B6%E4%BB%96%E6%8C%87%E4%BB%A4%E5%90%8E%E6%8F%92%E5%85%A5sfence%E6%8C%87%E4%BB%A4%EF%BC%8C%E8%83%BD%E8%AE%A9%E5%BD%93%E5%89%8D%E7%BA%BF%E7%A8%8B%E5%86%99%E5%85%A5%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98%E4%B8%AD%E7%9A%84%E6%9C%80%E6%96%B0%E6%95%B0%E6%8D%AE%E6%9B%B4%E6%96%B0%E5%86%99%E5%85%A5%E4%B8%BB%E5%86%85%E5%AD%98%EF%BC%8C%E8%AE%A9%E5%85%B6%E4%BB%96%E7%BA%BF%E7%A8%8B%E5%8F%AF%E8%A7%81%E3%80%82,%E5%9C%A8java%E9%87%8C%E9%9D%A2%E6%9C%894%E7%A7%8D%EF%BC%8C%E5%B0%B1%E6%98%AF%20LoadLoad%2CStoreStore%2CLoadStore%2CStoreLoad%EF%BC%8C%E5%AE%9E%E9%99%85%E4%B8%8A%E4%B9%9F%E8%83%BD%E7%9C%8B%E5%87%BA%E6%9D%A5%EF%BC%8C%E8%BF%99%E5%9B%9B%E7%A7%8D%E9%83%BD%E6%98%AF%E4%B8%8A%E9%9D%A2%E7%9A%84%E4%B8%A4%E7%A7%8D%E7%9A%84%E7%BB%84%E5%90%88%E4%BA%A7%E7%94%9F%E7%9A%84)

对于CPU的写，目前主流策略有两种：
- write through: CPU向内存写入数据时，同步完成store buffer与内存的写入
  - 严重影响CPU效率
- write back：CPU向内存写入数据时，**先把真实数据放入store buffer中**，待到某个合适的时间点，**CPU才会将store buffer中的数据刷到内存中**，而且这两个操作是异步的
  - 异步的更新操作在部分多线程场景下是不可接受的，会导致严重的数据一致性问题，因此引入了内存屏障进行优化

内存屏障是一个抽象的概念，它可以理解为一堵墙，这堵墙**正面与反面的指令无法被CPU乱序执行**，且这堵墙**正面与反面的读写操作需有序执行**

而CPU通过三个汇编指令串行化运行读写指令，达到了实现读写有序性的目的：
- SFENCE：该指令前的写操作，必须在该指令后的写操作之前完成
- LFENCE：该指令前的读操作，必须在该指令后的读操作之前完成
- MFENCE：该指令前的读写操作，必须在该指令后的读写操作之前完成



## volatile的特性？

- **可见性**：总是能看到（任意线程）对这个volatile变量最后的写入。
- **有序性**：Volatile通过内存屏障限制重排序，从而实现特定的运行顺序
- 原子性：对任意**单个volatile变量的读/写**具有原子性，但类似于volatile++这种复合操作不具有原子性。
- volatile写的内存语义：当写一个volatile变量时，**JMM 会把该线程对应的本地内存中的共享变量值刷新到主内存**
- volatile读的内存语义：当读一个volatile变量时，**JMM 会把该线程对应的本地内存置为无效，线程接下来将从主内存中读取共享变量**
- 它的缺点就是它只能对单个volatile变量的读写具有原子性，而锁是互斥行为，可以确保一个代码区域的执行原子性

## 锁的内存语义

- 当线程**获取锁**时，JMM会**把该线程对应的本地内存置为无效，从主内存中读取变量的最新值**。和 volatile 读 类似。
- 当线程**释放锁**时，JMM会把该线程对应的**本地内存中的共享变量刷新到主内存中**。和 volatile 写 类似。

> 线程A释放锁，随后线程B获取这个锁，这个过程实质上是**线程A通过主内存向线程B发送消息**。
> 线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了**线程A对共享变量所做修改的**消息。
> 线程B获取一个锁，实质上是线程B接收了之前某个线程发出的**在释放这个锁之前对共享变量所做修改的**消息。

## final域的内存语义

对于final域，编译器 和 处理器 要遵守两个 重排序规则：
- **构造函数内对一个final域的写入**，与随后**把这个被构造对象的引用赋值给一个引用变量**，这两个操作之间不能重排序
- 初次读一个**包含final域的对象的引用**，与随后**初次读这个final域**，这两个操作之间不能重排序


## 一个volatile变量，一个线程写，多个线程读，会不会有线程安全问题

由于使用了volatile变量，所以可以解决可见性与有序性问题，但实际上会不会出现线程安全问题，还是取决于写入的方式，如果是使用`i++`这种操作进行写入，当然还是会出现原子性的问题。

但其实还是要看实际业务逻辑是否允许出现短暂的脏读。
不加锁的优点是提高throughput。缺点在于，读线程可能无法立即读取最新的值。这个其实是某一种比较弱的一致性，叫做eventual consistency。

https://www.zhihu.com/question/31325454

## 写出volatile解决可见性问题的代码

https://www.cnblogs.com/zwh0910/p/15868968.html

```java
public class Demo1Jmm {
    public static void main(String[] args) throws InterruptedException {
        JmmDemo demo = new JmmDemo();
        Thread t = new Thread(demo);
        t.start();
        Thread.sleep(100);
        demo.flag = false;
        System.out.println("已经修改为false");
        System.out.println(demo.flag);
    }

    static class JmmDemo implements Runnable {
        public volatile boolean flag = true;
        public void run() {
            System.out.println("子线程执行。。。");
            while (flag) {
            }
            System.out.println("子线程结束。。。");
        }
    }
}
```

## synchronized 关键字和 volatile 关键字的区别

- volatile关键字是线程同步的轻量级实现，所以**volatile性能肯定比synchronized关键字要好**
- volatile关键字只能用于变量，而synchronized关键字可以修饰方法以及代码块。实际开发中使用 synchronized 关键字的场景还是更多一些。
- 多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞
- volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证
- volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。

# ThreadLocal


## ThreadLocal是什么？有什么用？

ThreadLocal，字面意思上为：**线程局部变量，也就是只有当前线程能够访问的变量**
> ThreadLocal的设计是**为每一个使用该变量的线程都提供一个变量值的副本**，每个线程都是改变自己的副本并且不会和其他线程的副本冲突，这样一来，从线程的角度来看，就好像每个线程都拥有了该变量。

简单说ThreadLocal就是一种以**空间换时间**的做法，在每个Thread里面维护了一个以开地址法实现的ThreadLocal.ThreadLocalMap，把数据进行隔离，数据不共享，自然就没有线程安全方面的问题了。

## 说一下ThreadLocal的原理和使用场景，以及使用的时候的注意事项（Threadlocal 为什么要设计 key 值）

在ThreadLocal的内部，`get()`与`set()`方法是基于`ThreadLocalMap`实现的，这个map的`key`为线程，`value`为当前线程的局部变量的值。

与HashMap不同的是，ThreadLocalMap中的`Entry`是继承于`WeakReference`类的，在Entry()构造器中，保持了==对 “键” 的弱引用`super(key)`==和==对 “值” 的强引用`this.value = value`==，但==对这个Entry的引用是强引用==
> 使用弱引用的原因：当没有强引用指向 `ThreadLocal` 实例时，它可被回收，从而避免内存泄露
> 如果使用的是**强引用**，对每一个Thread都维护一个`Key-Value`键值对，将会耗费大量内存，且GC无法回收这部分内存（一直被Map引用）
> 然而，如果对Entry的强引用不存在了，就会出现key被回收，但value没被回收的情况，即内存泄漏。因此，ThreadLocal需要调用`remove()`

使用场景：每条线程都需要存取一个同名变量，但每条线程中该变量的值均不相同。

# 无锁同步

## 多线程访问long和 double 会怎么样

在java中除了long，double之外的所有基本类型的读和赋值，都是原子性操作，线程安全的，而 64 位的 `long` 和 `double` 变量由于会被 JVM 当作两个分离的 32 位来进行操作，会出现两次写操作，这就造成了错位可能，所以不具有原子性，会产生字撕裂问题。
但是当定义 `long` 或 `double` 变量时，如果使用 `volatile` 关键字，就会可以实现（简单的赋值与返回操作的）原子性。


## 什么是 CAS 及其底层原理，局限性

CAS即`CompareAndSwap`，是乐观锁的核心。
CAS涉及三个基本操作数：内存地址V，旧的预期值A，要修改的新值B

当我们使用CAS更新一个变量时，**只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B**
而CAS操作的底层是通过`lock cmpxchg指令`实现的，即**通过一条处理器指令实现了CAS的一系列操作**，在单核CPU与多核CPU都能保证CAS这一系列操作的原子性。因此可以用于实现无锁同步。

但基于无锁同步的CAS也存在局限:
1. 在使用CAS实现同步时，通常需要**循环调用CAS**，并判断CAS是否成功；
   - 在并发量比较高的情况下，如果许多线程反复尝试更新某一个变量，却又一直更新不成功，循环往复，会给CPU带来很大的压力。
2. CAS机制所保证的只是一个变量的原子性操作，而不能保证整个代码块的原子性。比如需要保证3个变量共同进行原子性的更新，就不得不使用Synchronized了 
3. 基于CAS的无锁同步存在ABA的问题
   - 由于基于CAS的无锁同步是乐观锁，如果出现ABA问题，将会无法得知变量被其他线程修改了 



## CAS的ABA问题是啥

由于CAS是遵循乐观锁思想的无锁同步，其认为：并发读取同一个数据时，**这个数据不会被其他线程修改**，不加锁的并发操作是不会有问题的，只要在对数据更新时判断在此期间变量是否改变即可。

但如果一个线程把原值为A的数据修改为B，再修改为A，基于CAS的同步措施不会感知到这个数据已经被修改了。

解决方案：引入**版本号**，每次对变量进行修改，都需要将其版本号增加。


## 为什么无锁同步的效率高


- 无锁情况下，即使重试失败，线程仍然在高速运行，没有停歇，而synchronized会让线程在没有获得锁的时候，发生上下文切换，进入阻塞
    >需要完成t1用户态->t1内核态->t2内核态->t2用户态的切换，唤醒后被调度到又要切换回来，耗时长
- 线程上下文切换代价大
- 但无锁情况下，需要CPU的额外支持，如果没有分配到时间片，还是得进行上下文切换
    >CAS只是减少上下文切换
    且CAS在cpu时间片用完时，进入就绪态，线程切换消耗小


> 乐观锁一般用于系统竞争不大的情况下

## CAS的特点是什么

CAS的特点：
- 适用于线程数少且CPU核多的情况
- 基于乐观锁的思想：最乐观的设计，不怕别的线程修改共享变量，大不了重试
- synchronized基于悲观锁的思想：认为只要别人改了共享变量，就会失败
- 体现的是无锁并发、无阻塞并发（没有使用synchronized，不会陷入阻塞）


# AQS

## AQS简介

Java中的大部分同步类（Lock、Semaphore、ReentrantLock等）都是基于AbstractQueuedSynchronizer（简称为AQS）实现的。AQS是一种提供了原子式管理同步状态、阻塞和唤醒线程功能以及队列模型的简单框架。

## 原理

AQS核心思想是：
- 如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；
- 如果共享资源被占用，则调用`LockSupport.park()方法将Node中的线程状态改为WAITING，等待被唤醒或被中断` ，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要是通过类似双向链表实现的，将暂时获取不到锁的线程加入到队列中。


主要原理图如下：

![img](https://p0.meituan.net/travelcube/7132e4cef44c26f62835b197b239147b18062.png)

在AQS中，使用一个`Volatile`的`int`类型的成员变量`State`来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，通过CAS完成对State值的修改。

在FIFO队列中，**「头节点占有锁」**，也就是头节点才是锁的持有者，尾指针指向队列的最后一个等待线程节点，除了头节点和尾节点，节点之间都有**「前驱指针」**和**「后继指针」**

在AQS中维护了一个**volatile类型的共享变量state**，标识当前的资源是否被线程持有，多线程竞争的时候，会去判断state是否为0，尝试的去把state修改为1

### AQS数据结构

AQS中最基本的数据结构——`Node`，`Node`即为上面CLH变体队列中的节点。

线程两种锁的模式：

| 模式      | 含义                           |
| :--------: | :-----------------------------: |
| SHARED    | 表示线程以共享的模式等待锁     |
| EXCLUSIVE | 表示线程正在以独占的方式等待锁 |

`waitStatus`有下面几个值：

| 枚举      | 含义                                           |
| :--------: | :---------------------------------------------: |
| 0         | 当一个Node被初始化的时候的默认值               |
| 1 (`CANCELLED`) | 表示线程获取锁的请求已经取消了            |
| **-2 (`CONDITION`)** | **表示节点在等待队列中，节点线程等待唤醒**   |
| -3 (`PROPAGATE`) | 当前线程处在SHARED情况下，该字段才会使用 |
| **-1 (`SIGNAL`)**    | **表示线程已经准备好了，就等资源释放了**     |

### 同步状态State

AQS中维护了一个名为`State`的字段，意为同步状态，是由`Volatile`修饰的，用于展示当前临界资源的获锁情况。

AQS中的几个方法访问State的方法都是Final修饰的，说明子类中无法重写它们。
我们可以通过**修改State字段表示的同步状态**来实现多线程的独占模式和共享模式（加锁过程）。

![img](https://p0.meituan.net/travelcube/27605d483e8935da683a93be015713f331378.png)

![img](https://p0.meituan.net/travelcube/3f1e1a44f5b7d77000ba4f9476189b2e32806.png)

### AQS代码设计

AQS的设计模式采用了**模板方法模式**，子类通过**继承**的方式，实现它的**抽象方法**来管理同步状态。
子类并没有太多的工作，因为AQS提供了大量的模板方法来实现同步。
主要包含三类同步方法：**独占式获取和释放同步状态**、**共享式获取和释放同步状态**、**查询同步队列中的等待线程情况**。
自定义子类使用AQS提供的模板方法就可以实现自己的同步语义。

### Node的构建流程

构建当前线程的Node的流程：

1. 通过当前的线程和锁模式新建一个节点。
2. 将Pred指针指向尾节点`Tail`。
3. 通过CAS，将新建的Node的Prev指针指向Pred。
4. 进行尾节点的设置。


## ReentrantLock加锁流程

加锁流程：

1. 调用ReentrantLock的`lock()`方法加锁，此时会调用到内部类`Sync`的`lock()`，==其中，**非公平锁会首先抢占式地**通过CAS设置`State`，即获取锁==；
   - 成功则设置`Owner`为当前线程
   - 失败则调用`acquire(1)`，并首先调用`tryAcquire(arg)`，
2. 在`tryAcquire(arg)`中，会根据`State`进行判断
   - `State == 0`
     - 再==次尝试通过CAS公平地/非公平地（区别就是判断节点队列中有没有节点）尝试通过CAS获取锁，成功则return true==
   - `State != 0`但当前线程就是获得锁的线程，说明已经获得锁了
     - 进行重入，return true
3. 如果仍然获取锁失败，则回到`acquire()`方法中，构建`Node`节点，通过CAS将其放到队列的尾部
4. 在一个死循环中，找到**当前节点的前一个节点p**，==**如果p是head节点（dummy节点）**，再次调用 tryAcquire(arg) 尝试获取锁==：
   - **获取锁成功**，将当前节点设置为**新的dummy head节点**，并清空旧Dummy Head节点的引用关系，即可以被回收了，并设置`failed`标记位`false`（`failed`的初始值为true），返回`interrupted`
     > 注意，**这里返回`interrupted`是为了让`acquire`方法能够响应中断**，如果`interrupted`为`true`，则`acquire`会对当前线程调用`interrupt()`
     > > `interrupt()`方法只是**改变中断状态，不会中断一个正在运行的线程**。需要用户自己去监视线程的状态为并做处理

     > 在返回之前，会判断`failed`标记，如果为true，说明程序出错，直接取消获取锁，将Node的`waitStatus`设置为`-2：Cancelled` 

   - **获取锁失败 或 前一个节点不是head**：
     1. 如果前驱结点的 `waitStatus == -1`，则**进入第5步**
     2. 前驱结点的`waitStatus != -1`，则向前寻找第一个`waitStatus`为`-1`的前驱结点，删除两者之间的`waitStatus > 0`的**被取消的节点**，并继续自旋，即**重新执行第4步**，**重新尝试获取锁**
5. 通过`LockSupport.park(this)`让当前线程陷入阻塞
6. 当线程被唤醒后，返回`Thread.interrupted()`，清空`interrupted`标记
   - 若`interrupted`为`True`，将重新`interrupted`标记设置为true

正常情况下，

> 当节点的前驱是头结点（Dummy节点）时，就说明**当前节点可以尝试获取同步状态**。
> 所以在非公平锁中，`tryAcquire()`自旋CAS获取锁不需要判断前驱是不是head，但在公平锁中只有前驱为head，才能获取锁。


> 注意：这里的`tryAcquire(arg)`是需要子类自己实现的，根据公平、非公平的加锁机制，进行定制
> 当节点的前驱是头结点时，就说明当前节点获取到了同步状态。所以在非公平锁中，`tryAcquire()`自旋CAS获取锁不需要判断前驱是不是head，但在公平锁中只有前驱为head，才能获取锁。


## Lock怎么实现公平锁

1. 非公平锁在调用`lock()`方法时，会首先通过CAS将ReentrantLock的State从0修改为1，直接尝试获取锁，而不是先去排队；
   - 而公平锁则会直接取排队
2. 非公平锁在`tryAcquire()`方法中，会直接尝试使用CAS获取锁
   - 而公平锁会**先判断等待队列中有没有线程在排队**，如果有则不获取锁，之后才用过CAS获取锁

注意：在非公平锁中，只有节点在第一次尝试获取锁时，才是非公平的。
当节点加入队列后，同样只有Dummy节点的下一个节点能够获取锁

## 公平锁效率高还是非公平锁效率高，为什么

**非公平锁的效率 >> 公平锁**

在公平锁中，当后来的进程第一次获取锁时，就算锁是空闲的，它也需要去检查等待队列，查看有没有节点在等待，而非公平锁可以直接获取锁，**非公平锁多出来一次挂起和唤醒**

## ReentrantLock解锁流程

当线程获取同步状态后，执行完相应逻辑后就需要释放同步状态。AQS提供了release(int arg)方法释放同步状态：

`head`节点的下一个节点为获取锁成功的节点，当头结点在**释放同步状态**时，会唤醒后继节点，如果后继节点获得锁成功，会把自己设置为头结点，节点的变化过程如下


![](https://images-shf.oss-cn-beijing.aliyuncs.com/并发编程/ReentrantLock-%E9%9D%9E%E5%85%AC%E5%B9%B3%E9%94%81-%E8%A7%A3%E9%94%811.png?versionId=CAEQHhiBgICSn6CE.RciIGMxOGIwYTZmZTMzYTRmMTRiYjA4MzA4NmJlZTg4Mzgx)

![](https://images-shf.oss-cn-beijing.aliyuncs.com/并发编程/ReentrantLock-%E9%9D%9E%E5%85%AC%E5%B9%B3%E9%94%81-%E8%A7%A3%E9%94%81-%E6%81%A2%E5%A4%8D%E8%BF%90%E8%A1%8C.png?versionId=CAEQHhiBgICyn6CE.RciIDI2ZDU0MDc1MTdhMjQ4YzRiOTRkNWY2MDhjZmFkYTM2)

这个方法`release(int arg)`也是涉及到两个变化：
- 调用`tryRelease(arg)`方法，修改State的值，并将占有锁的线程设置为null
- 调用`unparkSuccessor(h)`，将当前Node的`waitStatus`修改为0，即废除，并找到下一个应当唤醒的节点，通过`LockSupport.unpark(next)`唤醒
  - 这样一来，后继节点就会在自旋获取锁的过程中，发现自己的前驱是head节点了，就回去获取锁

> 注意：修改`head节点`时不需要用CAS，原因是：设置`head节点`是**由获得锁的线程来完成的**，而同步锁只能由一个线程获得，所以不需要CAS保证，只需要把head节点设置为原首节点的后继节点，并且断开原head节点的next引用即可
> 但修改`Node`的`WaitStatus`时，需要通过CAS实现

通过上面的描述，大概可以总结出ReentrantLock加锁解锁时API层核心方法的映射关系。

![img](https://p0.meituan.net/travelcube/f30c631c8ebbf820d3e8fcb6eee3c0ef18748.png)

> **注意**:在公平锁尝试加锁之前，会利用 `hasQueuedPredecessors()` 方法来判断 AQS 的队列中中是否有其他线程，如果有则不会尝试获取锁(**这是公平锁特有的情况**)。



### 疑问

Q：某个线程获取锁失败的后续流程是什么呢？
A：线程会创建一个Node节点，并将其插入等待队列尾部，之后线程阻塞，等待节点的前驱结点对应的线程将当前线程唤醒，再尝试获得锁

Q：如果处于排队等候机制中的线程一直无法获取锁，需要一直等待么？还是有别的策略来解决这一问题？
A：线程所在节点的状态会变成取消状态，取消状态的节点会从队列中释放

## 需要在一个for循环里连续100次更新一个记录，这个过程中会出现阻塞吗，怎样规避这种情况（手动集成AQS）





## 介绍一下Lock接口的实现类

Lock接口是JDK5之后引入的，提供了与synchronized类似的同步功能，但在使用时需要显式地获得、释放锁。不如synchronized便捷，但可以提供比synchronized更加复杂的同步特性：

- 尝试非阻塞性获取锁： 当前线程尝试获取锁，如果此时没有其他线程占用此锁，则成功获取到锁。
- 能被中断的获取锁： 当获取到锁的线程被中断时，中断异常会抛出并且会释放锁。
- 超时获取锁： 在指定时间内获取锁，如果超过时间还没获取，则返回。









## synchronized和ReentrantLock 的区别

**1.两者都是可重入锁**

可重入锁：重入锁，也叫做递归锁，可重入锁指的是在一个线程中可以多次获取同一把锁，比如： 
一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，则该线程可以直接执行调用的方法，而无需重新获得锁。 

**2.synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API**

- synchronized 是基于 JVM 实现的，轻量级锁、偏向锁、自旋锁等优化均为基于JVM实现的
- ReentrantLock 是 JDK 层面实现的（也就是 API 层面，需要 `lock()` 和 `unlock()` 方法配合 `try/finally` 语句块来完成）

**3.ReentrantLock 比 synchronized 增加了一些高级功能**

相比synchronized，ReentrantLock增加了一些高级功能。主要来说主要有三点：①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件）

- 等待可中断.通过`lock.lockInterruptibly()`来实现这个机制。也就是说**正在等待的线程可以选择放弃等待，改为处理其他事情**。
- ReentrantLock可以指定是**公平锁**还是**非公平锁**。而synchronized只能是**非公平锁**。
- ReentrantLock类线程对象可以注册在指定的`Condition`中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用`notify()/notifyAll()`方法进行通知时，被通知的线程是由 JVM 选择的，**用ReentrantLock类结合Condition实例可以实现“选择性通知”**

**4.使用选择**

- 除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。
- synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放
 

## 说一下 ReentrantLock 可重入的原理

可重入的实现方式：在进行`tryAcquire()`时，如果当前`State > 0`，则会判断当先`OwnerThread`是否为当前线程，如果是，则令State递增



## 如何让可重入变成不可重入

只需要在子类中对加锁的核心方法`tryAcquire`与解锁的方法`tryRelease`进行重写，除去加锁时对重入的判断，即可实现不可重入

## 介绍一下ReentrantLock中的Condition

每个条件变量Condition对应一个等待队列，其实现类为`ConditionObject`

开始时，`Thread-0`持有锁，调用await，进入`ConditionObject`的`addConditionWaiter`流程，创建新Node，其状态为`-2(Node.CONDITION)`，关联`Thread-0`，加入Condition的等待队列尾部，并记录当时State的值，在后续通过CAS恢复State（为了恢复重入现场）

![](https://images-shf.oss-cn-beijing.aliyuncs.com/并发编程/ReentrantLock-Condition-1.png?versionId=CAEQHhiBgIDVoKCE.RciIDA3MTljNGJmZGQ4NDRjNzhhMzA0ZmE4ZWRlNmFhMGU4)

释放锁时，将Condition中的首个节点，加入锁的等待队列的尾部。


## 如果ReentrankLock中存在一个非volatile的属性，线程一访问后释放锁，线程二去获取，是否保持可见性

是保持可见性的，虽然ReentrantLock中并不像synchronized那样，通过monitorenter和monitorexit保证可见性与有序性，但根据JMM的hapens-before原则：
- 当某个线程写一个volatile变量时，会**把本地缓存中==所有共享变量副本==的最新值刷新到主内存中**。
- **另外一个线程读这个volatitle变量时会把把本地缓存中所有共享变量的副本置为无效，读取主内存中最新的值**

也就是说，在读写volatile时，并不只是通过读写屏障保证volatile的可见性

## 读写锁是什么，怎么实现，什么时候用读写锁？

当读操作远远高于写操作时，可以使用**读写锁**，让**读-读**操作可以并发，提高性能


读写锁用的是同一个Sync同步器，因此等待队列/state等都是共有的。不同的是：**写锁状态占state的低16位，读锁状态为高16位**

在使用时，首先实例化`ReentrantReadWriteLock rw`，然后实例化其变量`ReadLock`与`WriteLock`，并通过其各自的`lock()`、`unlock()`来实现加锁、解锁。

1. 在上例中，**读取与读取**是不互斥的，而**读取与写入是互斥的**，**获取写锁之前，必须等待读锁释放**
2. 写入与写入是互斥的
3. 读锁不支持条件变量，而写锁支持
4. 不支持**重入时升级**：即持**有读锁的情况下去获取写锁**，会导致写锁永久等待
5. 支持重入时降级，可以在持有写锁的情况下获取读锁

## 读写锁实现原理

### 共享式同步状态获取与释放

AQS提供`acquireShared(int arg)`方法**共享式获取同步状态**：

```java
    public final void acquireShared(int arg) {
        if (tryAcquireShared(arg) < 0)
            //获取失败，自旋获取同步状态
            doAcquireShared(arg);
    }
```
1. 调用`tryAcquireShared(int arg)`方法，尝试获取同步状态，如果获取失败则调用`doAcquireShared(int arg)`自旋方式获取同步状态
   - 共享式获取同步状态的标志是返回 `>= 0` 的值表示获取成功。
2. 在`doAcquireShared(int arg)`中，与`doAcquire(int arg)`类似，都是自旋获得`State`，但此处是继续调用之前的`tryAcquireShared(int arg)`，如果获取失败则阻塞

---

获取同步状态后，需要调用`release(int arg)`方法释放同步状态，方法如下：

因为可能会存在多个线程同时进行释放同步状态资源，所以需要确保同步状态安全地成功释放，一般都是通过CAS和循环来完成的。


# 线程池

## 线程池核心设计与实现

### 总体设计

Java中的线程池核心实现类是`ThreadPoolExecutor`

![图1 ThreadPoolExecutor UML类图](https://p1.meituan.net/travelcube/912883e51327e0c7a9d753d11896326511272.png)

ThreadPoolExecutor实现的顶层接口是`Executor`，顶层接口`Executor`提供了一种思想：**将任务提交和任务执行进行解耦**。
用户无需关注如何创建线程，如何调度线程来执行任务，用户只需提供Runnable对象，将任务的运行逻辑提交到执行器(Executor)中，由Executor框架完成线程的调配和任务的执行部分。

ThreadPoolExecutor**将会一方面维护自身的生命周期，另一方面同时管理线程和任务，使两者良好的结合从而执行并行任务**

线程池在内部实际上构建了一个**生产者消费者模型**，将线程和任务两者解耦，并不直接关联，从而良好的缓冲任务，复用线程。

### 生命周期管理

线程池运行的状态，并不是用户显式设置的，而是伴随着线程池的运行，由内部来维护。线程池内部使用一个变量维护两个值：运行状态(`runState`)和线程数量 (`workerCount`)。

如下代码所示：

```Java
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
```

`ctl`这个AtomicInteger类型，是对**线程池的运行状态和线程池中有效线程的数量**进行控制的一个字段，它同时包含两部分的信息：线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)，==高3位保存runState，低29位保存workerCount==，两个变量之间互不干扰。
> 用一个变量去存储两个值，可避免在做相关决策时，出现不一致的情况，不必为了维护两者的一致，而占用锁资源。

ThreadPoolExecutor的运行状态有5种，分别为：

![img](https://p0.meituan.net/travelcube/62853fa44bfa47d63143babe3b5a4c6e82532.png)

其生命周期转换如下入所示：

![图3 线程池生命周期](https://p0.meituan.net/travelcube/582d1606d57ff99aa0e5f8fc59c7819329028.png)

**参数**

keepAliveTime：非核心线程空闲时间（没有任务执行时）达到keepAliveTime，该线程会退出（避免资源浪费就应该要退出）

### 任务执行机制

任务调度是线程池的主要入口，当用户提交了一个任务，接下来这个任务将如何执行都是由这个阶段决定的。了解这部分就相当于了解了线程池的核心运行机制。

首先，所有任务的调度都是由`execute()`方法完成的，这部分完成的工作是：
- 检查现在线程池的运行状态、运行线程数、运行策略，
- 决定接下来执行的流程，是直接申请线程执行，或是缓冲到队列中执行，亦或是直接拒绝该任务。
   

其执行过程如下：

1. 首先检测线程池运行状态，如果不是`RUNNING`，则直接拒绝，线程池要保证在RUNNING的状态下执行任务。
4. 如果`workerCount < 最大核心线程数corePoolSize`，则创建并启动一个核心线程来执行新提交的任务。
5. 如果`workerCount >= 最大核心线程数corePoolSize`，且线程池内的**阻塞队列未满**，则将任务添加到该阻塞队列中。
6. 如果`workerCount >= 最大核心线程数corePoolSize && workerCount < 最大线程数maximumPoolSize`，且线程池内的**阻塞队列已满**，则创建并启动一个救急线程线程来执行新提交的任务。
7. 如果`workerCount >= 最大线程数maximumPoolSize`，并且线程池内的**阻塞队列已满**, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。

其执行流程如下图所示：

![图4 任务调度流程](https://p0.meituan.net/travelcube/31bad766983e212431077ca8da92762050214.png)

### **任务缓冲**

任务缓冲模块是线程池能够管理任务的核心部分。
线程池的本质是对任务和线程的管理，而做到这一点最关键的思想就是**将任务和线程两者解耦**，不让两者直接关联，才可以做后续的分配工作。
线程池中是以**生产者消费者模式**，通过一个**阻塞队列**来实现的。阻塞队列缓存任务，工作线程从阻塞队列中获取任务。

使用不同的队列可以实现不一样的任务存取策略，阻塞队列的类别如下：

![img](https://p0.meituan.net/travelcube/725a3db5114d95675f2098c12dc331c3316963.png)

实际上，阻塞队列可以划分为三大类：
- 无界队列：
  - 队列大小无限制，常用的为无界的LinkedBlockingQueue
    - LinkedBlockingQueue如果不指定容量，就是无界队列
  - 使用无界队列时要小心，**当任务耗时较长时可能会导致大量新任务在队列中堆积最终导致OOM**
- 有界队列：
  - 即存在容量限制的阻塞队列，常用的有两类：
    1. 遵循FIFO原则的ArrayBlockingQueue与指定了容量的LinkedBlockingQueue
    2. 优先队列，如：PriorityBlockingQueue（优先级由任务的Comparator决定） 
- 同步移交队列：
  - 如果不希望任务在队列中等待而是希望将任务直接移交给工作线程，可使用`SynchronousQueue`作为等待队列
  - `SynchronousQueue`不是一个真正的队列，而是一种**线程之间移交的机制**。
    - 要将一个元素放入`SynchronousQueue`中，==必须有另一个线程正在等待接收这个元素==。
    - **只有在使用无界线程池或者有饱和策略时才建议使用该队列**

### 饱和策略

饱和策略：如果线程数等于最大线程数（核心线程和救急线程都满了），且阻塞队列已满，则调用饱和策略

JDK提供的拒绝策略：
- `AbortPolicy`：让调用者抛出`RejectedExecutionException`异常
- `CallerRunsPolicy`：让调用者运行任务
- `DiscardPolicy`：放弃本次任务
- `DiscardOldestPolicy`：放弃队列中最早的任务，本任务取而代之

### Worker线程管理

线程池为了掌握线程的状态并维护线程的生命周期，设计了线程池内的工作线程Worker。我们来看一下它的部分代码：

```Java
private final class Worker extends AbstractQueuedSynchronizer implements Runnable{
    final Thread thread;//Worker持有的线程
    Runnable firstTask;//初始化的任务，可以为null
}
```

Worker这个工作线程，继承了AQS，实现了Runnable接口，并持有一个线程thread，一个初始化的任务firstTask。
- `thread`是在调用构造方法时通过`ThreadFactory`来创建的线程，可以用来执行任务；
- `firstTask`用它来保存传入的第一个任务，这个任务可以有也可以为null。
  - 如果这个值是非空的，那么线程就会在启动初期立即执行这个任务，也就对应核心线程创建时的情况；
  - 如果这个值是null，那么就需要创建一个线程去执行任务列表（workQueue）中的任务，也就是非核心线程的创建。

Worker执行任务的模型如下图所示：

![图7 Worker执行任务](https://p0.meituan.net/travelcube/03268b9dc49bd30bb63064421bb036bf90315.png)

线程池需要管理线程的生命周期，**需要在线程长时间不运行的时候进行回收**。
**线程池使用一张`Hash`表去持有线程的引用**，这样可以通过添加引用、移除引用这样的操作来**控制线程的生命周期**。这个时候重要的就是**如何判断线程是否在运行**。

**Worker是通过继承AQS，使用AQS来实现不可重入的独占锁，从而判断Worker的状态，判断线程是否在运行**。
> 没有使用可重入锁ReentrantLock，而是使用AQS，为的就是实现**不可重入**的特性去反应线程现在的执行状态。

在Worker执行任务前，首先要通过AQS获取锁，因此可以通过锁的状态判断worker的状态：
1. 线程持有独占锁，表示当前线程正在执行任务中，不应该中断线程。 
2. 线程未持有锁，即空闲状态，说明它没有在处理任务，这时可以对该线程进行中断。

线程池在执行`shutdown`方法或`tryTerminate`方法时，会调用`interruptIdleWorkers`方法来**中断空闲的线程**。
`interruptIdleWorkers`方法会==使用`tryLock`方法来判断线程池中的线程是否是空闲状态；如果线程是空闲状态则可以安全回收==

如图所示：

![图8 线程池回收过程](https://p1.meituan.net/travelcube/9d8dc9cebe59122127460f81a98894bb34085.png)

#### **Worker线程增加**

增加线程是通过线程池中的`addWorker`方法，该方法的功能就是增加一个线程。
该方法不考虑线程池是在哪个阶段增加的该线程，**分配线程的策略是在上个步骤完成的**，该步骤**仅仅完成增加线程，并使它运行**，最后返回是否成功这个结果。

addWorker方法有两个参数：`firstTask`、`core`。
- `firstTask`参数用于指定新增的线程执行的第一个任务，该参数可以为空；
- `core`参数为true表示在新增线程时会判断当前活动线程数是否少于`corePoolSize`
- 为false表示新增线程前需要判断当前活动线程数是否少于`maximumPoolSize`

![图9 申请线程执行流程图](https://p0.meituan.net/travelcube/49527b1bb385f0f43529e57b614f59ae145454.png)


#### **Worker线程回收**

==线程池中线程的销毁依赖JVM自动的回收==，线程池做的工作是根据当前线程池的状态**维护一定数量的线程引用**，防止这部分线程被JVM回收，当线程池决定哪些线程需要回收时，只需要将其引用消除即可。

Worker被创建出来后，就会不断地进行轮询，然后获取任务去执行，核心线程可以无限等待获取任务，非核心线程要限时获取任务。

**当Worker无法获取到任务，也就是获取的任务为空时，循环会结束，Worker会主动消除自身在线程池内的引用，从而可以被JVM回收**

```Java
try {
  while (task != null || (task = getTask()) != null) {
    //执行任务
  }
} finally {
  processWorkerExit(w, completedAbruptly);//获取不到任务时，主动回收自己
}
```

线程回收的工作是在`processWorkerExit`方法完成的。

![图10 线程销毁流程](https://p0.meituan.net/travelcube/90ea093549782945f2c968403fdc39d415386.png)

事实上，在这个方法中，将线程引用移出线程池就已经结束了线程销毁的部分。但由于引起线程销毁的可能性有很多，线程池还要判断是什么引发了这次销毁，是否要改变线程池的现阶段状态，是否要根据新状态，重新分配线程。

#### **Worker线程执行任务**

在Worker类中的`run`方法调用了`runWorker()`方法来执行任务，`runWorker()`方法的执行过程如下：

1. while循环不断地通过`getTask()`方法获取任务。 
2. `getTask()`方法从阻塞队列中取任务。 
3. 如果线程池正在停止，那么要保证当前线程是中断状态，否则要保证当前线程不是中断状态。 
4. 执行任务。 
5. 如果`getTask`结果为null则跳出循环，执行`processWorkerExit()`方法，销毁线程。

执行流程如下图所示：

![图11 执行任务流程](https://p0.meituan.net/travelcube/879edb4f06043d76cea27a3ff358cb1d45243.png)


## 线程池参数设置

### 常规设置

任务分 IO 密集型任务或者分 CPU 密集型任务

#### **CPU 密集型任务**

`CPU密集型`也叫`计算密集型`，指的是系统的硬盘、内存性能相对CPU要好很多，此时，系统运作大部分的状况是CPU Loading 100%，CPU要读/写I/O(硬盘/内存)，I/O在很短的时间就可以完成，而CPU还有许多运算要处理，CPU Loading 很高。

**CPU密集型：corePoolSize = CPU核数 + 1**

《Java并发编程实战》一书中给出的原因是：**即使当计算（CPU）密集型的线程偶尔由于页缺失故障或者其他原因而暂停时，这个“额外”的线程也能确保 CPU 的时钟周期不会被浪费。** 把它理解为一个备份的线程就行了。

> 注意：这个地方还有个需要注意的小点就是，如果你的服务器上部署的不止一个应用，你就得考虑其他的应用的线程池配置情况。
否则经过精密的计算，你咔一下设置为核心数，结果项目部署上去了，发现还有其他的应用在和你抢 CPU。

#### **IO 密集型任务**

IO密集型的话，是指系统大部分时间在跟I/O交互，而这个时间线程不会占用CPU来处理，即在这个时间范围内，可以由其他线程来使用CPU，因而可以多配置一些线程。

可设置为 `2*CPU 核心数`，有点像是把任务都当做 IO 密集型去处理了。而且一个项目里面一般来说不止一个自定义线程池吧？比如有专门处理数据上送的线程池，有专门处理查询请求的线程池，这样去做一个简单的线程隔离。但是如果都用这样的参数配置的话，显然是不合理的。

## 线程池被创建后里面有线程吗？如果没有的话，你知道有什么方法对线程池进行预热吗？

线程池被创建后如果没有任务过来，里面是不会有线程的，所以在使用线程池执行前几次任务时，会明显感知到响应时间会更长一些，因为需要创建Worker线程

## 核心线程数会被回收吗？需要什么设置？

核心线程数默认是不会被回收的



## 线程池的原理（工作流程）、四种拒绝策略（给用户发消息任务超出队列，你用哪个拒绝策略？）

线程池是`ThreadPoolExecutor`的实现类，将会**一方面维护自身的生命周期，另一方面同时管理线程和任务**，使两者良好的结合从而执行并行任务。
线程池在内部实际上构建了一个**生产者消费者模型**，将线程和任务两者解耦，并不直接关联，从而良好的缓冲任务，复用线程。
除此之外，线程池还包含一个阻塞队列，用来进行任务的缓冲。

拒绝策略：如果线程数等于最大线程数（核心线程和救急线程都满了），且阻塞队列已满，则调用拒绝策略

JDK提供的拒绝策略：
- AbortPolicy：让调用者抛出`RejectedExecutionException`异常
- CallerRunsPolicy：让调用者运行任务
- DiscardPolicy：放弃本次任务
- DiscardOldestPolicy：放弃队列中最早的任务，本任务取而代之

## 任务提交到线程池后会有哪些情况

当使用`execute()`方法将任务提交到线程池时，会有以下几种情况

1. 首先检测线程池运行状态，如果不是`RUNNING`，则直接拒绝，线程池要保证在RUNNING的状态下执行任务。
4. 如果`workerCount < 最大核心线程数corePoolSize`，则创建并启动一个核心线程来执行新提交的任务。
5. 如果`workerCount >= 最大核心线程数corePoolSize`，且线程池内的**阻塞队列未满**，则将任务添加到该阻塞队列中。
6. 如果`workerCount >= 最大核心线程数corePoolSize && workerCount < 最大线程数maximumPoolSize`，且线程池内的**阻塞队列已满**，则创建并启动一个救急线程线程来执行新提交的任务。
7. 如果`workerCount >= 最大线程数maximumPoolSize`，并且线程池内的**阻塞队列已满**, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。

其执行流程如下图所示：

![图4 任务调度流程](https://p0.meituan.net/travelcube/31bad766983e212431077ca8da92762050214.png)

## submit 和 execute 的区别

- execute只能提交`Runnable`类型的任务，==无返回值==
- submit既可以提交`Runnable`类型的任务，也可以提交`Callable`类型的任务，会有一个类型为`Future`的返回值，但**当任务类型为Runnable时，返回值为null**
- **execute在执行任务时，如果遇到异常会直接抛出**；
- 而**submit不会直接抛出，==只有在使用Future的get方法获取返回值时，才会抛出异常==**

## 创建线程池时的基本参数以及该如何配置

线程池的基本参数包含：
```java
public ThreadPoolExecutor(
    int corePoolSize,//核心线程数目（最多保留的线程数）
    int maximumPoolSize,//最大线程数目
    long keepAliveTime,//生存时间-针对救急线程
    TimeUnit unit,//时间单位
    BlockingQueue<Runnable> workQueue,//阻塞队列
    ThreadFactory threadFactory,//线程工厂
    RejectedExecutionHandler handler//拒绝策略
)
```
其中，最核心的三个参数为：核心线程数、最大线程数、阻塞队列类型，它们将直接影响提交任务时线程池的行为。

JDK默认提供了以下几种工厂方法，从而提供默认的线程池:
- `newFixedThreadPool`
  - `核心线程数 == 最大线程数`（没有救急线程），不需要超时时间
  - **阻塞队列是无界的，可以放任意数量的任务**
  - 使用默认的线程工厂，线程默认为非守护线程

  - 场景：
    - 任务量已知，且相对耗时
    - 如果核心线程数较少，很容易导致阻塞队列中存储了大量的任务，导致OOM

- `newCachedThreadPool`
  - 核心线程数为`0`，最大线程数为`Integer.MAX_VALUE`，救急线程的生存时间为60s，即：
      - ==所有线程都是救急线程，空闲60s后回收==
      - 救急线程可以无限创建
  - 队列采用了`SynchronousQueue`，特点：没有容量，没有线程来取任务时，是不能将任务放进去的（一手交钱，一手交货）
      - ==put方法会被阻塞，直到有take方法进来，才真正完成put的操作==
  - 场景：
    1. 线程数根据任务量增长，且没有上限
    2. 适用于：任务密集，且每个任务执行时间较短的情况


- `newSingleThreadExecutor`
  - 核心线程数与最大线程数都是1，即没有救急线程，且进入线程池的任务串行执行，多余的任务放入无界的任务队列
  - 和直接创建线程执行任务的区别：
    - 自己创建单线程来串行执行任务，如果任务执行失败而终止，就没有任何补救。二线程池会新创建一个线程，继续完成工作

- `newScheduledThreadPool`
  - 需要指定核心线程数，最大线程数为`Integer.MAX_VALUE`，救急线程的生存时间为0s，即
  - 创建一个定长线程池，支持定时及周期性任务执行
    - 通过设置`ScheduleFutureTask`的`time`字段，记录需要执行的时间，并在时间到达时执行，重新设置`time`域
# 同步工具类

## Java中文件最后都会转换为二进制字节流，那在这个层面是如何加锁解锁的呢？



## AtomicInteger的原理与实现



## 介绍一下fork join线程池

fork/join体现的是分治的思想，适用于能够进行任务拆分的cpu密集型运算

> 任务拆分：将大任务拆分为算法上相同的小任务

Fork/Join在分治的基础上加入了多线程，将每个任务的分解和合并交给不同的线程，进一步提高运算效率

> 默认创建于cpu核心数相同大小的线程池


## Java中的fork join框架是什么？

　　fork join框架是JDK7中出现的一款高效的工具，Java开发人员可以通过它充分利用现代服务器上的多处理器。它是专门为了那些可以递归划分成许多子模块设计的，目的是将所有可用的处理能力用来提升程序的性能。fork join框架一个巨大的优势是它使用了工作窃取算法，可以完成更多任务的工作线程可以从其它线程中窃取任务来执行。

## 介绍一下RNL，多线程去抢RNL的时候是怎样竞争锁的


## synchronized和 RNL的区别


## 介绍一下CountDownLatch（await、countDown）

CountDownLatch可以使一个获多个线程等待其他线程各自执行完毕后再执行

CountDownLatch 定义了一个计数器，和一个阻塞队列：
- **当计数器的值递减为0之前，阻塞队列里面的线程处于挂起状态**
- **当计数器递减到0时会唤醒阻塞队列所有线程**

这里的计数器是一个标志，可以表示一个任务一个线程，也可以表示一个倒计时器。
CountDownLatch可以解决那些一个或者多个线程在执行之前必须依赖于某些必要的前提业务先执行的场景。

CountDownLatch内部也是用一个AQS来实现计数与阻塞队列的
其中，计数器即AQS的state

## 介绍一下CyclicBarrier

CyclicBarrier和CountDownLatch类似，只是CyclicBarrier是基于ReentrantLock和Condition实现的

其原理是：当等待的线程达到指定值时，才将阻塞的线程放行

## 介绍一下Semaphore

Semaphore即信号量，主要是acquire 申请信号量的许可，release释放许可供其他线程申请。用于对并发资源的同步控制

也是通过AQS实现的

## 介绍一下Exchanger